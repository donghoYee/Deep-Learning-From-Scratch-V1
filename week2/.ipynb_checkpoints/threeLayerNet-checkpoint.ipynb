{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d195ded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d26d84dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DLFS_book.common.functions import *\n",
    "from DLFS_book.common.gradient import numerical_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4c5445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLayerNet:\n",
    "    def __init__(self, input_size, hidden1_size, hidden2_size, output_size, weight_init_std=0.01):\n",
    "        self.params= {}\n",
    "        \n",
    "        self.params[\"W1\"] = weight_init_std * np.random.randn(input_size, hidden1_size)\n",
    "        self.params[\"b1\"] = np.zeros(hidden1_size)\n",
    "        \n",
    "        self.params[\"W2\"] = weight_init_std * np.random.randn(hidden1_size, hidden2_size)\n",
    "        self.params[\"b2\"] = np.zeros(hidden2_size)\n",
    "        \n",
    "        self.params[\"W3\"] = weight_init_std * np.random.randn(hidden2_size, output_size)\n",
    "        self.params[\"b3\"] = np.zeros(output_size)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        W1, W2, W3 = self.params[\"W1\"], self.params[\"W2\"], self.params[\"W3\"]\n",
    "        b1, b2, b3 = self.params[\"b1\"], self.params[\"b2\"], self.params[\"b3\"]\n",
    "        \n",
    "        x = x @ W1 + b1\n",
    "        x = sigmoid(x)\n",
    "        x = x @ W2 + b2\n",
    "        x = sigmoid(x)\n",
    "        x = x @ W3 + b3\n",
    "        \n",
    "        return softmax(x)\n",
    "    \n",
    "    def loss(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        return cross_entropy_error(y_pred, y)\n",
    "        \n",
    "    def accuracy(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        y_pred = np.argmax(y_pred, axis = 1)\n",
    "        y = np.argmax(y, axis= 1)\n",
    "        \n",
    "        accuracy = np.sum(y_pred == y) / float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    def numerical_gradient(self, x, t):\n",
    "        \n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads[\"W1\"]= numerical_gradient(loss_W, self.params[\"W1\"])\n",
    "        grads[\"W2\"]= numerical_gradient(loss_W, self.params[\"W2\"])\n",
    "        grads[\"W3\"]= numerical_gradient(loss_W, self.params[\"W3\"])\n",
    "        \n",
    "        grads[\"b1\"]= numerical_gradient(loss_W, self.params[\"b1\"])\n",
    "        grads[\"b2\"]= numerical_gradient(loss_W, self.params[\"b2\"])\n",
    "        grads[\"b3\"]= numerical_gradient(loss_W, self.params[\"b3\"])\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d509f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ThreeLayerNet(input_size=784, hidden1_size = 300, hidden2_size=100, output_size=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49475953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.params[\"W1\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de60bcc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m t \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mpredict(x)\n\u001b[0;32m----> 4\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumerical_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mThreeLayerNet.numerical_gradient\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     40\u001b[0m loss_W \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m W: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, t)\n\u001b[1;32m     42\u001b[0m grads \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 43\u001b[0m grads[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39m \u001b[43mnumerical_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_W\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mW1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m grads[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW2\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39m numerical_gradient(loss_W, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW2\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     45\u001b[0m grads[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW3\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39m numerical_gradient(loss_W, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW3\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/tutor/tutor_1/DLFS1/week2/../DLFS_book/common/gradient.py:43\u001b[0m, in \u001b[0;36mnumerical_gradient\u001b[0;34m(f, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m tmp_val \u001b[38;5;241m=\u001b[39m x[idx]\n\u001b[1;32m     42\u001b[0m x[idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(tmp_val) \u001b[38;5;241m+\u001b[39m h\n\u001b[0;32m---> 43\u001b[0m fxh1 \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# f(x+h)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m x[idx] \u001b[38;5;241m=\u001b[39m tmp_val \u001b[38;5;241m-\u001b[39m h \n\u001b[1;32m     46\u001b[0m fxh2 \u001b[38;5;241m=\u001b[39m f(x) \u001b[38;5;66;03m# f(x-h)\u001b[39;00m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mThreeLayerNet.numerical_gradient.<locals>.<lambda>\u001b[0;34m(W)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumerical_gradient\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, t):\n\u001b[0;32m---> 40\u001b[0m     loss_W \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m W: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     grads \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     43\u001b[0m     grads[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39m numerical_gradient(loss_W, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW1\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mThreeLayerNet.loss\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y):\n\u001b[0;32m---> 27\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cross_entropy_error(y_pred, y)\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mThreeLayerNet.predict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m b1, b2, b3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb1\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb2\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb3\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     18\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m@\u001b[39m W1 \u001b[38;5;241m+\u001b[39m b1\n\u001b[0;32m---> 19\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m@\u001b[39m W2 \u001b[38;5;241m+\u001b[39m b2\n\u001b[1;32m     21\u001b[0m x \u001b[38;5;241m=\u001b[39m sigmoid(x)\n",
      "File \u001b[0;32m~/tutor/tutor_1/DLFS1/week2/../DLFS_book/common/functions.py:14\u001b[0m, in \u001b[0;36msigmoid\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msigmoid\u001b[39m(x):\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x = np.random.rand(100, 784)\n",
    "t = np.random.rand(100, 10)\n",
    "y = net.predict(x)\n",
    "grad = net.numerical_gradient(x, t)\n",
    "\n",
    "#net.params -= alpha * net.grads  # 학습 1번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09812348",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d595c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1bde6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
