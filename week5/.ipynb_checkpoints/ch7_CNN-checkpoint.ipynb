{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f824635",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4a6065",
   "metadata": {},
   "source": [
    "### 4 dim data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50f178bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.random.rand(10,3,28,28) # like mnist data!\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7471ed00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc00d8d",
   "metadata": {},
   "source": [
    "### im2col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a0fda8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"다수의 이미지를 입력받아 2차원 배열로 변환한다(평탄화).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : 4차원 배열 형태의 입력 데이터(이미지 수, 채널 수, 높이, 너비)\n",
    "    filter_h : 필터의 높이\n",
    "    filter_w : 필터의 너비\n",
    "    stride : 스트라이드\n",
    "    pad : 패딩\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    col : 2차원 배열\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecb01ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5760, 75)\n"
     ]
    }
   ],
   "source": [
    "col1 = im2col(x,5,5,stride=1,pad=0)\n",
    "print(col1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68c4881",
   "metadata": {},
   "source": [
    "## Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba49b1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"(im2col과 반대) 2차원 배열을 입력받아 다수의 이미지 묶음으로 변환한다.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    col : 2차원 배열(입력 데이터)\n",
    "    input_shape : 원래 이미지 데이터의 형상（예：(10, 1, 28, 28)）\n",
    "    filter_h : 필터의 높이\n",
    "    filter_w : 필터의 너비\n",
    "    stride : 스트라이드\n",
    "    pad : 패딩\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    img : 변환된 이미지들\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "\n",
    "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "    return img[:, :, pad:H + pad, pad:W + pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a64cd72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution: #########################################################\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        #for backward\n",
    "        self.x = None   \n",
    "        self.col = None\n",
    "        self.col_W = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1+ (H + 2*self.pad -FH)/ self.stride)\n",
    "        out_w = int(1+ (W + 2*self.pad -FW)/ self.stride)\n",
    "        \n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN,-1).T\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        \n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0,3,1,2)\n",
    "        \n",
    "        self.x = x\n",
    "        self.col = col\n",
    "        self.col_W = col_W\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n",
    "\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        self.dW = np.dot(self.col.T, dout) ######### 그냥 Affine과 계산 같다!\n",
    "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
    "\n",
    "        dcol = np.dot(dout, self.col_W.T)\n",
    "        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692bc1dd",
   "metadata": {},
   "source": [
    "# Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba721440",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.x = None\n",
    "        self.arg_max = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "\n",
    "        arg_max = np.argmax(col, axis=1)\n",
    "        out = np.max(col, axis=1)\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.x = x\n",
    "        self.arg_max = arg_max\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout = dout.transpose(0, 2, 3, 1)\n",
    "        \n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        dmax = np.zeros((dout.size, pool_size))\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
    "        dmax = dmax.reshape(dout.shape + (pool_size,)) \n",
    "        \n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ba9166",
   "metadata": {},
   "source": [
    "# CNN 구현하기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cb94fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"../DLFS_book/\")\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class SimpleConvNet:\n",
    "\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # init weights\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # layers\n",
    "        self.layers = OrderedDict() #use ordered dict for \"FOR\" statement\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values(): #use ordered dict for this!\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        # forward -> store values in layers!\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward (backpropagation!)\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # store values in this dictionary!\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    # save and load params for later use!\n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {} # why not just use self.params?\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']): # save weights in layers\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85db3d28",
   "metadata": {},
   "source": [
    "# Train with Mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c8b42ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.299594777507682\n",
      "=== epoch:1, train acc:0.194, test acc:0.195 ===\n",
      "train loss:2.298249264548422\n",
      "train loss:2.29531491377671\n",
      "train loss:2.2916129200083057\n",
      "train loss:2.2825492607143185\n",
      "train loss:2.272298059805847\n",
      "train loss:2.2573703029258474\n",
      "train loss:2.242829965948121\n",
      "train loss:2.219671919684183\n",
      "train loss:2.19676336828599\n",
      "train loss:2.165660341697161\n",
      "train loss:2.1097468502017445\n",
      "train loss:2.1181494512882493\n",
      "train loss:2.027535171356318\n",
      "train loss:2.027691043369949\n",
      "train loss:1.979260499124053\n",
      "train loss:1.9340022682240547\n",
      "train loss:1.877508123581955\n",
      "train loss:1.8327201896687568\n",
      "train loss:1.662630494246227\n",
      "train loss:1.7196307523784893\n",
      "train loss:1.5092744779202532\n",
      "train loss:1.3665257452861772\n",
      "train loss:1.3337746847229308\n",
      "train loss:1.2315243662895137\n",
      "train loss:1.1613881864148485\n",
      "train loss:1.1612411544598806\n",
      "train loss:1.114795000907659\n",
      "train loss:0.874773752762312\n",
      "train loss:0.9963450470670696\n",
      "train loss:0.8907047166481822\n",
      "train loss:0.892452226759067\n",
      "train loss:0.7367529795198667\n",
      "train loss:0.6991100541646776\n",
      "train loss:0.7683726022202579\n",
      "train loss:0.6879525879444519\n",
      "train loss:0.8256392082353566\n",
      "train loss:0.8349784080164226\n",
      "train loss:0.7734291994522785\n",
      "train loss:0.5616688326354096\n",
      "train loss:0.5561853501164221\n",
      "train loss:0.7788271785206246\n",
      "train loss:0.7310392946946522\n",
      "train loss:0.8144805729555114\n",
      "train loss:0.6492675028882269\n",
      "train loss:0.7328434754441022\n",
      "train loss:0.7025813825904531\n",
      "train loss:0.5461103758161455\n",
      "train loss:0.6070366545822146\n",
      "train loss:0.5199646376032147\n",
      "train loss:0.6828144651636845\n",
      "train loss:0.5977973164127119\n",
      "train loss:0.5953399628616641\n",
      "train loss:0.635004602997155\n",
      "train loss:0.805902410336679\n",
      "train loss:0.6070078748725042\n",
      "train loss:0.4099263127513693\n",
      "train loss:0.5857039387097437\n",
      "train loss:0.4376349400164863\n",
      "train loss:0.5460638983443356\n",
      "train loss:0.3097164461528374\n",
      "train loss:0.4582387666924908\n",
      "train loss:0.41178694347211076\n",
      "train loss:0.5783587120709922\n",
      "train loss:0.5417472707603487\n",
      "train loss:0.44586437885745633\n",
      "train loss:0.4310086502929133\n",
      "train loss:0.49452181935048456\n",
      "train loss:0.5574275821953285\n",
      "train loss:0.5400075975090671\n",
      "train loss:0.4728695788874074\n",
      "train loss:0.619026412715678\n",
      "train loss:0.4575695047919081\n",
      "train loss:0.4326960776582368\n",
      "train loss:0.28139743706160764\n",
      "train loss:0.5619246496062408\n",
      "train loss:0.3035275564986909\n",
      "train loss:0.45433476876824025\n",
      "train loss:0.4877379024898653\n",
      "train loss:0.46078719740836216\n",
      "train loss:0.4464574950791979\n",
      "train loss:0.36224082854684914\n",
      "train loss:0.47403744080565835\n",
      "train loss:0.5299443049945822\n",
      "train loss:0.41123679933039553\n",
      "train loss:0.443680303988341\n",
      "train loss:0.4723052457057279\n",
      "train loss:0.5063709504077917\n",
      "train loss:0.34002921030308414\n",
      "train loss:0.4649340428650459\n",
      "train loss:0.42243005665773836\n",
      "train loss:0.34676610768859784\n",
      "train loss:0.30601896731631667\n",
      "train loss:0.41334947550395634\n",
      "train loss:0.26327665564853964\n",
      "train loss:0.6689619159184178\n",
      "train loss:0.34199627271472105\n",
      "train loss:0.34787501159494\n",
      "train loss:0.2881303667527239\n",
      "train loss:0.34963911096137684\n",
      "train loss:0.5314491307702811\n",
      "train loss:0.33768653884789646\n",
      "train loss:0.28791853031937453\n",
      "train loss:0.1879432941688909\n",
      "train loss:0.3179019360526935\n",
      "train loss:0.40162375601477\n",
      "train loss:0.24147583939086129\n",
      "train loss:0.3001244846346597\n",
      "train loss:0.34577974607403517\n",
      "train loss:0.2916970194351533\n",
      "train loss:0.48301133420908526\n",
      "train loss:0.4221786798117705\n",
      "train loss:0.3750624714722211\n",
      "train loss:0.48570667245634785\n",
      "train loss:0.24329772970782015\n",
      "train loss:0.44161788812703123\n",
      "train loss:0.5480361601455694\n",
      "train loss:0.34282549918377503\n",
      "train loss:0.43476236468271034\n",
      "train loss:0.28707160707780166\n",
      "train loss:0.4133096600457412\n",
      "train loss:0.3624960782232817\n",
      "train loss:0.41716693776945574\n",
      "train loss:0.3637897691256565\n",
      "train loss:0.37851279391255815\n",
      "train loss:0.4077059982198857\n",
      "train loss:0.434343904223382\n",
      "train loss:0.5346991550768161\n",
      "train loss:0.454643571389961\n",
      "train loss:0.38353336574843766\n",
      "train loss:0.5006994360091495\n",
      "train loss:0.4648550626504673\n",
      "train loss:0.366477006294785\n",
      "train loss:0.41268599376404697\n",
      "train loss:0.3998749105228261\n",
      "train loss:0.4005083123190002\n",
      "train loss:0.3937343760907027\n",
      "train loss:0.25510662975524584\n",
      "train loss:0.25004275065011206\n",
      "train loss:0.32045867865084915\n",
      "train loss:0.4454826296747661\n",
      "train loss:0.4445528030862652\n",
      "train loss:0.21434018038465497\n",
      "train loss:0.15751053116693295\n",
      "train loss:0.3264293579826618\n",
      "train loss:0.3870759272238875\n",
      "train loss:0.33992405740473286\n",
      "train loss:0.3605114467329414\n",
      "train loss:0.22604689522177235\n",
      "train loss:0.19750446600189225\n",
      "train loss:0.3362265910524338\n",
      "train loss:0.2869026387267964\n",
      "train loss:0.2719986524574723\n",
      "train loss:0.34108138607619737\n",
      "train loss:0.23774248414468957\n",
      "train loss:0.2544836158617142\n",
      "train loss:0.3660223820145112\n",
      "train loss:0.3634988025108637\n",
      "train loss:0.27177773537998223\n",
      "train loss:0.2836333081196826\n",
      "train loss:0.3826638158322072\n",
      "train loss:0.4086069878566333\n",
      "train loss:0.46731826447790803\n",
      "train loss:0.43837551573954064\n",
      "train loss:0.2930561086846153\n",
      "train loss:0.2750028024520667\n",
      "train loss:0.2677816613290359\n",
      "train loss:0.4529090881293428\n",
      "train loss:0.34864950977935744\n",
      "train loss:0.3395985799479999\n",
      "train loss:0.4905188733976149\n",
      "train loss:0.4458010381452905\n",
      "train loss:0.3156201967481889\n",
      "train loss:0.37110288413985815\n",
      "train loss:0.30100143838522536\n",
      "train loss:0.3419338750622134\n",
      "train loss:0.19735599289074507\n",
      "train loss:0.4154978538360197\n",
      "train loss:0.2555445518181784\n",
      "train loss:0.36707017533133135\n",
      "train loss:0.25665451702987485\n",
      "train loss:0.3516917344284674\n",
      "train loss:0.36762619500810645\n",
      "train loss:0.42080156679181774\n",
      "train loss:0.3947872109718233\n",
      "train loss:0.2485169856426555\n",
      "train loss:0.1859315798630979\n",
      "train loss:0.3922355599013163\n",
      "train loss:0.3319888910275929\n",
      "train loss:0.45686071249905474\n",
      "train loss:0.37192838007563034\n",
      "train loss:0.2673793508562195\n",
      "train loss:0.3268027751304303\n",
      "train loss:0.26311920688215723\n",
      "train loss:0.27229420859459574\n",
      "train loss:0.24173014887203717\n",
      "train loss:0.2644152891793368\n",
      "train loss:0.25464807092612585\n",
      "train loss:0.36413514687368725\n",
      "train loss:0.2904474474027838\n",
      "train loss:0.3098553464252807\n",
      "train loss:0.2882709421978181\n",
      "train loss:0.39906042959428445\n",
      "train loss:0.4268799421234171\n",
      "train loss:0.23898544073608177\n",
      "train loss:0.17707081372837086\n",
      "train loss:0.3321337445647785\n",
      "train loss:0.5783411288633297\n",
      "train loss:0.34907700057971935\n",
      "train loss:0.184706119186093\n",
      "train loss:0.26719765166715637\n",
      "train loss:0.2992576010356173\n",
      "train loss:0.4584612064899505\n",
      "train loss:0.24699644010528168\n",
      "train loss:0.3960386087591559\n",
      "train loss:0.2955860261573278\n",
      "train loss:0.15154203389267445\n",
      "train loss:0.2554662923417091\n",
      "train loss:0.19706899470037684\n",
      "train loss:0.28830028137848673\n",
      "train loss:0.23688465829205782\n",
      "train loss:0.3805444613590155\n",
      "train loss:0.2233731422238836\n",
      "train loss:0.29214127907113013\n",
      "train loss:0.3506816686648832\n",
      "train loss:0.40457208408794865\n",
      "train loss:0.3423862509621487\n",
      "train loss:0.25199676973729984\n",
      "train loss:0.2134223144443547\n",
      "train loss:0.2518632955992222\n",
      "train loss:0.2738227398822605\n",
      "train loss:0.32342661982066434\n",
      "train loss:0.29937917668288877\n",
      "train loss:0.2321810550728688\n",
      "train loss:0.2341266513128045\n",
      "train loss:0.28790607371684573\n",
      "train loss:0.2893822172122762\n",
      "train loss:0.2647372898174292\n",
      "train loss:0.42223701415216297\n",
      "train loss:0.23441344396269007\n",
      "train loss:0.24122613168654233\n",
      "train loss:0.3017886869643343\n",
      "train loss:0.32226873968820086\n",
      "train loss:0.27554012064862415\n",
      "train loss:0.29671140604442525\n",
      "train loss:0.3804879352014023\n",
      "train loss:0.23285767819280326\n",
      "train loss:0.3117645809068465\n",
      "train loss:0.2610827073253947\n",
      "train loss:0.2111464198442508\n",
      "train loss:0.32460458713005275\n",
      "train loss:0.2303570223369448\n",
      "train loss:0.4392238384265796\n",
      "train loss:0.27594497163800885\n",
      "train loss:0.373010785085583\n",
      "train loss:0.17180118882270684\n",
      "train loss:0.29992407324925385\n",
      "train loss:0.3628771267890677\n",
      "train loss:0.27356618033814767\n",
      "train loss:0.3768807392110277\n",
      "train loss:0.49236049509473995\n",
      "train loss:0.17029843343284212\n",
      "train loss:0.30018137450399246\n",
      "train loss:0.31059573268876584\n",
      "train loss:0.21640745548177331\n",
      "train loss:0.2683287831106738\n",
      "train loss:0.2717972442167043\n",
      "train loss:0.25072356436343973\n",
      "train loss:0.34156253935657205\n",
      "train loss:0.20541355354546625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.1859071881049659\n",
      "train loss:0.22341698208111013\n",
      "train loss:0.26373341872963374\n",
      "train loss:0.1973309242256288\n",
      "train loss:0.13218587502488513\n",
      "train loss:0.19080533196324992\n",
      "train loss:0.27587247625363076\n",
      "train loss:0.24470634936563018\n",
      "train loss:0.1909019371968936\n",
      "train loss:0.1958329883472487\n",
      "train loss:0.28127969171436734\n",
      "train loss:0.2511301582874065\n",
      "train loss:0.23420017050618397\n",
      "train loss:0.20308933291175502\n",
      "train loss:0.28559524458102337\n",
      "train loss:0.22557780177332565\n",
      "train loss:0.21039366483261737\n",
      "train loss:0.32354831845834753\n",
      "train loss:0.2349128951190831\n",
      "train loss:0.2583688867768901\n",
      "train loss:0.274418826535969\n",
      "train loss:0.1764156313165961\n",
      "train loss:0.11789618078579006\n",
      "train loss:0.23329176883668307\n",
      "train loss:0.22954094464327546\n",
      "train loss:0.2782974845809128\n",
      "train loss:0.26453060886705937\n",
      "train loss:0.21727747761372943\n",
      "train loss:0.2555702859945345\n",
      "train loss:0.3469460025839583\n",
      "train loss:0.1792917795994014\n",
      "train loss:0.3310021522530056\n",
      "train loss:0.42496119982627334\n",
      "train loss:0.1569421599796775\n",
      "train loss:0.27692265148555195\n",
      "train loss:0.11602727038146343\n",
      "train loss:0.18327252053697518\n",
      "train loss:0.1995289998691073\n",
      "train loss:0.27066594866602434\n",
      "train loss:0.14329329252817413\n",
      "train loss:0.20076395909098288\n",
      "train loss:0.14431190350712741\n",
      "train loss:0.2153832916729146\n",
      "train loss:0.16608303875164282\n",
      "train loss:0.2674164130956349\n",
      "train loss:0.20085502557636908\n",
      "train loss:0.19966042529794614\n",
      "train loss:0.2334819759794211\n",
      "train loss:0.3070266887607389\n",
      "train loss:0.26287898199000803\n",
      "train loss:0.265738653611678\n",
      "train loss:0.19029385468213697\n",
      "train loss:0.16597593132637298\n",
      "train loss:0.1957346605733522\n",
      "train loss:0.39003394314304013\n",
      "train loss:0.18818128662630942\n",
      "train loss:0.2343388901789868\n",
      "train loss:0.0767852654586117\n",
      "train loss:0.2651882133758469\n",
      "train loss:0.2328502663541595\n",
      "train loss:0.175706328043609\n",
      "train loss:0.18266769603544167\n",
      "train loss:0.24634889625354334\n",
      "train loss:0.23371978091853535\n",
      "train loss:0.17335216810013038\n",
      "train loss:0.24955058608795508\n",
      "train loss:0.18594420888319071\n",
      "train loss:0.31197469422963814\n",
      "train loss:0.16823212493683218\n",
      "train loss:0.2622369720990802\n",
      "train loss:0.1956428521586341\n",
      "train loss:0.3221966656076517\n",
      "train loss:0.23570462323649014\n",
      "train loss:0.16939409429814414\n",
      "train loss:0.08075623219910008\n",
      "train loss:0.15937660329216816\n",
      "train loss:0.15887096959762026\n",
      "train loss:0.23075514934639302\n",
      "train loss:0.22325232044508117\n",
      "train loss:0.21549191054144162\n",
      "train loss:0.3301678294031741\n",
      "train loss:0.3186583042844119\n",
      "train loss:0.24107220740122037\n",
      "train loss:0.2066231302633546\n",
      "train loss:0.21503582152525097\n",
      "train loss:0.1444471618390138\n",
      "train loss:0.17006776289461847\n",
      "train loss:0.16990556295864997\n",
      "train loss:0.3311278704568446\n",
      "train loss:0.24331973113282288\n",
      "train loss:0.18043793387625529\n",
      "train loss:0.22884077752487245\n",
      "train loss:0.10115358309613866\n",
      "train loss:0.22086330800497206\n",
      "train loss:0.188519223976659\n",
      "train loss:0.14174489061714282\n",
      "train loss:0.22586433684619123\n",
      "train loss:0.16226427879223926\n",
      "train loss:0.21368101532824624\n",
      "train loss:0.2817803342120887\n",
      "train loss:0.253976582868758\n",
      "train loss:0.2815305880272174\n",
      "train loss:0.2829717989407559\n",
      "train loss:0.15124821028388935\n",
      "train loss:0.2328219741060057\n",
      "train loss:0.1696760030731416\n",
      "train loss:0.1681337880638862\n",
      "train loss:0.21561977969134485\n",
      "train loss:0.2782106719200679\n",
      "train loss:0.1331791054282401\n",
      "train loss:0.208693379067318\n",
      "train loss:0.17068817805131165\n",
      "train loss:0.306412668420624\n",
      "train loss:0.16543035939225992\n",
      "train loss:0.17236781313862573\n",
      "train loss:0.15487012549532223\n",
      "train loss:0.1665876811505353\n",
      "train loss:0.12086334664373868\n",
      "train loss:0.11889168221259955\n",
      "train loss:0.1292569501281925\n",
      "train loss:0.11923396440960163\n",
      "train loss:0.3078520381517577\n",
      "train loss:0.15045802098663413\n",
      "train loss:0.19847644043194712\n",
      "train loss:0.2012635179007319\n",
      "train loss:0.18170500352617416\n",
      "train loss:0.15942046170829763\n",
      "train loss:0.3116021375922362\n",
      "train loss:0.11874934903757146\n",
      "train loss:0.23996708011696083\n",
      "train loss:0.11961794324899414\n",
      "train loss:0.2695470645192484\n",
      "train loss:0.1582135930822846\n",
      "train loss:0.2639599254393069\n",
      "train loss:0.18339257805560746\n",
      "train loss:0.13214007469735187\n",
      "train loss:0.2891408492714639\n",
      "train loss:0.17627115211409766\n",
      "train loss:0.09645288364359322\n",
      "train loss:0.08605913233711317\n",
      "train loss:0.20363470111995266\n",
      "train loss:0.21926488556046794\n",
      "train loss:0.23721812229263187\n",
      "train loss:0.21319353632518087\n",
      "train loss:0.1914997816349194\n",
      "train loss:0.1618340222303798\n",
      "train loss:0.22121541606450035\n",
      "train loss:0.19953980340195757\n",
      "train loss:0.1594049164192672\n",
      "train loss:0.13669821251622058\n",
      "train loss:0.056541770245799185\n",
      "train loss:0.1752383867592146\n",
      "train loss:0.12671205588770104\n",
      "train loss:0.10752550401213215\n",
      "train loss:0.21900865042739262\n",
      "train loss:0.11467869257608809\n",
      "train loss:0.13324430148187663\n",
      "train loss:0.24009557964648626\n",
      "train loss:0.19498589997877122\n",
      "train loss:0.244952381586516\n",
      "train loss:0.1319228877616094\n",
      "train loss:0.1543139531477465\n",
      "train loss:0.13145439949535973\n",
      "train loss:0.17301223943638674\n",
      "train loss:0.09726744239547652\n",
      "train loss:0.12647551611078037\n",
      "train loss:0.1278643445194151\n",
      "train loss:0.11148147761233379\n",
      "train loss:0.22400238125037358\n",
      "train loss:0.23107599437343074\n",
      "train loss:0.10572094546352828\n",
      "train loss:0.19383018980435193\n",
      "train loss:0.2106607664666197\n",
      "train loss:0.08048972529513175\n",
      "train loss:0.19799701342434048\n",
      "train loss:0.24998430409173075\n",
      "train loss:0.10992934482640214\n",
      "train loss:0.07838118103671764\n",
      "train loss:0.11379112984449578\n",
      "train loss:0.11298054262897567\n",
      "train loss:0.2239500024974771\n",
      "train loss:0.2283585885716889\n",
      "train loss:0.12857781387191441\n",
      "train loss:0.2295900715678836\n",
      "train loss:0.19431699006854475\n",
      "train loss:0.08147992827939377\n",
      "train loss:0.1544225641152728\n",
      "train loss:0.0819955743970456\n",
      "train loss:0.11509273910156326\n",
      "train loss:0.16366306892560428\n",
      "train loss:0.1915286979116756\n",
      "train loss:0.11539805694642662\n",
      "train loss:0.09875398160618473\n",
      "train loss:0.17173188522582383\n",
      "train loss:0.16001051204954878\n",
      "train loss:0.15924137498545257\n",
      "train loss:0.14182133707102879\n",
      "train loss:0.17775171112231042\n",
      "train loss:0.18052495420190137\n",
      "train loss:0.1511511408463021\n",
      "train loss:0.12648936419529264\n",
      "train loss:0.3065931468607554\n",
      "train loss:0.2589958433443184\n",
      "train loss:0.15824056996187602\n",
      "train loss:0.09111417503377103\n",
      "train loss:0.21342654860376392\n",
      "train loss:0.2551838007299351\n",
      "train loss:0.08683324877299967\n",
      "train loss:0.18262046881272798\n",
      "train loss:0.2076537322270517\n",
      "train loss:0.20126024115226415\n",
      "train loss:0.13186942882452857\n",
      "train loss:0.26611583859381893\n",
      "train loss:0.19201874061548727\n",
      "train loss:0.1246053640459869\n",
      "train loss:0.13279990138058292\n",
      "train loss:0.13614694753300688\n",
      "train loss:0.14809603260963347\n",
      "train loss:0.2401697850829979\n",
      "train loss:0.18429173018628162\n",
      "train loss:0.19335941919506527\n",
      "train loss:0.23394190306364376\n",
      "train loss:0.1261477777800238\n",
      "train loss:0.10857146074445533\n",
      "train loss:0.27494005770730223\n",
      "train loss:0.09270412281975267\n",
      "train loss:0.08727462145883352\n",
      "train loss:0.1172356596466003\n",
      "train loss:0.21200496803487698\n",
      "train loss:0.21607023646751863\n",
      "train loss:0.11340723212321095\n",
      "train loss:0.18060684798881635\n",
      "train loss:0.13426840852771194\n",
      "train loss:0.06693189791300137\n",
      "train loss:0.13205344332802327\n",
      "train loss:0.1627803864724119\n",
      "train loss:0.11383540068925141\n",
      "train loss:0.21940212867195272\n",
      "train loss:0.16401998052149552\n",
      "train loss:0.09003666895394029\n",
      "train loss:0.19737567695755803\n",
      "train loss:0.16446212328474236\n",
      "train loss:0.2585803445755906\n",
      "train loss:0.1362507633071046\n",
      "train loss:0.1206993161364922\n",
      "train loss:0.1605352178805863\n",
      "train loss:0.13734348689365913\n",
      "train loss:0.12398884212919357\n",
      "train loss:0.10631597317106689\n",
      "train loss:0.11044403056566844\n",
      "train loss:0.10020229739430665\n",
      "train loss:0.16209310179842898\n",
      "train loss:0.17792721420382587\n",
      "train loss:0.09661405027617923\n",
      "train loss:0.17469994128320998\n",
      "train loss:0.13645694107158307\n",
      "train loss:0.23051938092756907\n",
      "train loss:0.2647595372776736\n",
      "train loss:0.08302929694219788\n",
      "train loss:0.27087779368447545\n",
      "train loss:0.11315881161568411\n",
      "train loss:0.09107877578327178\n",
      "train loss:0.08874475517380322\n",
      "train loss:0.10400134588228488\n",
      "train loss:0.08372376633803105\n",
      "train loss:0.06783065001345139\n",
      "train loss:0.04780303141149637\n",
      "train loss:0.09222036254537905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0893021596196896\n",
      "train loss:0.17734667685214606\n",
      "train loss:0.10177976077538536\n",
      "train loss:0.10893177724357164\n",
      "train loss:0.11226666872403125\n",
      "train loss:0.10734896244979715\n",
      "train loss:0.2063432128259772\n",
      "train loss:0.13173004386538595\n",
      "train loss:0.1373377528114194\n",
      "train loss:0.07785991720114831\n",
      "train loss:0.14519493617784837\n",
      "train loss:0.2102787223173228\n",
      "train loss:0.22795149206335968\n",
      "train loss:0.14432928384163957\n",
      "train loss:0.19777585610838133\n",
      "train loss:0.09392284169028949\n",
      "train loss:0.1602557294215056\n",
      "train loss:0.06325722274365439\n",
      "train loss:0.17017916188246598\n",
      "train loss:0.05734083930293279\n",
      "train loss:0.1214796064095227\n",
      "train loss:0.11310890501675848\n",
      "train loss:0.16996167241694324\n",
      "train loss:0.15929288675123304\n",
      "train loss:0.1507998517795285\n",
      "train loss:0.15808905656492628\n",
      "train loss:0.11661941781251722\n",
      "train loss:0.1938973219134429\n",
      "train loss:0.1419668053399952\n",
      "train loss:0.24145523015837195\n",
      "train loss:0.0856574186051226\n",
      "train loss:0.16299851770850718\n",
      "train loss:0.14659728353503548\n",
      "train loss:0.05093831669970572\n",
      "train loss:0.08168884064834556\n",
      "train loss:0.15035969674719618\n",
      "train loss:0.1570647446687782\n",
      "train loss:0.10795067718672692\n",
      "train loss:0.17940167393075115\n",
      "train loss:0.11122283474331911\n",
      "train loss:0.10155881086340177\n",
      "train loss:0.08717432276613893\n",
      "train loss:0.1808971295246811\n",
      "train loss:0.11771554932274306\n",
      "train loss:0.16972030534190805\n",
      "train loss:0.08925457452788665\n",
      "train loss:0.08032538088588334\n",
      "train loss:0.15085517132920495\n",
      "train loss:0.14296093252544984\n",
      "train loss:0.10964473878014636\n",
      "train loss:0.10822360279156769\n",
      "train loss:0.13589377245124865\n",
      "train loss:0.09619249160568763\n",
      "train loss:0.178589303666066\n",
      "train loss:0.180527438662454\n",
      "train loss:0.24419543140037214\n",
      "train loss:0.15964481003220884\n",
      "train loss:0.1782085240110178\n",
      "train loss:0.15113512690967004\n",
      "train loss:0.04408335946603239\n",
      "train loss:0.15507097884255786\n",
      "train loss:0.0694974826124062\n",
      "train loss:0.191003093411165\n",
      "=== epoch:2, train acc:0.957, test acc:0.96 ===\n",
      "train loss:0.1330858337736137\n",
      "train loss:0.19452549671930058\n",
      "train loss:0.11946333797039072\n",
      "train loss:0.10145262402657484\n",
      "train loss:0.19713340112682265\n",
      "train loss:0.06446300310629444\n",
      "train loss:0.08227363863918571\n",
      "train loss:0.116722301219406\n",
      "train loss:0.08888567601226889\n",
      "train loss:0.15037260798434574\n",
      "train loss:0.07074468636211974\n",
      "train loss:0.06344150536726124\n",
      "train loss:0.29172571224870497\n",
      "train loss:0.08072268536200904\n",
      "train loss:0.15946443795021514\n",
      "train loss:0.18965116501066695\n",
      "train loss:0.06572049542188525\n",
      "train loss:0.09262712092805671\n",
      "train loss:0.07433346782808649\n",
      "train loss:0.17991337444198696\n",
      "train loss:0.09630685663906854\n",
      "train loss:0.06568505695223659\n",
      "train loss:0.09466831324162191\n",
      "train loss:0.04467089161631148\n",
      "train loss:0.10099306233670621\n",
      "train loss:0.10985974554093471\n",
      "train loss:0.08555599916118574\n",
      "train loss:0.10129272069611844\n",
      "train loss:0.07763925670643117\n",
      "train loss:0.15204704480784006\n",
      "train loss:0.10908546127757164\n",
      "train loss:0.08467682417057219\n",
      "train loss:0.061769845423311674\n",
      "train loss:0.09378106236589048\n",
      "train loss:0.07298346791405502\n",
      "train loss:0.1069347221605315\n",
      "train loss:0.05773480494162225\n",
      "train loss:0.04313594692376871\n",
      "train loss:0.17757815380928807\n",
      "train loss:0.16962882316179598\n",
      "train loss:0.17694468622958662\n",
      "train loss:0.11734365804412074\n",
      "train loss:0.15889919018601786\n",
      "train loss:0.1350255501831915\n",
      "train loss:0.058190409678446596\n",
      "train loss:0.09347341157097679\n",
      "train loss:0.09051491103950043\n",
      "train loss:0.16466121827114158\n",
      "train loss:0.1393824412835674\n",
      "train loss:0.15313704493993957\n",
      "train loss:0.1491577406691267\n",
      "train loss:0.05138157763930146\n",
      "train loss:0.14720684696569195\n",
      "train loss:0.13640297834462817\n",
      "train loss:0.12472433521266411\n",
      "train loss:0.05376396549137124\n",
      "train loss:0.1991212399394031\n",
      "train loss:0.1734059619304783\n",
      "train loss:0.15787529412227555\n",
      "train loss:0.12752955587327316\n",
      "train loss:0.2021172421846738\n",
      "train loss:0.05506158293687837\n",
      "train loss:0.07145319923687088\n",
      "train loss:0.11867207722264692\n",
      "train loss:0.12434922533999185\n",
      "train loss:0.0765783499635955\n",
      "train loss:0.07550506646706143\n",
      "train loss:0.13297017538935965\n",
      "train loss:0.09931362568009167\n",
      "train loss:0.09304934140932831\n",
      "train loss:0.06631221881295918\n",
      "train loss:0.09044276457510828\n",
      "train loss:0.12463958914364932\n",
      "train loss:0.0431629244219602\n",
      "train loss:0.15672017360483165\n",
      "train loss:0.0843501567461996\n",
      "train loss:0.06317623787298415\n",
      "train loss:0.09460037184269832\n",
      "train loss:0.0623299041208412\n",
      "train loss:0.06767160325591565\n",
      "train loss:0.20620998910411648\n",
      "train loss:0.09464974306558767\n",
      "train loss:0.14690939360428576\n",
      "train loss:0.13163293892658517\n",
      "train loss:0.06262160117517519\n",
      "train loss:0.10038122893079976\n",
      "train loss:0.09574788002938954\n",
      "train loss:0.10912087515393719\n",
      "train loss:0.09153916748850499\n",
      "train loss:0.1133905752069348\n",
      "train loss:0.15857203536395795\n",
      "train loss:0.035192144609284\n",
      "train loss:0.17620310276815718\n",
      "train loss:0.0475791735211941\n",
      "train loss:0.1450006407111424\n",
      "train loss:0.0986520023989889\n",
      "train loss:0.1278966329626581\n",
      "train loss:0.08649363844081895\n",
      "train loss:0.1521609999451263\n",
      "train loss:0.055339904467412236\n",
      "train loss:0.07934145223710602\n",
      "train loss:0.1182209196194342\n",
      "train loss:0.11325985522701401\n",
      "train loss:0.12548933896768258\n",
      "train loss:0.10257647743057528\n",
      "train loss:0.09020968819158902\n",
      "train loss:0.05098248252166109\n",
      "train loss:0.06615851912758916\n",
      "train loss:0.16269467179672886\n",
      "train loss:0.07772801480206552\n",
      "train loss:0.07985152947317045\n",
      "train loss:0.12373625467029281\n",
      "train loss:0.07711029613223375\n",
      "train loss:0.08927632071165606\n",
      "train loss:0.19715274866771637\n",
      "train loss:0.10144026874189133\n",
      "train loss:0.04524817262228166\n",
      "train loss:0.14311570004905008\n",
      "train loss:0.18138159535740964\n",
      "train loss:0.17630748509095462\n",
      "train loss:0.07283151566572758\n",
      "train loss:0.12937530832189326\n",
      "train loss:0.0734059046867337\n",
      "train loss:0.11362284533071308\n",
      "train loss:0.11281589152165893\n",
      "train loss:0.04532253593178917\n",
      "train loss:0.07938696874012095\n",
      "train loss:0.08201860041044627\n",
      "train loss:0.18778396971939343\n",
      "train loss:0.07972796750655815\n",
      "train loss:0.12648866065255016\n",
      "train loss:0.12272961925143608\n",
      "train loss:0.0718661478512095\n",
      "train loss:0.12321121125701297\n",
      "train loss:0.09963276917666143\n",
      "train loss:0.18910904615799443\n",
      "train loss:0.12116719145512324\n",
      "train loss:0.06173857035496535\n",
      "train loss:0.04051763346205123\n",
      "train loss:0.0762860062487746\n",
      "train loss:0.13758169937446424\n",
      "train loss:0.12344441668613325\n",
      "train loss:0.14687077739630888\n",
      "train loss:0.20188057401314422\n",
      "train loss:0.04410129995839787\n",
      "train loss:0.10099502500452223\n",
      "train loss:0.21266065990135036\n",
      "train loss:0.07581340608801443\n",
      "train loss:0.06926652395670421\n",
      "train loss:0.13412726735361186\n",
      "train loss:0.04865299107391092\n",
      "train loss:0.0647137595792514\n",
      "train loss:0.1501801005032374\n",
      "train loss:0.0905161068211868\n",
      "train loss:0.07827384007428258\n",
      "train loss:0.21501526133525178\n",
      "train loss:0.16673054011536345\n",
      "train loss:0.06487283522445914\n",
      "train loss:0.054827074436635904\n",
      "train loss:0.10836145862758624\n",
      "train loss:0.06844411407701777\n",
      "train loss:0.08547109242017659\n",
      "train loss:0.10685345218744953\n",
      "train loss:0.028979130813511292\n",
      "train loss:0.10306338158554086\n",
      "train loss:0.10294405615275791\n",
      "train loss:0.17638422535526865\n",
      "train loss:0.09572466544061918\n",
      "train loss:0.05647386270928251\n",
      "train loss:0.12260557623714774\n",
      "train loss:0.07092200477985826\n",
      "train loss:0.05597349061139777\n",
      "train loss:0.03285134783092852\n",
      "train loss:0.19666405862691544\n",
      "train loss:0.04591618151436817\n",
      "train loss:0.09216036615691214\n",
      "train loss:0.09542547013673994\n",
      "train loss:0.10739199816499888\n",
      "train loss:0.09078037685024248\n",
      "train loss:0.05089497007577148\n",
      "train loss:0.12030949257585725\n",
      "train loss:0.04826177794668671\n",
      "train loss:0.08732201190686681\n",
      "train loss:0.07923340725872773\n",
      "train loss:0.11928118674364477\n",
      "train loss:0.13690894370725787\n",
      "train loss:0.08083945832335447\n",
      "train loss:0.2801714664184388\n",
      "train loss:0.1069511415011607\n",
      "train loss:0.0673905189347383\n",
      "train loss:0.06872134423794693\n",
      "train loss:0.09199668084417567\n",
      "train loss:0.0636582813010296\n",
      "train loss:0.05696427631076439\n",
      "train loss:0.09277727289456435\n",
      "train loss:0.12524213083057348\n",
      "train loss:0.12869596893152338\n",
      "train loss:0.15790552520242251\n",
      "train loss:0.1157527445631183\n",
      "train loss:0.13224483922165903\n",
      "train loss:0.06817273620594827\n",
      "train loss:0.04331966941294595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.05942289333635248\n",
      "train loss:0.058612629944473735\n",
      "train loss:0.15785933580736966\n",
      "train loss:0.13552151979020113\n",
      "train loss:0.0745994716962518\n",
      "train loss:0.14444370048235008\n",
      "train loss:0.1023878279276545\n",
      "train loss:0.07592047056630276\n",
      "train loss:0.03392128928469344\n",
      "train loss:0.06949473061409547\n",
      "train loss:0.0959606063897749\n",
      "train loss:0.06800750810324036\n",
      "train loss:0.09913766695094652\n",
      "train loss:0.059589431066004755\n",
      "train loss:0.06447187645378555\n",
      "train loss:0.15121312049468874\n",
      "train loss:0.09002280073626816\n",
      "train loss:0.0749958923069029\n",
      "train loss:0.0704269566304998\n",
      "train loss:0.037692728714187634\n",
      "train loss:0.10976579044660958\n",
      "train loss:0.05782354281849421\n",
      "train loss:0.09487965463287981\n",
      "train loss:0.061920575470556606\n",
      "train loss:0.0719699713255471\n",
      "train loss:0.12159622152794304\n",
      "train loss:0.12414021590065648\n",
      "train loss:0.10820153819809311\n",
      "train loss:0.07938172104438865\n",
      "train loss:0.08199654335044462\n",
      "train loss:0.12379891607415408\n",
      "train loss:0.027885726462116858\n",
      "train loss:0.1434897296851937\n",
      "train loss:0.05773444305469865\n",
      "train loss:0.10814839403410816\n",
      "train loss:0.14460429309175554\n",
      "train loss:0.07309857131135798\n",
      "train loss:0.13578432600251691\n",
      "train loss:0.10239124573900364\n",
      "train loss:0.05417659382348162\n",
      "train loss:0.03467426028019283\n",
      "train loss:0.09026505449950867\n",
      "train loss:0.05425838271641577\n",
      "train loss:0.04121738143943645\n",
      "train loss:0.0976819541937462\n",
      "train loss:0.058852616727768134\n",
      "train loss:0.13017734329455943\n",
      "train loss:0.03490433815001446\n",
      "train loss:0.10534797706965843\n",
      "train loss:0.046777619879380235\n",
      "train loss:0.13251908634836623\n",
      "train loss:0.1439019103155476\n",
      "train loss:0.047248802752280966\n",
      "train loss:0.11750833079366332\n",
      "train loss:0.05362059437471945\n",
      "train loss:0.031596581587607024\n",
      "train loss:0.05934034646780234\n",
      "train loss:0.03655926930687713\n",
      "train loss:0.12749909187011588\n",
      "train loss:0.09048705484487182\n",
      "train loss:0.05803132567784962\n",
      "train loss:0.13954687152647613\n",
      "train loss:0.04543825767672023\n",
      "train loss:0.0649472365496389\n",
      "train loss:0.0358718169161383\n",
      "train loss:0.10163865990901315\n",
      "train loss:0.0218858636488116\n",
      "train loss:0.08026876953025278\n",
      "train loss:0.10609113664696025\n",
      "train loss:0.09278336094532083\n",
      "train loss:0.07113448381467036\n",
      "train loss:0.09437630041581226\n",
      "train loss:0.06629783361756225\n",
      "train loss:0.04385048336556224\n",
      "train loss:0.07813375289844322\n",
      "train loss:0.06373128727719181\n",
      "train loss:0.08839636396793017\n",
      "train loss:0.030347153715344292\n",
      "train loss:0.04064602281968257\n",
      "train loss:0.09374443524028937\n",
      "train loss:0.0923746952889023\n",
      "train loss:0.09356944802866042\n",
      "train loss:0.14141278118517245\n",
      "train loss:0.06377462168304927\n",
      "train loss:0.04800252973638742\n",
      "train loss:0.08509760520568911\n",
      "train loss:0.04936719525103524\n",
      "train loss:0.05553770721006481\n",
      "train loss:0.07136586932055489\n",
      "train loss:0.09599561454708784\n",
      "train loss:0.04865815462780859\n",
      "train loss:0.08886793094877417\n",
      "train loss:0.08528932658506784\n",
      "train loss:0.08458519815435013\n",
      "train loss:0.14449677573336792\n",
      "train loss:0.08376640300146315\n",
      "train loss:0.1798425213894265\n",
      "train loss:0.08544656653822635\n",
      "train loss:0.09200989443459179\n",
      "train loss:0.11688149081098052\n",
      "train loss:0.04225957532102258\n",
      "train loss:0.09804723546892438\n",
      "train loss:0.15304903606994677\n",
      "train loss:0.06918866347290187\n",
      "train loss:0.12146193671805879\n",
      "train loss:0.1927608312656521\n",
      "train loss:0.09261123335185609\n",
      "train loss:0.060807801092319626\n",
      "train loss:0.032162020862852914\n",
      "train loss:0.0780982568615077\n",
      "train loss:0.10155212351544086\n",
      "train loss:0.09489971499526208\n",
      "train loss:0.16595831540970077\n",
      "train loss:0.04169077257725618\n",
      "train loss:0.12993400361978913\n",
      "train loss:0.06635021293980164\n",
      "train loss:0.06277353647321557\n",
      "train loss:0.041707151500628495\n",
      "train loss:0.16078532896666636\n",
      "train loss:0.04339800233890998\n",
      "train loss:0.09670497503897012\n",
      "train loss:0.0989247089552998\n",
      "train loss:0.07809904459392843\n",
      "train loss:0.09791143118723264\n",
      "train loss:0.07229961404881935\n",
      "train loss:0.17816852674289385\n",
      "train loss:0.08047520728363951\n",
      "train loss:0.09984309960577029\n",
      "train loss:0.06661957898388121\n",
      "train loss:0.04139496604368675\n",
      "train loss:0.0480339342203784\n",
      "train loss:0.07251076564471833\n",
      "train loss:0.08082500274128286\n",
      "train loss:0.06329951679229005\n",
      "train loss:0.06494218535097168\n",
      "train loss:0.09596912881205365\n",
      "train loss:0.05393855953340978\n",
      "train loss:0.045144115957714434\n",
      "train loss:0.12113944041373642\n",
      "train loss:0.04447430956734659\n",
      "train loss:0.07030261092807798\n",
      "train loss:0.0754493637967589\n",
      "train loss:0.1433537112584784\n",
      "train loss:0.09406757175199959\n",
      "train loss:0.030279874158336967\n",
      "train loss:0.03997636151187066\n",
      "train loss:0.047967283455855464\n",
      "train loss:0.09690404548747188\n",
      "train loss:0.039987955731421956\n",
      "train loss:0.10921743177128915\n",
      "train loss:0.08671082011913775\n",
      "train loss:0.06730072344054577\n",
      "train loss:0.05562349754860781\n",
      "train loss:0.09302802241839511\n",
      "train loss:0.03601917751058978\n",
      "train loss:0.0937485806040849\n",
      "train loss:0.11743151917864574\n",
      "train loss:0.14032621285027091\n",
      "train loss:0.03227353172461388\n",
      "train loss:0.07941576288501687\n",
      "train loss:0.02624417230867076\n",
      "train loss:0.08245182770099577\n",
      "train loss:0.05445817318474014\n",
      "train loss:0.07714930488237591\n",
      "train loss:0.04551956746947116\n",
      "train loss:0.17699590058210346\n",
      "train loss:0.0451163808967093\n",
      "train loss:0.09816659778619778\n",
      "train loss:0.040584548133640715\n",
      "train loss:0.16797762641150482\n",
      "train loss:0.028159764928475117\n",
      "train loss:0.09560731705586685\n",
      "train loss:0.09011977105950324\n",
      "train loss:0.03849498467969314\n",
      "train loss:0.0615844985477871\n",
      "train loss:0.029632711815250595\n",
      "train loss:0.04977059286032232\n",
      "train loss:0.08017167996610737\n",
      "train loss:0.1083049814467042\n",
      "train loss:0.04672092606961905\n",
      "train loss:0.17793189326921066\n",
      "train loss:0.04652734676994272\n",
      "train loss:0.026273047942104177\n",
      "train loss:0.06362104931451727\n",
      "train loss:0.0953709162807633\n",
      "train loss:0.064738857112062\n",
      "train loss:0.060066108602576655\n",
      "train loss:0.07717994513070194\n",
      "train loss:0.10644856412082211\n",
      "train loss:0.046247614957832625\n",
      "train loss:0.029627779712163203\n",
      "train loss:0.07387620145324866\n",
      "train loss:0.08658226509302588\n",
      "train loss:0.05235984230824982\n",
      "train loss:0.052348971219071144\n",
      "train loss:0.04436248001994908\n",
      "train loss:0.07673898714701628\n",
      "train loss:0.11008909868124206\n",
      "train loss:0.04817898790203756\n",
      "train loss:0.06376569841496012\n",
      "train loss:0.10345008831714425\n",
      "train loss:0.07166933787501596\n",
      "train loss:0.11092998596849943\n",
      "train loss:0.06715106534011421\n",
      "train loss:0.04736003055272582\n",
      "train loss:0.03242932079785087\n",
      "train loss:0.11025629541257453\n",
      "train loss:0.04495086493359937\n",
      "train loss:0.07114971178912795\n",
      "train loss:0.0341477189564632\n",
      "train loss:0.07154749227813496\n",
      "train loss:0.046555071753220656\n",
      "train loss:0.07657258612790034\n",
      "train loss:0.031833430269136015\n",
      "train loss:0.032451520845037926\n",
      "train loss:0.0819217872774887\n",
      "train loss:0.05578625849028725\n",
      "train loss:0.13105724362190618\n",
      "train loss:0.04079350907861398\n",
      "train loss:0.05220359320187304\n",
      "train loss:0.0911722816579947\n",
      "train loss:0.08795445052545295\n",
      "train loss:0.04394529919782839\n",
      "train loss:0.02299311720260123\n",
      "train loss:0.12220767119869339\n",
      "train loss:0.0867354479421585\n",
      "train loss:0.044832935278162435\n",
      "train loss:0.030611392160545717\n",
      "train loss:0.05238849241480412\n",
      "train loss:0.03891122219538424\n",
      "train loss:0.037081670174628815\n",
      "train loss:0.07208951972417452\n",
      "train loss:0.04009783624906251\n",
      "train loss:0.04346270708432589\n",
      "train loss:0.02265918462182407\n",
      "train loss:0.025145139452815646\n",
      "train loss:0.03859407185310972\n",
      "train loss:0.040190955148277224\n",
      "train loss:0.043993990074040014\n",
      "train loss:0.03474478516143402\n",
      "train loss:0.056173525294376005\n",
      "train loss:0.060522652308340204\n",
      "train loss:0.04262019816388847\n",
      "train loss:0.03797527220348433\n",
      "train loss:0.051200331091063214\n",
      "train loss:0.05326801054830376\n",
      "train loss:0.033557619324406665\n",
      "train loss:0.06996976387502482\n",
      "train loss:0.08306989093399757\n",
      "train loss:0.07253820077990213\n",
      "train loss:0.06725386300846735\n",
      "train loss:0.07281838009219528\n",
      "train loss:0.11446295570870109\n",
      "train loss:0.059669068443891485\n",
      "train loss:0.016459937830029314\n",
      "train loss:0.05443647335771207\n",
      "train loss:0.036934405333353834\n",
      "train loss:0.07877992828228826\n",
      "train loss:0.03475626919089689\n",
      "train loss:0.041269227151790995\n",
      "train loss:0.03986421175000503\n",
      "train loss:0.13902898998866728\n",
      "train loss:0.03031163624368904\n",
      "train loss:0.0330407128750019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.08564662938787393\n",
      "train loss:0.0395420943283913\n",
      "train loss:0.03486919888403093\n",
      "train loss:0.07872253909094205\n",
      "train loss:0.20259900176133253\n",
      "train loss:0.048437775288004976\n",
      "train loss:0.10062626499028188\n",
      "train loss:0.045725316371582225\n",
      "train loss:0.061504692877559816\n",
      "train loss:0.06563482510151798\n",
      "train loss:0.04870272947355469\n",
      "train loss:0.10236632258605174\n",
      "train loss:0.05966683322614359\n",
      "train loss:0.07196084114356321\n",
      "train loss:0.05663270664253088\n",
      "train loss:0.20216967328429614\n",
      "train loss:0.05594714029630408\n",
      "train loss:0.11001248588898306\n",
      "train loss:0.039802073502008616\n",
      "train loss:0.07887983120829795\n",
      "train loss:0.05460510026638921\n",
      "train loss:0.21936358273649634\n",
      "train loss:0.10494287227476985\n",
      "train loss:0.09845425031884432\n",
      "train loss:0.036074397821344285\n",
      "train loss:0.054609075692543065\n",
      "train loss:0.036306995486857487\n",
      "train loss:0.04102208272867518\n",
      "train loss:0.09026743761502617\n",
      "train loss:0.1561413918439305\n",
      "train loss:0.07049549255243358\n",
      "train loss:0.027036879677043067\n",
      "train loss:0.03904913889181217\n",
      "train loss:0.046505498514474074\n",
      "train loss:0.024177645647073517\n",
      "train loss:0.04993179808043102\n",
      "train loss:0.035707802417382715\n",
      "train loss:0.05552651927620346\n",
      "train loss:0.15059648634218098\n",
      "train loss:0.10373195365370153\n",
      "train loss:0.09520006732277991\n",
      "train loss:0.03216857299014037\n",
      "train loss:0.06238556570313089\n",
      "train loss:0.06961443715525718\n",
      "train loss:0.1465935368752474\n",
      "train loss:0.05256168347803393\n",
      "train loss:0.11947406405477548\n",
      "train loss:0.03660986413973438\n",
      "train loss:0.0293705165410249\n",
      "train loss:0.09018096158588808\n",
      "train loss:0.05714848317909894\n",
      "train loss:0.07022350496200992\n",
      "train loss:0.06465106555193699\n",
      "train loss:0.035156589893680125\n",
      "train loss:0.2067697617549459\n",
      "train loss:0.030974529974856085\n",
      "train loss:0.0642073901585478\n",
      "train loss:0.052381660140069515\n",
      "train loss:0.05936541370219825\n",
      "train loss:0.024372408740046935\n",
      "train loss:0.06300795306614021\n",
      "train loss:0.13281724064825196\n",
      "train loss:0.01726613068216972\n",
      "train loss:0.05754369415240526\n",
      "train loss:0.0511291973894901\n",
      "train loss:0.052793928610854086\n",
      "train loss:0.07273585493602329\n",
      "train loss:0.07778000023650514\n",
      "train loss:0.04295124308967241\n",
      "train loss:0.032049156858422204\n",
      "train loss:0.059417414734289624\n",
      "train loss:0.09632022227849597\n",
      "train loss:0.07606615886666714\n",
      "train loss:0.034356737817040336\n",
      "train loss:0.17218732456477998\n",
      "train loss:0.08590710092251624\n",
      "train loss:0.08068294795376053\n",
      "train loss:0.07014832029656944\n",
      "train loss:0.06363197596563192\n",
      "train loss:0.048112271350255205\n",
      "train loss:0.06936261200768522\n",
      "train loss:0.12169757448837167\n",
      "train loss:0.03042092159929797\n",
      "train loss:0.04430398885743715\n",
      "train loss:0.04627841875669184\n",
      "train loss:0.059830870181662235\n",
      "train loss:0.045873684951250576\n",
      "train loss:0.052511796946287846\n",
      "train loss:0.07135888337781847\n",
      "train loss:0.11400272430238413\n",
      "train loss:0.06757132845954078\n",
      "train loss:0.03925062491752532\n",
      "train loss:0.032517681329453374\n",
      "train loss:0.07737362710760498\n",
      "train loss:0.02285439926205996\n",
      "train loss:0.08967736282728435\n",
      "train loss:0.022117568359515272\n",
      "train loss:0.03443709541986109\n",
      "train loss:0.07026593629046729\n",
      "train loss:0.03331397600220174\n",
      "train loss:0.08599631467064432\n",
      "train loss:0.036892449345885814\n",
      "train loss:0.04463413162547671\n",
      "train loss:0.0625346885758387\n",
      "train loss:0.042537103426111826\n",
      "train loss:0.10316659408581925\n",
      "train loss:0.09536654766402647\n",
      "train loss:0.042778306455868324\n",
      "train loss:0.04569522987622625\n",
      "train loss:0.03810155123353645\n",
      "train loss:0.04745704792901331\n",
      "train loss:0.017575843068745947\n",
      "train loss:0.014097514208188257\n",
      "train loss:0.02956088170868118\n",
      "train loss:0.039874044409036496\n",
      "train loss:0.08881238782362721\n",
      "train loss:0.0725797451363978\n",
      "train loss:0.07065148604883902\n",
      "train loss:0.06448979615831149\n",
      "train loss:0.03559799344699208\n",
      "train loss:0.056631531867020815\n",
      "train loss:0.043774345604600286\n",
      "train loss:0.06796685912162921\n",
      "train loss:0.044551087633486676\n",
      "train loss:0.02956416530873379\n",
      "train loss:0.08451219721170229\n",
      "train loss:0.0223193322772044\n",
      "train loss:0.06378158045072325\n",
      "train loss:0.07436457892802455\n",
      "train loss:0.04599857973359264\n",
      "train loss:0.02112091994187969\n",
      "train loss:0.04029033080632976\n",
      "train loss:0.09548740230571645\n",
      "train loss:0.06552951726725702\n",
      "=== epoch:3, train acc:0.977, test acc:0.975 ===\n",
      "train loss:0.03746087551653156\n",
      "train loss:0.1313780512642337\n",
      "train loss:0.08763937602246165\n",
      "train loss:0.14300417146295907\n",
      "train loss:0.017226480620795202\n",
      "train loss:0.06025440904019832\n",
      "train loss:0.03323580417565836\n",
      "train loss:0.05418323493155694\n",
      "train loss:0.03753347566315956\n",
      "train loss:0.02725881579132802\n",
      "train loss:0.04448205525364272\n",
      "train loss:0.045051308345082586\n",
      "train loss:0.03346827737815073\n",
      "train loss:0.04233233167411507\n",
      "train loss:0.09373708804923415\n",
      "train loss:0.0546558089848094\n",
      "train loss:0.06415594045389106\n",
      "train loss:0.018340455876400114\n",
      "train loss:0.05903529258095677\n",
      "train loss:0.038341454953510955\n",
      "train loss:0.1548405616584294\n",
      "train loss:0.02927736700440624\n",
      "train loss:0.021760760870721395\n",
      "train loss:0.12903270890380913\n",
      "train loss:0.0477791266358974\n",
      "train loss:0.0570901103133395\n",
      "train loss:0.018469923644850353\n",
      "train loss:0.13010011939576255\n",
      "train loss:0.07623631694198364\n",
      "train loss:0.10094759901745574\n",
      "train loss:0.0419071455002406\n",
      "train loss:0.07294119940362226\n",
      "train loss:0.07213938536314765\n",
      "train loss:0.054022737645828905\n",
      "train loss:0.08905026582794137\n",
      "train loss:0.02038085981652904\n",
      "train loss:0.03845106813844735\n",
      "train loss:0.030888151205221676\n",
      "train loss:0.0245330567387195\n",
      "train loss:0.06792640358247039\n",
      "train loss:0.12796337479502967\n",
      "train loss:0.17313138004921616\n",
      "train loss:0.03772678587829382\n",
      "train loss:0.037885459939557796\n",
      "train loss:0.02104724241010125\n",
      "train loss:0.02037864034861494\n",
      "train loss:0.04825247575941544\n",
      "train loss:0.06305258696755225\n",
      "train loss:0.12180415130617357\n",
      "train loss:0.07267525878578757\n",
      "train loss:0.11367346342454572\n",
      "train loss:0.03343270116058898\n",
      "train loss:0.0854109520673388\n",
      "train loss:0.05924867205963524\n",
      "train loss:0.07242678286145993\n",
      "train loss:0.03638650967112\n",
      "train loss:0.02684582433340978\n",
      "train loss:0.07171096205882567\n",
      "train loss:0.06356477203771141\n",
      "train loss:0.044745374072157416\n",
      "train loss:0.02774820325711147\n",
      "train loss:0.03218281555439369\n",
      "train loss:0.07583981130912978\n",
      "train loss:0.040110051001182194\n",
      "train loss:0.08652160944058536\n",
      "train loss:0.05781643979675688\n",
      "train loss:0.07334529228612387\n",
      "train loss:0.07579596686109526\n",
      "train loss:0.10357504640330294\n",
      "train loss:0.046091371780199945\n",
      "train loss:0.07112608469984986\n",
      "train loss:0.06990937028477542\n",
      "train loss:0.08095102440139951\n",
      "train loss:0.05283590385782846\n",
      "train loss:0.15813388372541953\n",
      "train loss:0.02042872643627972\n",
      "train loss:0.07552951000479743\n",
      "train loss:0.1803083672307779\n",
      "train loss:0.12079030483971984\n",
      "train loss:0.03530860934888473\n",
      "train loss:0.0363780030569824\n",
      "train loss:0.09118295201891001\n",
      "train loss:0.075105036361157\n",
      "train loss:0.02952387575700482\n",
      "train loss:0.06169509082529106\n",
      "train loss:0.10407559983997196\n",
      "train loss:0.031340695134242674\n",
      "train loss:0.040369545322912835\n",
      "train loss:0.055498548334178714\n",
      "train loss:0.05258080974202538\n",
      "train loss:0.06668940297599303\n",
      "train loss:0.08044487916841395\n",
      "train loss:0.06976137736699524\n",
      "train loss:0.040193822146511675\n",
      "train loss:0.06093869127691369\n",
      "train loss:0.07986250278423221\n",
      "train loss:0.019686821873664523\n",
      "train loss:0.04706557686557619\n",
      "train loss:0.08745429195413555\n",
      "train loss:0.042724807922014225\n",
      "train loss:0.02232599658604225\n",
      "train loss:0.0710839034829809\n",
      "train loss:0.015665909523629576\n",
      "train loss:0.05053152062846931\n",
      "train loss:0.0381204819485941\n",
      "train loss:0.018145897352363792\n",
      "train loss:0.10946619374809781\n",
      "train loss:0.07543371759148168\n",
      "train loss:0.03178838216032048\n",
      "train loss:0.0484462051848515\n",
      "train loss:0.03179144943616754\n",
      "train loss:0.008210982471961802\n",
      "train loss:0.0249903192302926\n",
      "train loss:0.032413663186033885\n",
      "train loss:0.08170501459622866\n",
      "train loss:0.13993429604246085\n",
      "train loss:0.06301040024158086\n",
      "train loss:0.06377046030951317\n",
      "train loss:0.05415994523702187\n",
      "train loss:0.021648304565210733\n",
      "train loss:0.019453969167780374\n",
      "train loss:0.09575623329382887\n",
      "train loss:0.02346937300897437\n",
      "train loss:0.08057596766289862\n",
      "train loss:0.03561753359470277\n",
      "train loss:0.067267142165219\n",
      "train loss:0.06819594204818397\n",
      "train loss:0.10420125641667231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.052476184880014515\n",
      "train loss:0.07279440936878995\n",
      "train loss:0.06525331918557026\n",
      "train loss:0.0634399356592845\n",
      "train loss:0.026431729563092733\n",
      "train loss:0.13520980732548193\n",
      "train loss:0.08967162148563579\n",
      "train loss:0.06682913087179898\n",
      "train loss:0.11180769203226584\n",
      "train loss:0.044845207614531556\n",
      "train loss:0.03501943418841815\n",
      "train loss:0.0314906224633877\n",
      "train loss:0.05020358741030201\n",
      "train loss:0.04571636780002436\n",
      "train loss:0.12567379393616912\n",
      "train loss:0.045945192567711984\n",
      "train loss:0.062171566701898204\n",
      "train loss:0.10780348386609238\n",
      "train loss:0.05775550430055794\n",
      "train loss:0.029531947837835845\n",
      "train loss:0.05007836666108749\n",
      "train loss:0.07603528964362438\n",
      "train loss:0.15327803417030872\n",
      "train loss:0.13568299757424235\n",
      "train loss:0.05324596074976559\n",
      "train loss:0.04583174393102899\n",
      "train loss:0.06619969397956492\n",
      "train loss:0.09379593502235979\n",
      "train loss:0.02431364475419638\n",
      "train loss:0.1094538518656892\n",
      "train loss:0.07595763523888883\n",
      "train loss:0.06570381151582536\n",
      "train loss:0.026198539433606945\n",
      "train loss:0.11106760845443249\n",
      "train loss:0.043352641356831645\n",
      "train loss:0.07696085953220418\n",
      "train loss:0.10516092640537296\n",
      "train loss:0.05431436397982203\n",
      "train loss:0.03575830318408077\n",
      "train loss:0.07443780289252794\n",
      "train loss:0.02825747398762796\n",
      "train loss:0.04146439076727277\n",
      "train loss:0.06246674719337478\n",
      "train loss:0.04392085089967383\n",
      "train loss:0.05311811767893464\n",
      "train loss:0.02422215103338922\n",
      "train loss:0.0875407850457\n",
      "train loss:0.04763726158401952\n",
      "train loss:0.07482996344729091\n",
      "train loss:0.05531848740316524\n",
      "train loss:0.054585984170187875\n",
      "train loss:0.07083980762919291\n",
      "train loss:0.03503260720456802\n",
      "train loss:0.04626565402243345\n",
      "train loss:0.055942284475774554\n",
      "train loss:0.022658698851945977\n",
      "train loss:0.03901551725830269\n",
      "train loss:0.02639502923043974\n",
      "train loss:0.07038651888761312\n",
      "train loss:0.049805587082240574\n",
      "train loss:0.02496925641809623\n",
      "train loss:0.07990606964595597\n",
      "train loss:0.028024171317599468\n",
      "train loss:0.061202075296734514\n",
      "train loss:0.09420450075448096\n",
      "train loss:0.03956020760820488\n",
      "train loss:0.024311338628695965\n",
      "train loss:0.025814077412174178\n",
      "train loss:0.05613856677700418\n",
      "train loss:0.04433592294514835\n",
      "train loss:0.02444616511312238\n",
      "train loss:0.08392704990753669\n",
      "train loss:0.05829207644743195\n",
      "train loss:0.02389752555152576\n",
      "train loss:0.11787684986307882\n",
      "train loss:0.07783714117000949\n",
      "train loss:0.020419462947234006\n",
      "train loss:0.12030637282449218\n",
      "train loss:0.11481711723190224\n",
      "train loss:0.04847439578627763\n",
      "train loss:0.05203582975043431\n",
      "train loss:0.04996336229348812\n",
      "train loss:0.035548010641344975\n",
      "train loss:0.05139076504629112\n",
      "train loss:0.021601496547279452\n",
      "train loss:0.08163591883570395\n",
      "train loss:0.12024775657503012\n",
      "train loss:0.027687632185762402\n",
      "train loss:0.054017559113701596\n",
      "train loss:0.07626032678289181\n",
      "train loss:0.09166164407262269\n",
      "train loss:0.014614443461080458\n",
      "train loss:0.019330059393213667\n",
      "train loss:0.04831380820091519\n",
      "train loss:0.0836931668370736\n",
      "train loss:0.037247357981729894\n",
      "train loss:0.04027951795673145\n",
      "train loss:0.022736125130141907\n",
      "train loss:0.06857355682948162\n",
      "train loss:0.06140822288894498\n",
      "train loss:0.01598283195840616\n",
      "train loss:0.029785876391786394\n",
      "train loss:0.018009551537423372\n",
      "train loss:0.05746747584172473\n",
      "train loss:0.031443049012924516\n",
      "train loss:0.0609791387174747\n",
      "train loss:0.11171362321012486\n",
      "train loss:0.045524821103019315\n",
      "train loss:0.03589835175349289\n",
      "train loss:0.06323279552325851\n",
      "train loss:0.05188119130238586\n",
      "train loss:0.03940124021323253\n",
      "train loss:0.02230987307083582\n",
      "train loss:0.07073170851824415\n",
      "train loss:0.030734893459108313\n",
      "train loss:0.013236143732484417\n",
      "train loss:0.029314893184473972\n",
      "train loss:0.05086826845778983\n",
      "train loss:0.06616275857430713\n",
      "train loss:0.029015406174230273\n",
      "train loss:0.06742641305597387\n",
      "train loss:0.03164585462168222\n",
      "train loss:0.032635321145282524\n",
      "train loss:0.023510507585514713\n",
      "train loss:0.04192875183910564\n",
      "train loss:0.03245917026423242\n",
      "train loss:0.07473130000198572\n",
      "train loss:0.018019193202698135\n",
      "train loss:0.08743042120131504\n",
      "train loss:0.015991043299493045\n",
      "train loss:0.14102681222159913\n",
      "train loss:0.016292515521668213\n",
      "train loss:0.024409312290689083\n",
      "train loss:0.02071756505917233\n",
      "train loss:0.13667059649075325\n",
      "train loss:0.05832631486435704\n",
      "train loss:0.011964879096851226\n",
      "train loss:0.19067828623676217\n",
      "train loss:0.05293082347845675\n",
      "train loss:0.018335071821018175\n",
      "train loss:0.054082237549464784\n",
      "train loss:0.021825409775630664\n",
      "train loss:0.04609688464042086\n",
      "train loss:0.031240453455842417\n",
      "train loss:0.05043578041763586\n",
      "train loss:0.08282330071444761\n",
      "train loss:0.027815909007907504\n",
      "train loss:0.06043683244419579\n",
      "train loss:0.04189015100859799\n",
      "train loss:0.04631059232078888\n",
      "train loss:0.03365832561437784\n",
      "train loss:0.038634325247086244\n",
      "train loss:0.03190310619690029\n",
      "train loss:0.046807896127217245\n",
      "train loss:0.04849028124870768\n",
      "train loss:0.0997234439253373\n",
      "train loss:0.0700216609988711\n",
      "train loss:0.027687359575240003\n",
      "train loss:0.08753936719678189\n",
      "train loss:0.05105492798984251\n",
      "train loss:0.020936441065814354\n",
      "train loss:0.0562180568116215\n",
      "train loss:0.020891769499099554\n",
      "train loss:0.07757098254966413\n",
      "train loss:0.03840876686296658\n",
      "train loss:0.0550383989099697\n",
      "train loss:0.02880516997532329\n",
      "train loss:0.013431399467266856\n",
      "train loss:0.11178799830737983\n",
      "train loss:0.056049699368333636\n",
      "train loss:0.044774832295264376\n",
      "train loss:0.017973407083249147\n",
      "train loss:0.14523017757764312\n",
      "train loss:0.045371068626491644\n",
      "train loss:0.07356346859470979\n",
      "train loss:0.015626650002043815\n",
      "train loss:0.03085238921304702\n",
      "train loss:0.03559192512446841\n",
      "train loss:0.06695723443426829\n",
      "train loss:0.04368689598576789\n",
      "train loss:0.021487459757643202\n",
      "train loss:0.06626660688695234\n",
      "train loss:0.08401910453940103\n",
      "train loss:0.05529762102938921\n",
      "train loss:0.055480349568609706\n",
      "train loss:0.014633318818869107\n",
      "train loss:0.05715851561116165\n",
      "train loss:0.06131823219581009\n",
      "train loss:0.0366051984602418\n",
      "train loss:0.06282277233075621\n",
      "train loss:0.040467156376874314\n",
      "train loss:0.04579383559451414\n",
      "train loss:0.015048544024498796\n",
      "train loss:0.06923162008020306\n",
      "train loss:0.03541257942282506\n",
      "train loss:0.06486418620125273\n",
      "train loss:0.0883801722474908\n",
      "train loss:0.05977959792029373\n",
      "train loss:0.03177345518976738\n",
      "train loss:0.08395831643851555\n",
      "train loss:0.03070853880536053\n",
      "train loss:0.02014231295633456\n",
      "train loss:0.07136428743056665\n",
      "train loss:0.02015606608471008\n",
      "train loss:0.062461509926282605\n",
      "train loss:0.01113436809909163\n",
      "train loss:0.028891338623698925\n",
      "train loss:0.051374816974469655\n",
      "train loss:0.0779815165730694\n",
      "train loss:0.03555978339295287\n",
      "train loss:0.024019698919868347\n",
      "train loss:0.05828609527475794\n",
      "train loss:0.03718602058923925\n",
      "train loss:0.08020698370592047\n",
      "train loss:0.058038834681330476\n",
      "train loss:0.034402853027620514\n",
      "train loss:0.022623932075631244\n",
      "train loss:0.018156899696385106\n",
      "train loss:0.012390887081922151\n",
      "train loss:0.04079170809144887\n",
      "train loss:0.011652106695303064\n",
      "train loss:0.0238434667322705\n",
      "train loss:0.04010133044742051\n",
      "train loss:0.029026524706151302\n",
      "train loss:0.03229743342324768\n",
      "train loss:0.05386962778688807\n",
      "train loss:0.06187630553267903\n",
      "train loss:0.04199129314881434\n",
      "train loss:0.016970137223779203\n",
      "train loss:0.25890245464971656\n",
      "train loss:0.047335230506950855\n",
      "train loss:0.03572438228356872\n",
      "train loss:0.02898889182067626\n",
      "train loss:0.10403294856820691\n",
      "train loss:0.052043484195519116\n",
      "train loss:0.029255914132187467\n",
      "train loss:0.1196916700178289\n",
      "train loss:0.03139279648711362\n",
      "train loss:0.054290304436944756\n",
      "train loss:0.07382319256821815\n",
      "train loss:0.041778134619350676\n",
      "train loss:0.05649136903261742\n",
      "train loss:0.023639108088062685\n",
      "train loss:0.0383137684866779\n",
      "train loss:0.039224583710698535\n",
      "train loss:0.012929993425854054\n",
      "train loss:0.013553653910677836\n",
      "train loss:0.03493616489142585\n",
      "train loss:0.04598373351020982\n",
      "train loss:0.061274134825350116\n",
      "train loss:0.030782017187291136\n",
      "train loss:0.15207056718047957\n",
      "train loss:0.029398463606273073\n",
      "train loss:0.0517431959344767\n",
      "train loss:0.05957076441839753\n",
      "train loss:0.07642577945383575\n",
      "train loss:0.060547969079684946\n",
      "train loss:0.07872457607079061\n",
      "train loss:0.026832818956883137\n",
      "train loss:0.04179883738249729\n",
      "train loss:0.027615043688497813\n",
      "train loss:0.06532710194341203\n",
      "train loss:0.09522038776083437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.036697114683047455\n",
      "train loss:0.08099255204902762\n",
      "train loss:0.03185532515398424\n",
      "train loss:0.036748154792901916\n",
      "train loss:0.02252571153276833\n",
      "train loss:0.07572467708584289\n",
      "train loss:0.05415076282975201\n",
      "train loss:0.022932881173587417\n",
      "train loss:0.0379750942709649\n",
      "train loss:0.05649857162093576\n",
      "train loss:0.055869978458246955\n",
      "train loss:0.023705397151489237\n",
      "train loss:0.058020204656362255\n",
      "train loss:0.021550338417574623\n",
      "train loss:0.09173875129923813\n",
      "train loss:0.0791676318029166\n",
      "train loss:0.0537263521993874\n",
      "train loss:0.03370773089910318\n",
      "train loss:0.021481320526895012\n",
      "train loss:0.031471349809138544\n",
      "train loss:0.010375145232593044\n",
      "train loss:0.022385175330904512\n",
      "train loss:0.016319824530577374\n",
      "train loss:0.05235955396030586\n",
      "train loss:0.07220744318563253\n",
      "train loss:0.06840386952086255\n",
      "train loss:0.04700817828556219\n",
      "train loss:0.027344711803728643\n",
      "train loss:0.015249887775416915\n",
      "train loss:0.03618044326737374\n",
      "train loss:0.06129810114897343\n",
      "train loss:0.0800434184071306\n",
      "train loss:0.09812063631042896\n",
      "train loss:0.03961878634733441\n",
      "train loss:0.028186812358901244\n",
      "train loss:0.08624890079288272\n",
      "train loss:0.04318430727300632\n",
      "train loss:0.02201010790076024\n",
      "train loss:0.03370406934138168\n",
      "train loss:0.006084128871042486\n",
      "train loss:0.0256774940212642\n",
      "train loss:0.031809905671946734\n",
      "train loss:0.032681691814673994\n",
      "train loss:0.02668252674404406\n",
      "train loss:0.022799411488068647\n",
      "train loss:0.037687112616096266\n",
      "train loss:0.06395497169043993\n",
      "train loss:0.03540769898939515\n",
      "train loss:0.018856871641275363\n",
      "train loss:0.04387554050338098\n",
      "train loss:0.027872319490812952\n",
      "train loss:0.06178864792544661\n",
      "train loss:0.023489769903103176\n",
      "train loss:0.015485475704623986\n",
      "train loss:0.04669546262124833\n",
      "train loss:0.029899085213213578\n",
      "train loss:0.06569461115460022\n",
      "train loss:0.025257605831766238\n",
      "train loss:0.010128444417276094\n",
      "train loss:0.020154313061892082\n",
      "train loss:0.03523656359040311\n",
      "train loss:0.027531929993981387\n",
      "train loss:0.016296325224101273\n",
      "train loss:0.02787354853716508\n",
      "train loss:0.06950080762833923\n",
      "train loss:0.031794199584995624\n",
      "train loss:0.06013948960665934\n",
      "train loss:0.03078163252611662\n",
      "train loss:0.042197186371449355\n",
      "train loss:0.02636768570037156\n",
      "train loss:0.05358370774940553\n",
      "train loss:0.09520951153945865\n",
      "train loss:0.04051250034835476\n",
      "train loss:0.12480490972756096\n",
      "train loss:0.05531242163825238\n",
      "train loss:0.020719202018561252\n",
      "train loss:0.036314574405180905\n",
      "train loss:0.060459808151262735\n",
      "train loss:0.048612687552814234\n",
      "train loss:0.04175296678796224\n",
      "train loss:0.022603023703529634\n",
      "train loss:0.018207743242205792\n",
      "train loss:0.023670302746604553\n",
      "train loss:0.06770337224164966\n",
      "train loss:0.05139421331149589\n",
      "train loss:0.024069868124677516\n",
      "train loss:0.05119830420552805\n",
      "train loss:0.03098485981386019\n",
      "train loss:0.050742793668858435\n",
      "train loss:0.06736983344412996\n",
      "train loss:0.08179203543014137\n",
      "train loss:0.02894165356090666\n",
      "train loss:0.010510206090886008\n",
      "train loss:0.06683399801274334\n",
      "train loss:0.012485722291339455\n",
      "train loss:0.039878059515540326\n",
      "train loss:0.04857754150772906\n",
      "train loss:0.06706271897890438\n",
      "train loss:0.0775155519786101\n",
      "train loss:0.05271442246545981\n",
      "train loss:0.10242267181178173\n",
      "train loss:0.03751777772044487\n",
      "train loss:0.10129545611519207\n",
      "train loss:0.03791954670022334\n",
      "train loss:0.04550447369021844\n",
      "train loss:0.0673940463622316\n",
      "train loss:0.07589243089074399\n",
      "train loss:0.011135697780831805\n",
      "train loss:0.09322244165800533\n",
      "train loss:0.021651626375087378\n",
      "train loss:0.02535624709475393\n",
      "train loss:0.048756881851628193\n",
      "train loss:0.07691537184382347\n",
      "train loss:0.017455125103365794\n",
      "train loss:0.03666044720524939\n",
      "train loss:0.04514194790828964\n",
      "train loss:0.02367896380739505\n",
      "train loss:0.041523284332154464\n",
      "train loss:0.08809637738757611\n",
      "train loss:0.010413406782676653\n",
      "train loss:0.017101626059089464\n",
      "train loss:0.022683773114572797\n",
      "train loss:0.02124659199409911\n",
      "train loss:0.11278496605801645\n",
      "train loss:0.02594477914862539\n",
      "train loss:0.06524690800663115\n",
      "train loss:0.03512098491331047\n",
      "train loss:0.017466116673211005\n",
      "train loss:0.015475244472522522\n",
      "train loss:0.0670561457113907\n",
      "train loss:0.025036021854665736\n",
      "train loss:0.024408199389917673\n",
      "train loss:0.06158138148387691\n",
      "train loss:0.03552794984772924\n",
      "train loss:0.03280057409688035\n",
      "train loss:0.03487814331506251\n",
      "train loss:0.03296014028876117\n",
      "train loss:0.02878867201598034\n",
      "train loss:0.01237357626690602\n",
      "train loss:0.04017807148453348\n",
      "train loss:0.046408021694154054\n",
      "train loss:0.014675323956065108\n",
      "train loss:0.02962026729916019\n",
      "train loss:0.026375229229000607\n",
      "train loss:0.015269120537467642\n",
      "train loss:0.0804197160277829\n",
      "train loss:0.0556261782242608\n",
      "train loss:0.046602521179836785\n",
      "train loss:0.048012607690220574\n",
      "train loss:0.031056255157585394\n",
      "train loss:0.03574929940793912\n",
      "train loss:0.02360218566808882\n",
      "train loss:0.07973885001818798\n",
      "train loss:0.017698050388066055\n",
      "train loss:0.03142302103676584\n",
      "train loss:0.05196223782296831\n",
      "train loss:0.02089511403207399\n",
      "train loss:0.06810617922678835\n",
      "train loss:0.017285991707185946\n",
      "train loss:0.005710117793331182\n",
      "train loss:0.035439361964019075\n",
      "train loss:0.0635244801457325\n",
      "train loss:0.015136972475628634\n",
      "train loss:0.018068881579252547\n",
      "train loss:0.021815802952041143\n",
      "train loss:0.05631506008774582\n",
      "train loss:0.05430597942259187\n",
      "train loss:0.02754872156455292\n",
      "train loss:0.07900947209637971\n",
      "train loss:0.04034882119994458\n",
      "train loss:0.018343526195519246\n",
      "train loss:0.052447870751590485\n",
      "train loss:0.051261065667130075\n",
      "train loss:0.028726998414851115\n",
      "train loss:0.02462160138980292\n",
      "train loss:0.014611330359171395\n",
      "train loss:0.0475546845063799\n",
      "train loss:0.13749375974627798\n",
      "train loss:0.028214447813623957\n",
      "train loss:0.04019660869331307\n",
      "train loss:0.023797497877349798\n",
      "train loss:0.019269494370652406\n",
      "train loss:0.040750160877723644\n",
      "train loss:0.013805708908425363\n",
      "train loss:0.012196239098007605\n",
      "train loss:0.014569538424545924\n",
      "train loss:0.022341819672027228\n",
      "train loss:0.0413313665410684\n",
      "train loss:0.05898834267574503\n",
      "train loss:0.0932856015350253\n",
      "train loss:0.010668244654060997\n",
      "train loss:0.036730172648274835\n",
      "train loss:0.019937129400684758\n",
      "train loss:0.015109222365344944\n",
      "train loss:0.020359667322190425\n",
      "train loss:0.027430714085813462\n",
      "train loss:0.015548688323558242\n",
      "train loss:0.023819856372296274\n",
      "train loss:0.026619272094975516\n",
      "train loss:0.03017214282546789\n",
      "train loss:0.05500425008841851\n",
      "train loss:0.02658037037395064\n",
      "train loss:0.05744510556368479\n",
      "train loss:0.042369378995011815\n",
      "train loss:0.038986668693155264\n",
      "train loss:0.015345537468846968\n",
      "train loss:0.16072976614785425\n",
      "train loss:0.017840647038671414\n",
      "train loss:0.019533515428343057\n",
      "=== epoch:4, train acc:0.986, test acc:0.983 ===\n",
      "train loss:0.05415032112680976\n",
      "train loss:0.041617271159676596\n",
      "train loss:0.07777578093723608\n",
      "train loss:0.061490692727606586\n",
      "train loss:0.009033681012773532\n",
      "train loss:0.09881524777175887\n",
      "train loss:0.02701346959034918\n",
      "train loss:0.014157780745863165\n",
      "train loss:0.03904692247612463\n",
      "train loss:0.047520722139820455\n",
      "train loss:0.056501347630525174\n",
      "train loss:0.0485079169511439\n",
      "train loss:0.04181786235223098\n",
      "train loss:0.016681755112452224\n",
      "train loss:0.047009807180937\n",
      "train loss:0.020539894515242317\n",
      "train loss:0.04457154180386867\n",
      "train loss:0.027776313942160704\n",
      "train loss:0.011593841080265519\n",
      "train loss:0.011600309260054257\n",
      "train loss:0.012798151674273754\n",
      "train loss:0.06432883999323359\n",
      "train loss:0.03938903744825678\n",
      "train loss:0.07712093181935167\n",
      "train loss:0.020609811842786888\n",
      "train loss:0.04015955140117046\n",
      "train loss:0.03996794579161386\n",
      "train loss:0.04783925463495496\n",
      "train loss:0.049092460266406096\n",
      "train loss:0.024864688208292633\n",
      "train loss:0.024153151159383376\n",
      "train loss:0.052570612398906515\n",
      "train loss:0.04009679567228746\n",
      "train loss:0.015532149656322623\n",
      "train loss:0.013378410511623182\n",
      "train loss:0.08739066778344143\n",
      "train loss:0.1329541088817379\n",
      "train loss:0.18356930138823327\n",
      "train loss:0.06294043428090153\n",
      "train loss:0.16105534437993288\n",
      "train loss:0.025364580654215253\n",
      "train loss:0.0462149666170642\n",
      "train loss:0.01967367201133353\n",
      "train loss:0.04441681578788335\n",
      "train loss:0.007453867452485337\n",
      "train loss:0.02320928766997779\n",
      "train loss:0.03943212628351324\n",
      "train loss:0.04089858989715757\n",
      "train loss:0.0720089824531339\n",
      "train loss:0.007438633271231556\n",
      "train loss:0.017345135343624356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06804959908384499\n",
      "train loss:0.027735032828122695\n",
      "train loss:0.014579809217795925\n",
      "train loss:0.024572520561255008\n",
      "train loss:0.03087523884859845\n",
      "train loss:0.040216946039967255\n",
      "train loss:0.011904204412778565\n",
      "train loss:0.02556369299540785\n",
      "train loss:0.039149208839116996\n",
      "train loss:0.023795581222262524\n",
      "train loss:0.0582783804714726\n",
      "train loss:0.033829030268434805\n",
      "train loss:0.04139137959406107\n",
      "train loss:0.0139118326091304\n",
      "train loss:0.063928127096886\n",
      "train loss:0.03221294860471125\n",
      "train loss:0.04004412245408024\n",
      "train loss:0.05559355137947982\n",
      "train loss:0.03559982507768081\n",
      "train loss:0.03959801487763925\n",
      "train loss:0.04048978206487083\n",
      "train loss:0.044664083411087116\n",
      "train loss:0.07142476145965816\n",
      "train loss:0.023971733907294072\n",
      "train loss:0.15140863661900206\n",
      "train loss:0.03802775779161507\n",
      "train loss:0.02569145447399209\n",
      "train loss:0.024217701403667413\n",
      "train loss:0.034039207818173385\n",
      "train loss:0.04666849259754745\n",
      "train loss:0.10501742730449845\n",
      "train loss:0.06005367280507973\n",
      "train loss:0.04684730473401078\n",
      "train loss:0.007344663968810232\n",
      "train loss:0.009887367185340334\n",
      "train loss:0.014525738036330404\n",
      "train loss:0.06618617003017797\n",
      "train loss:0.07153830986039207\n",
      "train loss:0.009423729510673636\n",
      "train loss:0.06173406161332177\n",
      "train loss:0.009195660044016259\n",
      "train loss:0.03590184160780587\n",
      "train loss:0.07983615083689659\n",
      "train loss:0.025898057238436217\n",
      "train loss:0.054644261407745025\n",
      "train loss:0.033062130429823804\n",
      "train loss:0.03972941796455614\n",
      "train loss:0.025350657103580528\n",
      "train loss:0.0066252510567665675\n",
      "train loss:0.030440233046790433\n",
      "train loss:0.03742433528055303\n",
      "train loss:0.052122950349119665\n",
      "train loss:0.07834319087959324\n",
      "train loss:0.07086180371950104\n",
      "train loss:0.010901854786778535\n",
      "train loss:0.04101011642717355\n",
      "train loss:0.09387959805019438\n",
      "train loss:0.018748562806968863\n",
      "train loss:0.03451561015262725\n",
      "train loss:0.053640298665231664\n",
      "train loss:0.04814317081677686\n",
      "train loss:0.017621600559524764\n",
      "train loss:0.11081214702630442\n",
      "train loss:0.013358870602094048\n",
      "train loss:0.021869345041647975\n",
      "train loss:0.017400881236380162\n",
      "train loss:0.08098469249585596\n",
      "train loss:0.09636541140917115\n",
      "train loss:0.06341673380662956\n",
      "train loss:0.014081475957656795\n",
      "train loss:0.02906402509586488\n",
      "train loss:0.04837487737844581\n",
      "train loss:0.021569744578528977\n",
      "train loss:0.016274507083914435\n",
      "train loss:0.026695429851726172\n",
      "train loss:0.04760944340703855\n",
      "train loss:0.031938880623125845\n",
      "train loss:0.01772256920861824\n",
      "train loss:0.027092411368452033\n",
      "train loss:0.04042357191613946\n",
      "train loss:0.14216263269092544\n",
      "train loss:0.020781484860429016\n",
      "train loss:0.02564682588931991\n",
      "train loss:0.05734489062041571\n",
      "train loss:0.02563499533870358\n",
      "train loss:0.038053773621269146\n",
      "train loss:0.0198668543879814\n",
      "train loss:0.03337285717723589\n",
      "train loss:0.015049501738229519\n",
      "train loss:0.024478126156409617\n",
      "train loss:0.04853008871028401\n",
      "train loss:0.0159008523261534\n",
      "train loss:0.02495043383823248\n",
      "train loss:0.03771234211025199\n",
      "train loss:0.020401050203597747\n",
      "train loss:0.018441208682867746\n",
      "train loss:0.01892402729341261\n",
      "train loss:0.08255073137809782\n",
      "train loss:0.02405149673278366\n",
      "train loss:0.04574320785088197\n",
      "train loss:0.0066065546435569835\n",
      "train loss:0.03509855303717728\n",
      "train loss:0.06271028372667611\n",
      "train loss:0.030815044839413757\n",
      "train loss:0.06885102669439198\n",
      "train loss:0.02776290874408465\n",
      "train loss:0.016287498956978678\n",
      "train loss:0.02398319962626622\n",
      "train loss:0.023071097087048305\n",
      "train loss:0.017870849419163472\n",
      "train loss:0.005271397637648401\n",
      "train loss:0.09286470734744025\n",
      "train loss:0.014303438904186972\n",
      "train loss:0.017165454418028588\n",
      "train loss:0.05623514955399076\n",
      "train loss:0.015985218623988114\n",
      "train loss:0.021357880498881564\n",
      "train loss:0.06588961013400431\n",
      "train loss:0.012775415373318215\n",
      "train loss:0.06710112372734137\n",
      "train loss:0.015240861683558916\n",
      "train loss:0.05214677647268723\n",
      "train loss:0.053468240997962206\n",
      "train loss:0.025445214092438856\n",
      "train loss:0.019608873909851558\n",
      "train loss:0.01813143594417906\n",
      "train loss:0.02947540481608576\n",
      "train loss:0.025590151186746065\n",
      "train loss:0.012089254740647204\n",
      "train loss:0.029308257549602375\n",
      "train loss:0.07615632184194443\n",
      "train loss:0.031191188469384602\n",
      "train loss:0.022441224003487723\n",
      "train loss:0.0632797657164195\n",
      "train loss:0.06595376451224694\n",
      "train loss:0.058969410957888393\n",
      "train loss:0.013336996024021395\n",
      "train loss:0.06459405599597048\n",
      "train loss:0.05419296091867037\n",
      "train loss:0.05396905022475338\n",
      "train loss:0.015115195303319874\n",
      "train loss:0.021101497961535404\n",
      "train loss:0.05324258354326828\n",
      "train loss:0.052712671357872554\n",
      "train loss:0.00680199000766304\n",
      "train loss:0.02901752544913802\n",
      "train loss:0.03496873029812215\n",
      "train loss:0.04722879090797983\n",
      "train loss:0.04697399738836868\n",
      "train loss:0.023773437729298196\n",
      "train loss:0.06016666811539979\n",
      "train loss:0.020653216737523402\n",
      "train loss:0.06134322268061892\n",
      "train loss:0.034043584617043314\n",
      "train loss:0.02454174024044586\n",
      "train loss:0.012296580497780995\n",
      "train loss:0.0776270228211434\n",
      "train loss:0.025913700183986452\n",
      "train loss:0.0455922791765351\n",
      "train loss:0.0033640738610820633\n",
      "train loss:0.05374795853639524\n",
      "train loss:0.03902705182206111\n",
      "train loss:0.02899330868282479\n",
      "train loss:0.013671444510208318\n",
      "train loss:0.07396637850196881\n",
      "train loss:0.03369806924246835\n",
      "train loss:0.04867777280773564\n",
      "train loss:0.015989045384109037\n",
      "train loss:0.02320159916622222\n",
      "train loss:0.023283140461996612\n",
      "train loss:0.01536310304432436\n",
      "train loss:0.019015740493513636\n",
      "train loss:0.026194157627597088\n",
      "train loss:0.03986954898669477\n",
      "train loss:0.010904584912569537\n",
      "train loss:0.011460572308721653\n",
      "train loss:0.01938039204934764\n",
      "train loss:0.011708517487765085\n",
      "train loss:0.011782305760014988\n",
      "train loss:0.026051861664178753\n",
      "train loss:0.01921990036363516\n",
      "train loss:0.05532467835653038\n",
      "train loss:0.08338900591602384\n",
      "train loss:0.044374168489688184\n",
      "train loss:0.009240914069665915\n",
      "train loss:0.00625257653936102\n",
      "train loss:0.10240555858088463\n",
      "train loss:0.008297773851232483\n",
      "train loss:0.041770504615882095\n",
      "train loss:0.050556902953764596\n",
      "train loss:0.07525576841072311\n",
      "train loss:0.07441121574991366\n",
      "train loss:0.07751676624843529\n",
      "train loss:0.034103161778034054\n",
      "train loss:0.05071648157111858\n",
      "train loss:0.01263830522736734\n",
      "train loss:0.02614594242222001\n",
      "train loss:0.03579802200490801\n",
      "train loss:0.010127469182866127\n",
      "train loss:0.129569647080239\n",
      "train loss:0.03883230958922334\n",
      "train loss:0.024209884264959337\n",
      "train loss:0.006011949775136738\n",
      "train loss:0.024115278759075265\n",
      "train loss:0.013402474259601638\n",
      "train loss:0.023085873262847955\n",
      "train loss:0.07284080523464903\n",
      "train loss:0.018521239255753396\n",
      "train loss:0.11202596800703551\n",
      "train loss:0.04811804475553125\n",
      "train loss:0.023371625762960112\n",
      "train loss:0.028993575961739043\n",
      "train loss:0.03610684606376289\n",
      "train loss:0.019900059751824763\n",
      "train loss:0.01218349329153125\n",
      "train loss:0.030849839646261645\n",
      "train loss:0.07278008084500127\n",
      "train loss:0.025799137614914588\n",
      "train loss:0.04864942455237506\n",
      "train loss:0.010922144665713555\n",
      "train loss:0.023263000722184603\n",
      "train loss:0.07088607484983465\n",
      "train loss:0.0718655554873465\n",
      "train loss:0.04218777867251489\n",
      "train loss:0.04795964046030546\n",
      "train loss:0.013760598406706397\n",
      "train loss:0.020346874455330465\n",
      "train loss:0.045603997638179274\n",
      "train loss:0.04971397518300893\n",
      "train loss:0.011635948492476764\n",
      "train loss:0.030628840950555656\n",
      "train loss:0.09134364615492903\n",
      "train loss:0.03205082124997743\n",
      "train loss:0.013737421500858606\n",
      "train loss:0.02221140420651795\n",
      "train loss:0.03446193023524699\n",
      "train loss:0.0569823406855372\n",
      "train loss:0.03455874666072614\n",
      "train loss:0.029803970812468487\n",
      "train loss:0.08634450107058457\n",
      "train loss:0.07278437612580735\n",
      "train loss:0.043683196334717636\n",
      "train loss:0.041720310312300925\n",
      "train loss:0.05986911917159575\n",
      "train loss:0.05111565121238819\n",
      "train loss:0.011899938484775708\n",
      "train loss:0.010847558165276138\n",
      "train loss:0.03082818914146273\n",
      "train loss:0.008697586786228156\n",
      "train loss:0.03691980003854422\n",
      "train loss:0.019442140515527187\n",
      "train loss:0.010020376130951534\n",
      "train loss:0.11853753149301234\n",
      "train loss:0.10376914929484435\n",
      "train loss:0.05254421848949261\n",
      "train loss:0.01095145809053563\n",
      "train loss:0.10235298979799008\n",
      "train loss:0.010047769274965394\n",
      "train loss:0.016870713796521424\n",
      "train loss:0.014590882294180702\n",
      "train loss:0.05518001336654813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.023040949111462275\n",
      "train loss:0.11303432137442329\n",
      "train loss:0.036466293956245274\n",
      "train loss:0.038114758901297535\n",
      "train loss:0.03889950820453259\n",
      "train loss:0.008114178565713098\n",
      "train loss:0.018290734180047712\n",
      "train loss:0.01872386133803198\n",
      "train loss:0.014552577829203212\n",
      "train loss:0.027782182338871215\n",
      "train loss:0.04446978660269429\n",
      "train loss:0.034499002188918285\n",
      "train loss:0.011005920409151977\n",
      "train loss:0.06827510603348771\n",
      "train loss:0.03314810439470522\n",
      "train loss:0.00408701418211895\n",
      "train loss:0.049318883348961215\n",
      "train loss:0.05785964882282145\n",
      "train loss:0.043022646015370744\n",
      "train loss:0.011085881634175178\n",
      "train loss:0.05543032911142459\n",
      "train loss:0.028458360056240407\n",
      "train loss:0.08203236786512397\n",
      "train loss:0.014979887338390275\n",
      "train loss:0.06992846409215894\n",
      "train loss:0.015459559280907254\n",
      "train loss:0.02291813831786005\n",
      "train loss:0.006314007919614445\n",
      "train loss:0.02305818589796024\n",
      "train loss:0.10107665750810989\n",
      "train loss:0.022027133385406253\n",
      "train loss:0.027173264428835057\n",
      "train loss:0.021466801452448267\n",
      "train loss:0.014447125287899836\n",
      "train loss:0.013348655540452191\n",
      "train loss:0.07054833403926505\n",
      "train loss:0.08438640592047594\n",
      "train loss:0.03622044461964851\n",
      "train loss:0.11149661119423496\n",
      "train loss:0.01232006635070415\n",
      "train loss:0.0443140792269747\n",
      "train loss:0.01617149107161498\n",
      "train loss:0.01267213214885014\n",
      "train loss:0.022373287604429498\n",
      "train loss:0.04044282765503706\n",
      "train loss:0.03677832228887162\n",
      "train loss:0.023174315654897228\n",
      "train loss:0.021061651531155925\n",
      "train loss:0.03069868090190729\n",
      "train loss:0.015809672514379005\n",
      "train loss:0.029833007356728523\n",
      "train loss:0.061157856328891765\n",
      "train loss:0.03165823855462651\n",
      "train loss:0.031718932484636794\n",
      "train loss:0.02129353418870801\n",
      "train loss:0.010670592631429821\n",
      "train loss:0.017134223143418597\n",
      "train loss:0.047189246911940194\n",
      "train loss:0.07288627971134996\n",
      "train loss:0.01066005923404101\n",
      "train loss:0.04124083304887031\n",
      "train loss:0.015298376454282656\n",
      "train loss:0.011689168590565527\n",
      "train loss:0.029132963473966666\n",
      "train loss:0.014391941183221443\n",
      "train loss:0.016835207914680697\n",
      "train loss:0.015379175153278878\n",
      "train loss:0.028631350168846766\n",
      "train loss:0.009569314637739136\n",
      "train loss:0.02657334148755349\n",
      "train loss:0.03960316093417632\n",
      "train loss:0.027307002527569\n",
      "train loss:0.01859945082825287\n",
      "train loss:0.015371036383890655\n",
      "train loss:0.010617849396163082\n",
      "train loss:0.07355292242661438\n",
      "train loss:0.02274776214077744\n",
      "train loss:0.013826824952383798\n",
      "train loss:0.027152623028476545\n",
      "train loss:0.013630442746898865\n",
      "train loss:0.010506712990750854\n",
      "train loss:0.011444369649296713\n",
      "train loss:0.03145263505043225\n",
      "train loss:0.02923521962856341\n",
      "train loss:0.03173351786590478\n",
      "train loss:0.012505866445976298\n",
      "train loss:0.02742519166224422\n",
      "train loss:0.05899096986396136\n",
      "train loss:0.0491080745726135\n",
      "train loss:0.005293645852537009\n",
      "train loss:0.03460278175386081\n",
      "train loss:0.020461686834744988\n",
      "train loss:0.02297804468877245\n",
      "train loss:0.01595935818790614\n",
      "train loss:0.021329000925026008\n",
      "train loss:0.020127241341862348\n",
      "train loss:0.03703777848157812\n",
      "train loss:0.024295995211029552\n",
      "train loss:0.037657373997916195\n",
      "train loss:0.012056136347281294\n",
      "train loss:0.03032199048063035\n",
      "train loss:0.007698195928248715\n",
      "train loss:0.027379263671409006\n",
      "train loss:0.011970029375818649\n",
      "train loss:0.004257725456980591\n",
      "train loss:0.006578370809748735\n",
      "train loss:0.04584185295992386\n",
      "train loss:0.09827505509822573\n",
      "train loss:0.017178293863497493\n",
      "train loss:0.020853186084086893\n",
      "train loss:0.02274032818196644\n",
      "train loss:0.07447347806360485\n",
      "train loss:0.05094645776245149\n",
      "train loss:0.0572420376726544\n",
      "train loss:0.04147088857677818\n",
      "train loss:0.05944891720828292\n",
      "train loss:0.02714828977227011\n",
      "train loss:0.08707795334603005\n",
      "train loss:0.021648023221341253\n",
      "train loss:0.017823162300476956\n",
      "train loss:0.017727807377075376\n",
      "train loss:0.02422643332714409\n",
      "train loss:0.013773523254765377\n",
      "train loss:0.02410698782954319\n",
      "train loss:0.02731936054463946\n",
      "train loss:0.06410352613606383\n",
      "train loss:0.031450590719953146\n",
      "train loss:0.022573397279990713\n",
      "train loss:0.023894773026020638\n",
      "train loss:0.032666677302167095\n",
      "train loss:0.013006054128071548\n",
      "train loss:0.05360452405630659\n",
      "train loss:0.07059433573950745\n",
      "train loss:0.015358684568479851\n",
      "train loss:0.019404096315512775\n",
      "train loss:0.03441031650363567\n",
      "train loss:0.007706219275529201\n",
      "train loss:0.013383328576866017\n",
      "train loss:0.026363336265110858\n",
      "train loss:0.008706395645270227\n",
      "train loss:0.036054459760241936\n",
      "train loss:0.024403675307206996\n",
      "train loss:0.09538511222997484\n",
      "train loss:0.045461392120169315\n",
      "train loss:0.036249235604471144\n",
      "train loss:0.011174953788159475\n",
      "train loss:0.01091549493252735\n",
      "train loss:0.0217965298921695\n",
      "train loss:0.06735648866682518\n",
      "train loss:0.04951421177193561\n",
      "train loss:0.057594417826575664\n",
      "train loss:0.06495117467698792\n",
      "train loss:0.025932659922867786\n",
      "train loss:0.03779845929297463\n",
      "train loss:0.004918023778061606\n",
      "train loss:0.01696875320760599\n",
      "train loss:0.0327988912522979\n",
      "train loss:0.040839671183681495\n",
      "train loss:0.018786457896320077\n",
      "train loss:0.01686468194140923\n",
      "train loss:0.02593566052768724\n",
      "train loss:0.0138495521492448\n",
      "train loss:0.11043326505664713\n",
      "train loss:0.04743974759588872\n",
      "train loss:0.033441648043282445\n",
      "train loss:0.06727701991166661\n",
      "train loss:0.028050719260001314\n",
      "train loss:0.011059077723664507\n",
      "train loss:0.0118109312024754\n",
      "train loss:0.04326647034989214\n",
      "train loss:0.056309554590728415\n",
      "train loss:0.06376147553329227\n",
      "train loss:0.015782993316695457\n",
      "train loss:0.06167151464255114\n",
      "train loss:0.030416134424191874\n",
      "train loss:0.02535903924986772\n",
      "train loss:0.010024222828732665\n",
      "train loss:0.022296315261606057\n",
      "train loss:0.010577867028750087\n",
      "train loss:0.009376913316841144\n",
      "train loss:0.06561551087056516\n",
      "train loss:0.004742842004511609\n",
      "train loss:0.022961823026198827\n",
      "train loss:0.15208964045084974\n",
      "train loss:0.008409195405807266\n",
      "train loss:0.052927852200873336\n",
      "train loss:0.01338465501620325\n",
      "train loss:0.0667536642634723\n",
      "train loss:0.012582219472506024\n",
      "train loss:0.011728623903442361\n",
      "train loss:0.003880331260379292\n",
      "train loss:0.02274909362209613\n",
      "train loss:0.03767752986854536\n",
      "train loss:0.07050808673188873\n",
      "train loss:0.029879814747445308\n",
      "train loss:0.02351287156984634\n",
      "train loss:0.03203884415723703\n",
      "train loss:0.14440053420878926\n",
      "train loss:0.07387930716237347\n",
      "train loss:0.013773445465516867\n",
      "train loss:0.004021081465133201\n",
      "train loss:0.02215591028354558\n",
      "train loss:0.06946215007540996\n",
      "train loss:0.005021642417683528\n",
      "train loss:0.031903376697606255\n",
      "train loss:0.025862549347251317\n",
      "train loss:0.029694038886118657\n",
      "train loss:0.011725874349720838\n",
      "train loss:0.01849609179914842\n",
      "train loss:0.028056997329706537\n",
      "train loss:0.02207468415031147\n",
      "train loss:0.048223870096455804\n",
      "train loss:0.009732146687100467\n",
      "train loss:0.018319677433447635\n",
      "train loss:0.031933828584723545\n",
      "train loss:0.031386411574129115\n",
      "train loss:0.01628999436040532\n",
      "train loss:0.018299360568950058\n",
      "train loss:0.04250993189086201\n",
      "train loss:0.0312472065977693\n",
      "train loss:0.06670664213843652\n",
      "train loss:0.016359824174709426\n",
      "train loss:0.0723810300295715\n",
      "train loss:0.047507603368376984\n",
      "train loss:0.034585621260175545\n",
      "train loss:0.014781810628239099\n",
      "train loss:0.07837648735503974\n",
      "train loss:0.036898168140134385\n",
      "train loss:0.004958494119474312\n",
      "train loss:0.056450947996307975\n",
      "train loss:0.04641524336500608\n",
      "train loss:0.009003601356122217\n",
      "train loss:0.03983995589745159\n",
      "train loss:0.030492381535515607\n",
      "train loss:0.020060820047253486\n",
      "train loss:0.005731418107600003\n",
      "train loss:0.02218108579451371\n",
      "train loss:0.09366654669680063\n",
      "train loss:0.038660120475651524\n",
      "train loss:0.012696367092837599\n",
      "train loss:0.01574780875457314\n",
      "train loss:0.0076982818903484525\n",
      "train loss:0.03118300886741121\n",
      "train loss:0.0425902892880047\n",
      "train loss:0.03895671952827782\n",
      "train loss:0.008729364455905667\n",
      "train loss:0.05314148166909625\n",
      "train loss:0.05131622312121476\n",
      "train loss:0.008292503706565955\n",
      "train loss:0.008882410420924273\n",
      "train loss:0.020699900552723402\n",
      "train loss:0.08527384493406207\n",
      "train loss:0.00947816590799637\n",
      "train loss:0.042152035604256406\n",
      "train loss:0.020319293465754003\n",
      "train loss:0.014969876492423317\n",
      "train loss:0.010023164175235435\n",
      "train loss:0.026888183268015956\n",
      "train loss:0.01491447577614823\n",
      "train loss:0.024130406979406143\n",
      "train loss:0.006709429850786763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.08136337827433066\n",
      "train loss:0.02044552685100852\n",
      "train loss:0.02703320171417445\n",
      "train loss:0.03763225082885337\n",
      "train loss:0.04829429556654162\n",
      "train loss:0.018221452334696443\n",
      "train loss:0.035150531587187145\n",
      "train loss:0.021937932795745355\n",
      "train loss:0.01677619107686209\n",
      "train loss:0.030069193441181485\n",
      "train loss:0.04231483928088901\n",
      "train loss:0.07990497699333898\n",
      "train loss:0.01730384095133017\n",
      "train loss:0.011234696635554686\n",
      "train loss:0.012624314740353533\n",
      "train loss:0.04006662967188256\n",
      "train loss:0.024398246397647358\n",
      "train loss:0.0361355315677547\n",
      "train loss:0.07612815755668184\n",
      "train loss:0.008244577848804623\n",
      "train loss:0.046276276657683635\n",
      "train loss:0.02068031550643531\n",
      "train loss:0.02906102388972057\n",
      "train loss:0.008625106024010967\n",
      "train loss:0.010369534147029529\n",
      "train loss:0.04734257091889513\n",
      "train loss:0.014383597997086314\n",
      "=== epoch:5, train acc:0.983, test acc:0.982 ===\n",
      "train loss:0.06359761617318563\n",
      "train loss:0.005150544809112739\n",
      "train loss:0.006171444793438421\n",
      "train loss:0.02162306236344436\n",
      "train loss:0.01549706020371775\n",
      "train loss:0.011613810817138\n",
      "train loss:0.03744049714659258\n",
      "train loss:0.05812156375182533\n",
      "train loss:0.02239354198615659\n",
      "train loss:0.07815847500195157\n",
      "train loss:0.04985191989686893\n",
      "train loss:0.008285251896345613\n",
      "train loss:0.008440599603264263\n",
      "train loss:0.01735390659152069\n",
      "train loss:0.021146765107109496\n",
      "train loss:0.02457527514791624\n",
      "train loss:0.05491565553108096\n",
      "train loss:0.00613246083467158\n",
      "train loss:0.029227696440787293\n",
      "train loss:0.02895961365997909\n",
      "train loss:0.04022230410734566\n",
      "train loss:0.05870734505189096\n",
      "train loss:0.03210628439380195\n",
      "train loss:0.004209083148481028\n",
      "train loss:0.003929017762603823\n",
      "train loss:0.02829959072005856\n",
      "train loss:0.0698852017382958\n",
      "train loss:0.00922250863988097\n",
      "train loss:0.10538205657871885\n",
      "train loss:0.036729559236072316\n",
      "train loss:0.017041188000829176\n",
      "train loss:0.03277709037694454\n",
      "train loss:0.015868816728155995\n",
      "train loss:0.06834728483591906\n",
      "train loss:0.010976383617965466\n",
      "train loss:0.01420014991119099\n",
      "train loss:0.00951997457638886\n",
      "train loss:0.028481268834156942\n",
      "train loss:0.007970554742820012\n",
      "train loss:0.02133149481540324\n",
      "train loss:0.019145403949458364\n",
      "train loss:0.07006895951455044\n",
      "train loss:0.011698235793110207\n",
      "train loss:0.05655684249070246\n",
      "train loss:0.010339766423834596\n",
      "train loss:0.01266100496936476\n",
      "train loss:0.02131317912176585\n",
      "train loss:0.08021068860340438\n",
      "train loss:0.05378857097527259\n",
      "train loss:0.03639489862559437\n",
      "train loss:0.01572757344437159\n",
      "train loss:0.03254442667727893\n",
      "train loss:0.022729584975588208\n",
      "train loss:0.0217302256459201\n",
      "train loss:0.01196455169923501\n",
      "train loss:0.022692010160130338\n",
      "train loss:0.014868710934785178\n",
      "train loss:0.03851625124202027\n",
      "train loss:0.030857399781543518\n",
      "train loss:0.06249932335341258\n",
      "train loss:0.09977727601272493\n",
      "train loss:0.013598676728071494\n",
      "train loss:0.03629837349817366\n",
      "train loss:0.03133494160532991\n",
      "train loss:0.007068776403331467\n",
      "train loss:0.04220448441313231\n",
      "train loss:0.01715498252357582\n",
      "train loss:0.009522856198742002\n",
      "train loss:0.02956960718994603\n",
      "train loss:0.006037867568432137\n",
      "train loss:0.024150195383257946\n",
      "train loss:0.019077888330234095\n",
      "train loss:0.020477739226546034\n",
      "train loss:0.008095927424348332\n",
      "train loss:0.03775136559318208\n",
      "train loss:0.016412562800031793\n",
      "train loss:0.010422637799934858\n",
      "train loss:0.004279633579255032\n",
      "train loss:0.02471858854417935\n",
      "train loss:0.015105780560889745\n",
      "train loss:0.07322175965573612\n",
      "train loss:0.0551773431290147\n",
      "train loss:0.008948615343080979\n",
      "train loss:0.0046927648188346514\n",
      "train loss:0.014893238323378653\n",
      "train loss:0.009097044625258056\n",
      "train loss:0.03007744434426378\n",
      "train loss:0.007749277975638457\n",
      "train loss:0.027415416294608044\n",
      "train loss:0.0475948752642107\n",
      "train loss:0.07028243052246524\n",
      "train loss:0.011561790856434289\n",
      "train loss:0.03465843268477306\n",
      "train loss:0.027177351004105475\n",
      "train loss:0.017777567030171998\n",
      "train loss:0.015538213294579373\n",
      "train loss:0.017069537336826316\n",
      "train loss:0.009005982710563947\n",
      "train loss:0.03165600796690695\n",
      "train loss:0.07376888605589806\n",
      "train loss:0.011486540855416418\n",
      "train loss:0.005841334842153409\n",
      "train loss:0.0406630565112272\n",
      "train loss:0.021239224877044924\n",
      "train loss:0.024409200821729177\n",
      "train loss:0.0065517969720327\n",
      "train loss:0.03341484195198796\n",
      "train loss:0.04614495197845203\n",
      "train loss:0.14541763448263922\n",
      "train loss:0.048641467981700055\n",
      "train loss:0.027130537067453303\n",
      "train loss:0.007230271297498178\n",
      "train loss:0.009662325327706394\n",
      "train loss:0.029545370347607073\n",
      "train loss:0.0065940397178959045\n",
      "train loss:0.08304086483435981\n",
      "train loss:0.029042919386249536\n",
      "train loss:0.013599045192322728\n",
      "train loss:0.006832529640207483\n",
      "train loss:0.04894380013314634\n",
      "train loss:0.009445021289964438\n",
      "train loss:0.013002422806349705\n",
      "train loss:0.010993047490429625\n",
      "train loss:0.03049550831348817\n",
      "train loss:0.020219851094738676\n",
      "train loss:0.08020235021847696\n",
      "train loss:0.014580064690647654\n",
      "train loss:0.00873639815580993\n",
      "train loss:0.00363448728657296\n",
      "train loss:0.016418416360293734\n",
      "train loss:0.010219872149842784\n",
      "train loss:0.003114812157872923\n",
      "train loss:0.006721443471020963\n",
      "train loss:0.03551777716306058\n",
      "train loss:0.011858246781017528\n",
      "train loss:0.01336906734643734\n",
      "train loss:0.005922514070805423\n",
      "train loss:0.020737316290468183\n",
      "train loss:0.015118663355726883\n",
      "train loss:0.012749181537003662\n",
      "train loss:0.03568154762311306\n",
      "train loss:0.033814181026211455\n",
      "train loss:0.010342255644801701\n",
      "train loss:0.03524010350564299\n",
      "train loss:0.025461657228395357\n",
      "train loss:0.01816295444008377\n",
      "train loss:0.06508895948358502\n",
      "train loss:0.10887820010750277\n",
      "train loss:0.012001354619591967\n",
      "train loss:0.06664715166987324\n",
      "train loss:0.02492564270472139\n",
      "train loss:0.008975467822194822\n",
      "train loss:0.023676079711152726\n",
      "train loss:0.017034320767031656\n",
      "train loss:0.0710976266423858\n",
      "train loss:0.07070112549871593\n",
      "train loss:0.05650621089731099\n",
      "train loss:0.0035861892148241884\n",
      "train loss:0.04782953285410037\n",
      "train loss:0.015623360066970347\n",
      "train loss:0.02205952771045786\n",
      "train loss:0.020372302215325475\n",
      "train loss:0.06215122745441523\n",
      "train loss:0.026788209655972874\n",
      "train loss:0.01878295646113394\n",
      "train loss:0.017944591252142875\n",
      "train loss:0.011740726386265886\n",
      "train loss:0.02837487241462865\n",
      "train loss:0.022336762324429046\n",
      "train loss:0.03548229326187979\n",
      "train loss:0.014083581528597433\n",
      "train loss:0.023891677195456734\n",
      "train loss:0.0037742048022104983\n",
      "train loss:0.011469303541958336\n",
      "train loss:0.09875054524233443\n",
      "train loss:0.016438909740602317\n",
      "train loss:0.0036629971666216695\n",
      "train loss:0.007832691301474268\n",
      "train loss:0.004479032564354693\n",
      "train loss:0.05216885125705197\n",
      "train loss:0.07060514856967857\n",
      "train loss:0.1497213352734085\n",
      "train loss:0.022916203347171326\n",
      "train loss:0.01430742163251859\n",
      "train loss:0.021261912520228306\n",
      "train loss:0.019098561146134455\n",
      "train loss:0.00959771434528417\n",
      "train loss:0.06600900028652835\n",
      "train loss:0.01193938968845693\n",
      "train loss:0.028921160978987316\n",
      "train loss:0.0366574113785065\n",
      "train loss:0.051700252186059066\n",
      "train loss:0.03294419054811885\n",
      "train loss:0.020088180327072148\n",
      "train loss:0.015080418917297446\n",
      "train loss:0.008147962873741263\n",
      "train loss:0.06295983687068771\n",
      "train loss:0.07474666259984061\n",
      "train loss:0.023466076502764888\n",
      "train loss:0.016561683677906964\n",
      "train loss:0.014824561895440265\n",
      "train loss:0.02223247728909629\n",
      "train loss:0.04834711286280276\n",
      "train loss:0.03978962210855903\n",
      "train loss:0.016447463899124062\n",
      "train loss:0.02582992559211374\n",
      "train loss:0.04326327511402747\n",
      "train loss:0.018452578319735354\n",
      "train loss:0.017266037153078544\n",
      "train loss:0.06989927763921303\n",
      "train loss:0.002353132910149174\n",
      "train loss:0.05925897001596399\n",
      "train loss:0.06927638182708896\n",
      "train loss:0.007849929553592443\n",
      "train loss:0.009552535884631612\n",
      "train loss:0.0046243490077990095\n",
      "train loss:0.017766729934512435\n",
      "train loss:0.019392315429109856\n",
      "train loss:0.02314785564866969\n",
      "train loss:0.048460601410559245\n",
      "train loss:0.04787127386322041\n",
      "train loss:0.026493653445231368\n",
      "train loss:0.007359689811072338\n",
      "train loss:0.010908627488626572\n",
      "train loss:0.006468731995675921\n",
      "train loss:0.024531813183749952\n",
      "train loss:0.007868591933567383\n",
      "train loss:0.18003904579320104\n",
      "train loss:0.008947101558512284\n",
      "train loss:0.00788721057341524\n",
      "train loss:0.005585575714481032\n",
      "train loss:0.029245094108251036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.014909254493841208\n",
      "train loss:0.015153166696533984\n",
      "train loss:0.013016148156344243\n",
      "train loss:0.057828146010216214\n",
      "train loss:0.008840709093712058\n",
      "train loss:0.012548932972383702\n",
      "train loss:0.0294790693066276\n",
      "train loss:0.011524104395927883\n",
      "train loss:0.008881848868216663\n",
      "train loss:0.024308780578535947\n",
      "train loss:0.035316196637234884\n",
      "train loss:0.016819312938208035\n",
      "train loss:0.03310668081108322\n",
      "train loss:0.056773127926245615\n",
      "train loss:0.04162491240028054\n",
      "train loss:0.031828352267898284\n",
      "train loss:0.007162646309072878\n",
      "train loss:0.004516003617303097\n",
      "train loss:0.055717812345294215\n",
      "train loss:0.030604458893360907\n",
      "train loss:0.032305745746121176\n",
      "train loss:0.031042159374388967\n",
      "train loss:0.07305199714739218\n",
      "train loss:0.01389871582624274\n",
      "train loss:0.030654130198794805\n",
      "train loss:0.01229025705859989\n",
      "train loss:0.05947971133243315\n",
      "train loss:0.027963913471064878\n",
      "train loss:0.027850214893072583\n",
      "train loss:0.025241041022017078\n",
      "train loss:0.02020046526293398\n",
      "train loss:0.007918410987217664\n",
      "train loss:0.017787118774628054\n",
      "train loss:0.04958776718502128\n",
      "train loss:0.01401165072081584\n",
      "train loss:0.05699571698675234\n",
      "train loss:0.008207007455353795\n",
      "train loss:0.029424752328829823\n",
      "train loss:0.009936465406226171\n",
      "train loss:0.022021034544714883\n",
      "train loss:0.009931996795457011\n",
      "train loss:0.031046283233865716\n",
      "train loss:0.04012447144774743\n",
      "train loss:0.006259789914651847\n",
      "train loss:0.12703197479014838\n",
      "train loss:0.05887695775889746\n",
      "train loss:0.0238880496246044\n",
      "train loss:0.0265598971405957\n",
      "train loss:0.06201960613027148\n",
      "train loss:0.004558918297292241\n",
      "train loss:0.008796834684961102\n",
      "train loss:0.016177149037870642\n",
      "train loss:0.039365200269951627\n",
      "train loss:0.03582859315815335\n",
      "train loss:0.010093153283047116\n",
      "train loss:0.012210941560102629\n",
      "train loss:0.021023386727179228\n",
      "train loss:0.023884137833165626\n",
      "train loss:0.015774648140730582\n",
      "train loss:0.02976341756122892\n",
      "train loss:0.006492533984916481\n",
      "train loss:0.038797367057456913\n",
      "train loss:0.01652086885148596\n",
      "train loss:0.014529256691216146\n",
      "train loss:0.01924709088042046\n",
      "train loss:0.006366905930911378\n",
      "train loss:0.006786176033117303\n",
      "train loss:0.022400227498003685\n",
      "train loss:0.029862950459309232\n",
      "train loss:0.04350765549856254\n",
      "train loss:0.007833128183073905\n",
      "train loss:0.010671628920060256\n",
      "train loss:0.01159504532527555\n",
      "train loss:0.032864221635557606\n",
      "train loss:0.016083950573648385\n",
      "train loss:0.010456721675996395\n",
      "train loss:0.030007592778725917\n",
      "train loss:0.0025891862708707246\n",
      "train loss:0.020071421938793566\n",
      "train loss:0.03458431964052748\n",
      "train loss:0.035799337740614084\n",
      "train loss:0.03360098728600824\n",
      "train loss:0.007055438129204142\n",
      "train loss:0.011459974257518952\n",
      "train loss:0.011122204328390107\n",
      "train loss:0.036844439860237846\n",
      "train loss:0.006858148958707649\n",
      "train loss:0.034307020751288615\n",
      "train loss:0.00938893543097832\n",
      "train loss:0.03101287128419532\n",
      "train loss:0.007039895319887952\n",
      "train loss:0.0780897972961039\n",
      "train loss:0.011424730442068156\n",
      "train loss:0.02834620427574762\n",
      "train loss:0.02469419329515427\n",
      "train loss:0.01866115013548458\n",
      "train loss:0.059051321548282534\n",
      "train loss:0.04010030537276706\n",
      "train loss:0.010353630814009163\n",
      "train loss:0.030673208108082158\n",
      "train loss:0.009267761075204127\n",
      "train loss:0.010327895881410913\n",
      "train loss:0.04117456385788984\n",
      "train loss:0.008492336327235873\n",
      "train loss:0.009301152151700692\n",
      "train loss:0.07539163928797464\n",
      "train loss:0.04403568964108384\n",
      "train loss:0.014159125657038262\n",
      "train loss:0.05905228865986015\n",
      "train loss:0.037449224944058876\n",
      "train loss:0.04036516888556287\n",
      "train loss:0.03465824873931314\n",
      "train loss:0.00992710118463243\n",
      "train loss:0.046648993424539764\n",
      "train loss:0.0193695165879132\n",
      "train loss:0.09816200043677577\n",
      "train loss:0.02947082114343006\n",
      "train loss:0.017434275625727372\n",
      "train loss:0.02586341571821544\n",
      "train loss:0.012853840927254202\n",
      "train loss:0.015059576220099338\n",
      "train loss:0.0040211577717972\n",
      "train loss:0.008363995975082418\n",
      "train loss:0.009947638088789054\n",
      "train loss:0.00574542973651829\n",
      "train loss:0.01585747287518423\n",
      "train loss:0.014859503912302412\n",
      "train loss:0.007548719558366668\n",
      "train loss:0.03317136270235108\n",
      "train loss:0.007299678632313328\n",
      "train loss:0.00890952483506058\n",
      "train loss:0.01290797266615639\n",
      "train loss:0.02553409913192139\n",
      "train loss:0.02233659469270214\n",
      "train loss:0.022081685283536698\n",
      "train loss:0.0036961041436906626\n",
      "train loss:0.02992594376988018\n",
      "train loss:0.03202434309256185\n",
      "train loss:0.02247762502723495\n",
      "train loss:0.025476335720943624\n",
      "train loss:0.17862295993327987\n",
      "train loss:0.006460610771121546\n",
      "train loss:0.016002369884190012\n",
      "train loss:0.007423952180726878\n",
      "train loss:0.005881405270421192\n",
      "train loss:0.00562925414005003\n",
      "train loss:0.01478564018398259\n",
      "train loss:0.038206351644761286\n",
      "train loss:0.007907986668158076\n",
      "train loss:0.005017993941973637\n",
      "train loss:0.012382358568341682\n",
      "train loss:0.022516307431102667\n",
      "train loss:0.022254247866162306\n",
      "train loss:0.02437026179017551\n",
      "train loss:0.005324939587430029\n",
      "train loss:0.005942280466509169\n",
      "train loss:0.014888638787330377\n",
      "train loss:0.010359104052584478\n",
      "train loss:0.004890969503608702\n",
      "train loss:0.01235413623841252\n",
      "train loss:0.04170472917681635\n",
      "train loss:0.04747773250667785\n",
      "train loss:0.01612927310573669\n",
      "train loss:0.008634292728696752\n",
      "train loss:0.0032189306084455306\n",
      "train loss:0.03236852870191152\n",
      "train loss:0.015405763398447639\n",
      "train loss:0.011048447631347635\n",
      "train loss:0.008715085427452219\n",
      "train loss:0.006310470813634013\n",
      "train loss:0.0029516191167876927\n",
      "train loss:0.0282822145076907\n",
      "train loss:0.020613109150937885\n",
      "train loss:0.052795879562956075\n",
      "train loss:0.010118544868596573\n",
      "train loss:0.002615413101506264\n",
      "train loss:0.005082803099932253\n",
      "train loss:0.009262695675399309\n",
      "train loss:0.006574811303689281\n",
      "train loss:0.010190889023337766\n",
      "train loss:0.030158755577519195\n",
      "train loss:0.030709723375570624\n",
      "train loss:0.006722335651245974\n",
      "train loss:0.01487381560003044\n",
      "train loss:0.04772548967593922\n",
      "train loss:0.018871767916382672\n",
      "train loss:0.01345207175206395\n",
      "train loss:0.00731595140580396\n",
      "train loss:0.004088928522800336\n",
      "train loss:0.01813839979152398\n",
      "train loss:0.026509435873493727\n",
      "train loss:0.030389549483864707\n",
      "train loss:0.006753654030347156\n",
      "train loss:0.004550862698334475\n",
      "train loss:0.029600478893805234\n",
      "train loss:0.05631107004864659\n",
      "train loss:0.01353955381947232\n",
      "train loss:0.0643425476630875\n",
      "train loss:0.0051729832073740675\n",
      "train loss:0.025830428765688494\n",
      "train loss:0.023992220906984926\n",
      "train loss:0.05474688989627152\n",
      "train loss:0.004902209400877861\n",
      "train loss:0.05497826343211756\n",
      "train loss:0.03538469681838849\n",
      "train loss:0.029688159285442613\n",
      "train loss:0.02170470503862211\n",
      "train loss:0.024111348104466204\n",
      "train loss:0.01231034660647348\n",
      "train loss:0.029417171924928587\n",
      "train loss:0.04191024246623404\n",
      "train loss:0.01181983985294867\n",
      "train loss:0.004590954779465819\n",
      "train loss:0.00985671484912924\n",
      "train loss:0.036856833169339416\n",
      "train loss:0.05841541271744236\n",
      "train loss:0.005659062736634327\n",
      "train loss:0.019656385961191535\n",
      "train loss:0.007615519678080982\n",
      "train loss:0.0877710206495128\n",
      "train loss:0.033889805589328886\n",
      "train loss:0.011540969252011852\n",
      "train loss:0.03242300616825537\n",
      "train loss:0.004601578850972701\n",
      "train loss:0.02118024673795996\n",
      "train loss:0.01872072988566886\n",
      "train loss:0.00813540794799041\n",
      "train loss:0.0772811738572161\n",
      "train loss:0.02417734876060757\n",
      "train loss:0.014939175463962779\n",
      "train loss:0.010609360641466076\n",
      "train loss:0.004299324939590763\n",
      "train loss:0.018792144133504097\n",
      "train loss:0.02843249548991245\n",
      "train loss:0.02271412622862986\n",
      "train loss:0.05241243950974482\n",
      "train loss:0.004736966255061615\n",
      "train loss:0.030585597321373094\n",
      "train loss:0.03618229864137292\n",
      "train loss:0.023143773119840772\n",
      "train loss:0.019205560603694924\n",
      "train loss:0.018596425632361045\n",
      "train loss:0.009192077908829515\n",
      "train loss:0.030637662149582082\n",
      "train loss:0.027121527891248123\n",
      "train loss:0.020266392498636206\n",
      "train loss:0.03758421376067477\n",
      "train loss:0.028519175777630426\n",
      "train loss:0.010093570700887993\n",
      "train loss:0.020783671615560252\n",
      "train loss:0.027136071765939934\n",
      "train loss:0.009725681591589857\n",
      "train loss:0.02215197164236272\n",
      "train loss:0.03601853267857023\n",
      "train loss:0.02447958608226529\n",
      "train loss:0.01100752298125892\n",
      "train loss:0.007553280836659424\n",
      "train loss:0.1669135916335412\n",
      "train loss:0.018409038594437616\n",
      "train loss:0.013243668658426286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06888255893289409\n",
      "train loss:0.008455812957338257\n",
      "train loss:0.05324502074740744\n",
      "train loss:0.01258594825389018\n",
      "train loss:0.026459022721207273\n",
      "train loss:0.023378112709393634\n",
      "train loss:0.011930939004635878\n",
      "train loss:0.01970291270314138\n",
      "train loss:0.08987356794327699\n",
      "train loss:0.015903493247934785\n",
      "train loss:0.017327998847975413\n",
      "train loss:0.014445209463835103\n",
      "train loss:0.011737252355592783\n",
      "train loss:0.011751697007722082\n",
      "train loss:0.020264313831214853\n",
      "train loss:0.021773799868920057\n",
      "train loss:0.08752736264971686\n",
      "train loss:0.01791428736530375\n",
      "train loss:0.02962726616685417\n",
      "train loss:0.023545129891658786\n",
      "train loss:0.04956645862002928\n",
      "train loss:0.012399889119030415\n",
      "train loss:0.03392412192445235\n",
      "train loss:0.06365771203415302\n",
      "train loss:0.010026234848637709\n",
      "train loss:0.01666576408537561\n",
      "train loss:0.020383204101450624\n",
      "train loss:0.01601894365028353\n",
      "train loss:0.03329985861929936\n",
      "train loss:0.01127830249407092\n",
      "train loss:0.01972853127131884\n",
      "train loss:0.02225987899809023\n",
      "train loss:0.019572211660398384\n",
      "train loss:0.011432366640383673\n",
      "train loss:0.05477822194945046\n",
      "train loss:0.004834351249505989\n",
      "train loss:0.0052671372361383665\n",
      "train loss:0.012247186400334453\n",
      "train loss:0.04883590886877659\n",
      "train loss:0.016251348312825323\n",
      "train loss:0.025292708131386128\n",
      "train loss:0.03438635406463297\n",
      "train loss:0.01720090155700281\n",
      "train loss:0.02607755345156537\n",
      "train loss:0.006858422613793472\n",
      "train loss:0.01185887295930369\n",
      "train loss:0.0188587111090439\n",
      "train loss:0.05888552753688437\n",
      "train loss:0.015379576127587693\n",
      "train loss:0.002667548505827536\n",
      "train loss:0.01177725324669462\n",
      "train loss:0.028960951430454896\n",
      "train loss:0.016037280689520525\n",
      "train loss:0.010740930513531652\n",
      "train loss:0.016393370793590118\n",
      "train loss:0.010139000255062078\n",
      "train loss:0.006201268074503422\n",
      "train loss:0.03112752064987398\n",
      "train loss:0.05511656895422202\n",
      "train loss:0.009107829493781356\n",
      "train loss:0.031054604535525932\n",
      "train loss:0.014447139680734548\n",
      "train loss:0.008720528033722162\n",
      "train loss:0.035157609227798654\n",
      "train loss:0.07833988802933371\n",
      "train loss:0.012434048249156752\n",
      "train loss:0.046987314560778655\n",
      "train loss:0.02765348964616174\n",
      "train loss:0.011910809328078436\n",
      "train loss:0.011533049105421586\n",
      "train loss:0.03646831272053098\n",
      "train loss:0.01268578108816752\n",
      "train loss:0.026931484086375485\n",
      "train loss:0.006206760179512709\n",
      "train loss:0.044304825610335274\n",
      "train loss:0.0048316727326048504\n",
      "train loss:0.02830875390911312\n",
      "train loss:0.027249660693183242\n",
      "train loss:0.03187466921248407\n",
      "train loss:0.004322167037170668\n",
      "train loss:0.030875994346117007\n",
      "train loss:0.027665290177494337\n",
      "train loss:0.03160188911042254\n",
      "train loss:0.027162314206178175\n",
      "train loss:0.028211729418876362\n",
      "train loss:0.020917788451835048\n",
      "train loss:0.010761161342885905\n",
      "train loss:0.032332455588237836\n",
      "train loss:0.07663570477060576\n",
      "train loss:0.006056403166171007\n",
      "train loss:0.00605702322201764\n",
      "train loss:0.022251309073799436\n",
      "train loss:0.009386941066699038\n",
      "train loss:0.013439694824255506\n",
      "train loss:0.012963099596694488\n",
      "train loss:0.07144036622920144\n",
      "train loss:0.01674762300938198\n",
      "train loss:0.05862258459960085\n",
      "train loss:0.0035522780213072393\n",
      "train loss:0.019205080039238164\n",
      "train loss:0.024402795849660798\n",
      "train loss:0.009981616830676469\n",
      "train loss:0.017846611843427514\n",
      "train loss:0.05439214926633386\n",
      "train loss:0.01814572483179278\n",
      "train loss:0.006366389486212636\n",
      "train loss:0.006854005263929437\n",
      "train loss:0.02913991708220227\n",
      "=== epoch:6, train acc:0.987, test acc:0.987 ===\n",
      "train loss:0.006806673105297416\n",
      "train loss:0.11225183014239962\n",
      "train loss:0.02949908951894726\n",
      "train loss:0.05874536645440026\n",
      "train loss:0.0060319660418456725\n",
      "train loss:0.04924095156837034\n",
      "train loss:0.010320399534911196\n",
      "train loss:0.11139027605268169\n",
      "train loss:0.020422834059386406\n",
      "train loss:0.0030747845427205457\n",
      "train loss:0.02190792018980503\n",
      "train loss:0.013072926208729012\n",
      "train loss:0.02605388004134311\n",
      "train loss:0.010214876007829589\n",
      "train loss:0.0071827783624726525\n",
      "train loss:0.030055670924888304\n",
      "train loss:0.032971679127720484\n",
      "train loss:0.027523369596218955\n",
      "train loss:0.015516021905502591\n",
      "train loss:0.01153364683773276\n",
      "train loss:0.018607680295982688\n",
      "train loss:0.012378828314205805\n",
      "train loss:0.013708892388755483\n",
      "train loss:0.01407122936051819\n",
      "train loss:0.023509701230379862\n",
      "train loss:0.014930505400130157\n",
      "train loss:0.0034771323724155866\n",
      "train loss:0.008240013570270883\n",
      "train loss:0.008271446197593992\n",
      "train loss:0.01665119408078503\n",
      "train loss:0.023838937829330806\n",
      "train loss:0.016031773124990684\n",
      "train loss:0.02244933997954598\n",
      "train loss:0.028455968691335\n",
      "train loss:0.014165698580988628\n",
      "train loss:0.017503048410546326\n",
      "train loss:0.017400712705713847\n",
      "train loss:0.002495656826588792\n",
      "train loss:0.00983643513504261\n",
      "train loss:0.008575083082687101\n",
      "train loss:0.07247447636114862\n",
      "train loss:0.014993561941471894\n",
      "train loss:0.0370183837084183\n",
      "train loss:0.007550782294606522\n",
      "train loss:0.013907473825017592\n",
      "train loss:0.05324873540233322\n",
      "train loss:0.02354827343788719\n",
      "train loss:0.04925850114841486\n",
      "train loss:0.014934432209878255\n",
      "train loss:0.006620754322625706\n",
      "train loss:0.02125084677694745\n",
      "train loss:0.014142502671685691\n",
      "train loss:0.02277522802921761\n",
      "train loss:0.014744013445608528\n",
      "train loss:0.010862139242676917\n",
      "train loss:0.01015573544799958\n",
      "train loss:0.06420930270836753\n",
      "train loss:0.018398986026874554\n",
      "train loss:0.005522465595499547\n",
      "train loss:0.009886766559518877\n",
      "train loss:0.009787136630057695\n",
      "train loss:0.009581365131213325\n",
      "train loss:0.010361756116156666\n",
      "train loss:0.028724210968413724\n",
      "train loss:0.008279741013360955\n",
      "train loss:0.006593769446002391\n",
      "train loss:0.019308513018741816\n",
      "train loss:0.028748336673174488\n",
      "train loss:0.02690420723696758\n",
      "train loss:0.005657919995179923\n",
      "train loss:0.012858872803543357\n",
      "train loss:0.01159071649834182\n",
      "train loss:0.012490961337655638\n",
      "train loss:0.013147518196975565\n",
      "train loss:0.022246651575914923\n",
      "train loss:0.01055297300077695\n",
      "train loss:0.019762144610823772\n",
      "train loss:0.07472001341778987\n",
      "train loss:0.0038687210157642028\n",
      "train loss:0.009778122821923661\n",
      "train loss:0.007145860218016073\n",
      "train loss:0.05029617173326947\n",
      "train loss:0.016023701119138516\n",
      "train loss:0.013944896264007254\n",
      "train loss:0.029221948561640523\n",
      "train loss:0.02346980560646443\n",
      "train loss:0.0503943790398305\n",
      "train loss:0.027160539745621878\n",
      "train loss:0.022092155871309544\n",
      "train loss:0.0068841248905958715\n",
      "train loss:0.016671976672061942\n",
      "train loss:0.0037029315626029027\n",
      "train loss:0.017125698903796047\n",
      "train loss:0.006228429975635472\n",
      "train loss:0.011448565418003378\n",
      "train loss:0.011708089407754672\n",
      "train loss:0.02929625199157512\n",
      "train loss:0.038423884768419694\n",
      "train loss:0.017001377198371893\n",
      "train loss:0.050557695196559296\n",
      "train loss:0.06406249249388338\n",
      "train loss:0.055522651608357475\n",
      "train loss:0.035031910240527014\n",
      "train loss:0.08093646156814813\n",
      "train loss:0.0058437039111654855\n",
      "train loss:0.005381948172965854\n",
      "train loss:0.08311920447688387\n",
      "train loss:0.02743316314572324\n",
      "train loss:0.016157194460944217\n",
      "train loss:0.014352286407603044\n",
      "train loss:0.04030465427936866\n",
      "train loss:0.06354072733009365\n",
      "train loss:0.019373927705590682\n",
      "train loss:0.0039863604533255685\n",
      "train loss:0.005709220597030011\n",
      "train loss:0.012498874387238273\n",
      "train loss:0.030727969221785206\n",
      "train loss:0.007714811503751434\n",
      "train loss:0.022934385053155718\n",
      "train loss:0.0879388579224468\n",
      "train loss:0.013577612248398395\n",
      "train loss:0.010393675150067005\n",
      "train loss:0.02543361415275578\n",
      "train loss:0.007117777973497156\n",
      "train loss:0.04783383398173555\n",
      "train loss:0.013829701633792888\n",
      "train loss:0.019614306248538094\n",
      "train loss:0.017619373577616143\n",
      "train loss:0.014445643765379025\n",
      "train loss:0.03935201127984368\n",
      "train loss:0.012915388563989043\n",
      "train loss:0.036054340318870726\n",
      "train loss:0.006769323959143617\n",
      "train loss:0.009233684169576673\n",
      "train loss:0.017955234856913267\n",
      "train loss:0.008385908936499022\n",
      "train loss:0.01490866068428112\n",
      "train loss:0.017526761998545446\n",
      "train loss:0.021226201637471905\n",
      "train loss:0.03936990061021383\n",
      "train loss:0.054450907433453856\n",
      "train loss:0.011798275193834995\n",
      "train loss:0.03944693261196216\n",
      "train loss:0.018004273090136736\n",
      "train loss:0.023109896195506786\n",
      "train loss:0.029353578349801387\n",
      "train loss:0.002609513642679073\n",
      "train loss:0.0384873714667453\n",
      "train loss:0.037785240474255286\n",
      "train loss:0.023990597095813974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.018887327989306667\n",
      "train loss:0.03454382352784187\n",
      "train loss:0.011257632601095007\n",
      "train loss:0.007700513803517222\n",
      "train loss:0.05835820320700513\n",
      "train loss:0.011510733052734083\n",
      "train loss:0.010624942593772349\n",
      "train loss:0.012483429945831981\n",
      "train loss:0.03190998678305103\n",
      "train loss:0.01482258516501462\n",
      "train loss:0.010668627924791412\n",
      "train loss:0.04679769132141194\n",
      "train loss:0.008958718446995622\n",
      "train loss:0.029242711961927906\n",
      "train loss:0.01497643669542063\n",
      "train loss:0.006856894413000114\n",
      "train loss:0.014344351398329323\n",
      "train loss:0.014601267959287925\n",
      "train loss:0.023883740756349314\n",
      "train loss:0.016065117598958747\n",
      "train loss:0.04809368891751855\n",
      "train loss:0.004485602647402197\n",
      "train loss:0.022212307084948216\n",
      "train loss:0.03399848091911927\n",
      "train loss:0.008351795046837883\n",
      "train loss:0.004700777306922731\n",
      "train loss:0.015574936866492872\n",
      "train loss:0.011411155744420157\n",
      "train loss:0.09922220907164238\n",
      "train loss:0.03668389079318627\n",
      "train loss:0.017958175533574688\n",
      "train loss:0.003581356384431042\n",
      "train loss:0.014155487737539295\n",
      "train loss:0.023368468015708566\n",
      "train loss:0.0028693695820738996\n",
      "train loss:0.009000414461136315\n",
      "train loss:0.00328332179526161\n",
      "train loss:0.005841213254815205\n",
      "train loss:0.020933541819024817\n",
      "train loss:0.011549220221208467\n",
      "train loss:0.006803747292077491\n",
      "train loss:0.01616366877519237\n",
      "train loss:0.01205032015050795\n",
      "train loss:0.08573323583292561\n",
      "train loss:0.0128603046121812\n",
      "train loss:0.03670471959389636\n",
      "train loss:0.012081887428322828\n",
      "train loss:0.008341485721091186\n",
      "train loss:0.01031738532115896\n",
      "train loss:0.007469438122313171\n",
      "train loss:0.006809019365849479\n",
      "train loss:0.008522484500953572\n",
      "train loss:0.0046923187108092075\n",
      "train loss:0.009114060238824273\n",
      "train loss:0.008350743455541461\n",
      "train loss:0.00639848908460377\n",
      "train loss:0.004906894732288336\n",
      "train loss:0.011202105691560058\n",
      "train loss:0.004728318927038608\n",
      "train loss:0.042562936962425094\n",
      "train loss:0.00809166813204281\n",
      "train loss:0.005573335797422961\n",
      "train loss:0.004879969467455533\n",
      "train loss:0.002721506331651209\n",
      "train loss:0.010572762675797652\n",
      "train loss:0.009929918648631022\n",
      "train loss:0.005898883846533904\n",
      "train loss:0.0010344227307858439\n",
      "train loss:0.010173604847570772\n",
      "train loss:0.015595176295481279\n",
      "train loss:0.004334171538418277\n",
      "train loss:0.007105585719025158\n",
      "train loss:0.01719411102960515\n",
      "train loss:0.004142943799567895\n",
      "train loss:0.008148503058289333\n",
      "train loss:0.002205830042612205\n",
      "train loss:0.019153179747482506\n",
      "train loss:0.009587652668317155\n",
      "train loss:0.007183825700842956\n",
      "train loss:0.0016819871097325995\n",
      "train loss:0.023316377899283803\n",
      "train loss:0.009648241439289093\n",
      "train loss:0.009181452778595573\n",
      "train loss:0.05299496626046186\n",
      "train loss:0.017713802074423406\n",
      "train loss:0.005625720603931311\n",
      "train loss:0.009533384198839817\n",
      "train loss:0.015948689227769673\n",
      "train loss:0.008633012505126015\n",
      "train loss:0.005917598419772634\n",
      "train loss:0.008439231336961452\n",
      "train loss:0.009273717560780778\n",
      "train loss:0.01152179976594603\n",
      "train loss:0.0532814262980746\n",
      "train loss:0.008234404902194592\n",
      "train loss:0.002484644770529416\n",
      "train loss:0.029894051411663094\n",
      "train loss:0.0017005673752564327\n",
      "train loss:0.03568881885420991\n",
      "train loss:0.007188898831423793\n",
      "train loss:0.014486301612120545\n",
      "train loss:0.017199140474446546\n",
      "train loss:0.006749485570860647\n",
      "train loss:0.0030418630985062627\n",
      "train loss:0.004999150631971255\n",
      "train loss:0.0025928548160943214\n",
      "train loss:0.011247292431535166\n",
      "train loss:0.005199419789202681\n",
      "train loss:0.002494547144615986\n",
      "train loss:0.014323941189944768\n",
      "train loss:0.004322735325455748\n",
      "train loss:0.0034913479805341596\n",
      "train loss:0.004693623825042518\n",
      "train loss:0.011811575953332315\n",
      "train loss:0.01986432485377921\n",
      "train loss:0.0074957506750672285\n",
      "train loss:0.03109034273449628\n",
      "train loss:0.018387462224978154\n",
      "train loss:0.02477765696440618\n",
      "train loss:0.009566792008361531\n",
      "train loss:0.0062498286240454245\n",
      "train loss:0.03612236296979023\n",
      "train loss:0.009110037382973904\n",
      "train loss:0.06271418395729153\n",
      "train loss:0.03696239439054158\n",
      "train loss:0.019426008072202534\n",
      "train loss:0.017068920665715432\n",
      "train loss:0.010136247460764138\n",
      "train loss:0.003030903952765455\n",
      "train loss:0.01040688325146582\n",
      "train loss:0.007934701113494655\n",
      "train loss:0.025522267009891183\n",
      "train loss:0.07704969107341207\n",
      "train loss:0.0034823210063685463\n",
      "train loss:0.030350512437854974\n",
      "train loss:0.01760690366210207\n",
      "train loss:0.010813709773363584\n",
      "train loss:0.007901798380481294\n",
      "train loss:0.0025525643110707193\n",
      "train loss:0.003679097537177303\n",
      "train loss:0.0330320317023998\n",
      "train loss:0.008848907879594801\n",
      "train loss:0.01960457593265363\n",
      "train loss:0.02344637250280719\n",
      "train loss:0.010787497936536961\n",
      "train loss:0.005096711217020727\n",
      "train loss:0.03251335002142132\n",
      "train loss:0.009094693129744561\n",
      "train loss:0.042250507908334976\n",
      "train loss:0.013983253456615824\n",
      "train loss:0.010975664840330064\n",
      "train loss:0.006979390570551185\n",
      "train loss:0.007754998956582756\n",
      "train loss:0.01910028188247742\n",
      "train loss:0.005414877721739226\n",
      "train loss:0.009126817704421721\n",
      "train loss:0.01717407668322248\n",
      "train loss:0.010359739101527132\n",
      "train loss:0.009060341138240703\n",
      "train loss:0.006314405599794224\n",
      "train loss:0.0025423231120074085\n",
      "train loss:0.010030880046885998\n",
      "train loss:0.04825513262403334\n",
      "train loss:0.007709280369812047\n",
      "train loss:0.03648515571388624\n",
      "train loss:0.00890420924051854\n",
      "train loss:0.0034287863032708226\n",
      "train loss:0.015098918380076909\n",
      "train loss:0.030953468267741913\n",
      "train loss:0.003446272989530196\n",
      "train loss:0.024997653529915568\n",
      "train loss:0.0112191852813733\n",
      "train loss:0.011145965100947917\n",
      "train loss:0.0486346698168139\n",
      "train loss:0.005733760276819777\n",
      "train loss:0.009444659005893828\n",
      "train loss:0.015650760348950167\n",
      "train loss:0.0186994620258848\n",
      "train loss:0.020695298148755575\n",
      "train loss:0.03392814056129452\n",
      "train loss:0.008572600315136979\n",
      "train loss:0.01226364214824947\n",
      "train loss:0.006129882928657547\n",
      "train loss:0.038917043275380266\n",
      "train loss:0.040566833322251535\n",
      "train loss:0.04018639321153723\n",
      "train loss:0.008186243874808341\n",
      "train loss:0.08753107067800776\n",
      "train loss:0.00972295008674279\n",
      "train loss:0.006570702602251153\n",
      "train loss:0.0064758371724863715\n",
      "train loss:0.002660382359132793\n",
      "train loss:0.026144526112895364\n",
      "train loss:0.06284295589485717\n",
      "train loss:0.010582341876886255\n",
      "train loss:0.023208231207220945\n",
      "train loss:0.006675040100999404\n",
      "train loss:0.01935684075465053\n",
      "train loss:0.00785077360403057\n",
      "train loss:0.00600771807798472\n",
      "train loss:0.03053776024534187\n",
      "train loss:0.023028613267538293\n",
      "train loss:0.0035838016315596554\n",
      "train loss:0.006412720121248784\n",
      "train loss:0.017507498168291682\n",
      "train loss:0.019778677324296143\n",
      "train loss:0.022722373476093547\n",
      "train loss:0.005324347897290367\n",
      "train loss:0.007302962176632821\n",
      "train loss:0.05780933174294807\n",
      "train loss:0.003983052545260678\n",
      "train loss:0.011193741697802484\n",
      "train loss:0.033024426019541184\n",
      "train loss:0.00275911038752496\n",
      "train loss:0.013154091939590197\n",
      "train loss:0.004270987748908582\n",
      "train loss:0.01460539929641035\n",
      "train loss:0.01233175894646885\n",
      "train loss:0.010742620273143978\n",
      "train loss:0.008319431514274897\n",
      "train loss:0.013951485548454217\n",
      "train loss:0.021858035661201744\n",
      "train loss:0.010630119570259658\n",
      "train loss:0.007556859195333797\n",
      "train loss:0.01711608766711923\n",
      "train loss:0.03071363538082494\n",
      "train loss:0.016949829164286417\n",
      "train loss:0.014036970947381123\n",
      "train loss:0.008196422646202227\n",
      "train loss:0.03748891927180471\n",
      "train loss:0.11682891989543646\n",
      "train loss:0.0066533955861926165\n",
      "train loss:0.05165454755236002\n",
      "train loss:0.01577211284280434\n",
      "train loss:0.018870668307975413\n",
      "train loss:0.017091557700589233\n",
      "train loss:0.011586046160100439\n",
      "train loss:0.010010925088933644\n",
      "train loss:0.02895106631543746\n",
      "train loss:0.0072020785266061595\n",
      "train loss:0.02423945053949155\n",
      "train loss:0.010174103719444709\n",
      "train loss:0.011236204797619094\n",
      "train loss:0.010635207105296243\n",
      "train loss:0.014329296558019441\n",
      "train loss:0.010518362809994124\n",
      "train loss:0.008131592777377789\n",
      "train loss:0.004133778213223482\n",
      "train loss:0.07358386866756172\n",
      "train loss:0.012099524530659876\n",
      "train loss:0.007632754114862892\n",
      "train loss:0.002571730935009546\n",
      "train loss:0.02443991317845792\n",
      "train loss:0.02228385403133006\n",
      "train loss:0.03281079796701122\n",
      "train loss:0.01284809606876746\n",
      "train loss:0.0313581215865551\n",
      "train loss:0.018260611882567616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.009731620277339606\n",
      "train loss:0.025985563161420464\n",
      "train loss:0.015418433288278166\n",
      "train loss:0.02352839219978208\n",
      "train loss:0.04776881179984421\n",
      "train loss:0.004320983746322974\n",
      "train loss:0.005711001745961087\n",
      "train loss:0.016225029067142144\n",
      "train loss:0.009842930480423116\n",
      "train loss:0.008653142289658453\n",
      "train loss:0.009017668850492891\n",
      "train loss:0.019517874662180527\n",
      "train loss:0.02735025758794613\n",
      "train loss:0.013496696115204827\n",
      "train loss:0.027368375173640228\n",
      "train loss:0.005589111331899076\n",
      "train loss:0.025981443823564578\n",
      "train loss:0.02566414139429447\n",
      "train loss:0.004599245149369488\n",
      "train loss:0.018329229339998906\n",
      "train loss:0.07347683369468014\n",
      "train loss:0.007022037822141875\n",
      "train loss:0.0226212199018214\n",
      "train loss:0.003542894228676112\n",
      "train loss:0.010402121165142558\n",
      "train loss:0.009175495484379593\n",
      "train loss:0.010252096875403434\n",
      "train loss:0.03934463938172865\n",
      "train loss:0.009416718192001738\n",
      "train loss:0.01495452483120497\n",
      "train loss:0.015223907910138479\n",
      "train loss:0.038732519465017816\n",
      "train loss:0.00754785424581374\n",
      "train loss:0.010099693772520527\n",
      "train loss:0.004237463435644834\n",
      "train loss:0.006570882068299169\n",
      "train loss:0.019812740916692023\n",
      "train loss:0.0035219916910059932\n",
      "train loss:0.01644142984362036\n",
      "train loss:0.010784108933356119\n",
      "train loss:0.003414675388537206\n",
      "train loss:0.03091465448895577\n",
      "train loss:0.031196442016695518\n",
      "train loss:0.03927490678608005\n",
      "train loss:0.03304859190265626\n",
      "train loss:0.023757033968699628\n",
      "train loss:0.0067879423196627485\n",
      "train loss:0.016827749757719352\n",
      "train loss:0.03203505742688429\n",
      "train loss:0.014216178134511981\n",
      "train loss:0.010761541098255632\n",
      "train loss:0.04532428837677911\n",
      "train loss:0.018228871002060516\n",
      "train loss:0.017392003737042572\n",
      "train loss:0.033340976389539825\n",
      "train loss:0.005209858525000025\n",
      "train loss:0.019605969957137745\n",
      "train loss:0.008173272906405267\n",
      "train loss:0.015470309491671384\n",
      "train loss:0.03716157911286504\n",
      "train loss:0.005587406993445993\n",
      "train loss:0.043881462791330324\n",
      "train loss:0.05797703972894756\n",
      "train loss:0.03154576570299427\n",
      "train loss:0.0897121359536417\n",
      "train loss:0.017444214238859522\n",
      "train loss:0.005446651170782469\n",
      "train loss:0.006131522138398828\n",
      "train loss:0.008312319943956654\n",
      "train loss:0.0023079940564282525\n",
      "train loss:0.018206551544885485\n",
      "train loss:0.03766377988752944\n",
      "train loss:0.03899061197242382\n",
      "train loss:0.01241191855613347\n",
      "train loss:0.024470563665825017\n",
      "train loss:0.014129810929116152\n",
      "train loss:0.02562027779900724\n",
      "train loss:0.004035411879395957\n",
      "train loss:0.010772693060089805\n",
      "train loss:0.026420280292855904\n",
      "train loss:0.004602476517997688\n",
      "train loss:0.024828598749486033\n",
      "train loss:0.008139453082165791\n",
      "train loss:0.045340594512095274\n",
      "train loss:0.013332172233801738\n",
      "train loss:0.012523906008491754\n",
      "train loss:0.010224017008225538\n",
      "train loss:0.008884437237850278\n",
      "train loss:0.01609404516318129\n",
      "train loss:0.012251391250208408\n",
      "train loss:0.01325790275135274\n",
      "train loss:0.015667022374573143\n",
      "train loss:0.01802495203254679\n",
      "train loss:0.02378091648815847\n",
      "train loss:0.010983369088687564\n",
      "train loss:0.029997823285717037\n",
      "train loss:0.04360929620815248\n",
      "train loss:0.004104822541275797\n",
      "train loss:0.022173322575661018\n",
      "train loss:0.005496400263106894\n",
      "train loss:0.036723451343768886\n",
      "train loss:0.03204830839197531\n",
      "train loss:0.005706985070097609\n",
      "train loss:0.014742628069687095\n",
      "train loss:0.015862466423121977\n",
      "train loss:0.046119003196753106\n",
      "train loss:0.015782212720251612\n",
      "train loss:0.05540872627703628\n",
      "train loss:0.09349117969477007\n",
      "train loss:0.05836858949908109\n",
      "train loss:0.0021661672877750066\n",
      "train loss:0.009225245217104638\n",
      "train loss:0.06838421002888286\n",
      "train loss:0.013636448268309318\n",
      "train loss:0.0047476785208590624\n",
      "train loss:0.018626155941937183\n",
      "train loss:0.026631640884472483\n",
      "train loss:0.019485515055640733\n",
      "train loss:0.005465869783377086\n",
      "train loss:0.01645326019980303\n",
      "train loss:0.028481422835318577\n",
      "train loss:0.021445853058504397\n",
      "train loss:0.021709123075085476\n",
      "train loss:0.005540271553516313\n",
      "train loss:0.027476517586915255\n",
      "train loss:0.006924313184088725\n",
      "train loss:0.03286904315409617\n",
      "train loss:0.025585509012259037\n",
      "train loss:0.006745865873026564\n",
      "train loss:0.00335318295234068\n",
      "train loss:0.011410374887920025\n",
      "train loss:0.017980337284958618\n",
      "train loss:0.004769546078372853\n",
      "train loss:0.02327925350317233\n",
      "train loss:0.008697458943263578\n",
      "train loss:0.020143861457252218\n",
      "train loss:0.008907477996034306\n",
      "train loss:0.015717527900318964\n",
      "train loss:0.10858098584168746\n",
      "train loss:0.01572463940686418\n",
      "train loss:0.0041247378211145495\n",
      "train loss:0.003519855006328811\n",
      "train loss:0.036638753280369495\n",
      "train loss:0.06641341601657619\n",
      "train loss:0.012750530297198075\n",
      "train loss:0.009902566213025953\n",
      "train loss:0.0074337501501892025\n",
      "train loss:0.010557152720066798\n",
      "train loss:0.007218748043200062\n",
      "train loss:0.021754184425639336\n",
      "train loss:0.0566673322975883\n",
      "train loss:0.023218086495466164\n",
      "train loss:0.11309848133849366\n",
      "train loss:0.03152720633634248\n",
      "train loss:0.023410942938334265\n",
      "train loss:0.05290232815893824\n",
      "train loss:0.029023879680031523\n",
      "train loss:0.029215185428774677\n",
      "train loss:0.007701788004432373\n",
      "train loss:0.020175180899952218\n",
      "train loss:0.036565939288465084\n",
      "train loss:0.017129892807066997\n",
      "train loss:0.00931499726891158\n",
      "train loss:0.006705230289543578\n",
      "train loss:0.016032027578223883\n",
      "train loss:0.015098733583506638\n",
      "train loss:0.009049737515972009\n",
      "train loss:0.08440983001338301\n",
      "train loss:0.004587128378955908\n",
      "train loss:0.011863986608277087\n",
      "train loss:0.015711801876013093\n",
      "train loss:0.03372506216376677\n",
      "train loss:0.019572089440440463\n",
      "train loss:0.03361900611616097\n",
      "train loss:0.014779575850990673\n",
      "train loss:0.03474941954570851\n",
      "train loss:0.051338441732588086\n",
      "train loss:0.0030638112214487327\n",
      "train loss:0.027718134419120674\n",
      "train loss:0.0064683768173557895\n",
      "train loss:0.01617261311473976\n",
      "train loss:0.01976082108254907\n",
      "train loss:0.003122738273366623\n",
      "train loss:0.05590091370551378\n",
      "train loss:0.040944011848304804\n",
      "train loss:0.03421687226269017\n",
      "train loss:0.013210421408508678\n",
      "train loss:0.01403385855902415\n",
      "train loss:0.007512850000206701\n",
      "train loss:0.0031305071685484047\n",
      "train loss:0.015460066419686478\n",
      "train loss:0.002847622125228926\n",
      "=== epoch:7, train acc:0.991, test acc:0.986 ===\n",
      "train loss:0.05091680429688363\n",
      "train loss:0.014596434187412797\n",
      "train loss:0.04961939655797407\n",
      "train loss:0.06815577658113654\n",
      "train loss:0.0036825847849664573\n",
      "train loss:0.08935094333528912\n",
      "train loss:0.011996274161653681\n",
      "train loss:0.010223257534210948\n",
      "train loss:0.009551484518201677\n",
      "train loss:0.012649059901648094\n",
      "train loss:0.008910612942913348\n",
      "train loss:0.027388198967353575\n",
      "train loss:0.007205075033535551\n",
      "train loss:0.016804123318592528\n",
      "train loss:0.0071924204486693575\n",
      "train loss:0.010630100497620858\n",
      "train loss:0.023007215176359196\n",
      "train loss:0.01220924346589642\n",
      "train loss:0.010976623277470409\n",
      "train loss:0.005961288397040036\n",
      "train loss:0.005955669422858389\n",
      "train loss:0.005348548367681359\n",
      "train loss:0.007340743945974953\n",
      "train loss:0.007454636872146769\n",
      "train loss:0.009554314511589702\n",
      "train loss:0.00946821522126815\n",
      "train loss:0.03235279418635259\n",
      "train loss:0.013193083679716871\n",
      "train loss:0.017961701331423885\n",
      "train loss:0.011846054771974973\n",
      "train loss:0.018192352335133277\n",
      "train loss:0.0042064761742431666\n",
      "train loss:0.0045989808037846394\n",
      "train loss:0.10007002877992682\n",
      "train loss:0.008873982445318347\n",
      "train loss:0.013879044363483086\n",
      "train loss:0.005957557153574365\n",
      "train loss:0.006591912786542959\n",
      "train loss:0.030972849289000973\n",
      "train loss:0.004692073610187943\n",
      "train loss:0.017690307344277158\n",
      "train loss:0.00527021100732344\n",
      "train loss:0.027181153061328938\n",
      "train loss:0.013260580214178959\n",
      "train loss:0.028036707010854388\n",
      "train loss:0.0352225171920308\n",
      "train loss:0.007600010321274284\n",
      "train loss:0.0031399594835109785\n",
      "train loss:0.007105900571484882\n",
      "train loss:0.011248082623074201\n",
      "train loss:0.007695671056244801\n",
      "train loss:0.008464912465441482\n",
      "train loss:0.01626594964604409\n",
      "train loss:0.005726638362744594\n",
      "train loss:0.0053238285750745636\n",
      "train loss:0.02281948949382633\n",
      "train loss:0.005906120830445417\n",
      "train loss:0.013284865306970279\n",
      "train loss:0.0043120630237916974\n",
      "train loss:0.005475094862910248\n",
      "train loss:0.011008713936939364\n",
      "train loss:0.011046140580539819\n",
      "train loss:0.002015788068206296\n",
      "train loss:0.007729733230463459\n",
      "train loss:0.02150935975715634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.007859119345033196\n",
      "train loss:0.01647058450068421\n",
      "train loss:0.004286395111426217\n",
      "train loss:0.027030145406182652\n",
      "train loss:0.05704866220122043\n",
      "train loss:0.026705081083925317\n",
      "train loss:0.0024808773826161964\n",
      "train loss:0.058431214210606264\n",
      "train loss:0.0028819895052245785\n",
      "train loss:0.009704791356024778\n",
      "train loss:0.032022493718971694\n",
      "train loss:0.024092188730070414\n",
      "train loss:0.004372762102238184\n",
      "train loss:0.008422362895796487\n",
      "train loss:0.06805527299602374\n",
      "train loss:0.019870910503021567\n",
      "train loss:0.01956745052645764\n",
      "train loss:0.0026925433939131633\n",
      "train loss:0.031192481352172688\n",
      "train loss:0.006907880823904427\n",
      "train loss:0.007237688908743305\n",
      "train loss:0.002814966368472219\n",
      "train loss:0.007840738479763583\n",
      "train loss:0.006018137222281664\n",
      "train loss:0.04600495585024812\n",
      "train loss:0.0076013935250161405\n",
      "train loss:0.017468151814648943\n",
      "train loss:0.00597255914654615\n",
      "train loss:0.03926025937002534\n",
      "train loss:0.009255482865118172\n",
      "train loss:0.006757160026768103\n",
      "train loss:0.003205577276850087\n",
      "train loss:0.017393336294549297\n",
      "train loss:0.026792152130386094\n",
      "train loss:0.0416048334511904\n",
      "train loss:0.01129215444956153\n",
      "train loss:0.003453293541882732\n",
      "train loss:0.01109788204224488\n",
      "train loss:0.015237702330885148\n",
      "train loss:0.003981395327059396\n",
      "train loss:0.014422138996499047\n",
      "train loss:0.004030977615418296\n",
      "train loss:0.052935052965757026\n",
      "train loss:0.008618406994309498\n",
      "train loss:0.011330427641817336\n",
      "train loss:0.01746248570010525\n",
      "train loss:0.008185450357316628\n",
      "train loss:0.043654835190725966\n",
      "train loss:0.00609665610352826\n",
      "train loss:0.03487688443254533\n",
      "train loss:0.03757718754798074\n",
      "train loss:0.01868140523212082\n",
      "train loss:0.00834311870521667\n",
      "train loss:0.010257135335608326\n",
      "train loss:0.005037930512773624\n",
      "train loss:0.03614475850826072\n",
      "train loss:0.008708362854006646\n",
      "train loss:0.006511438985152891\n",
      "train loss:0.007827451654696966\n",
      "train loss:0.004661343337798676\n",
      "train loss:0.016362658088819565\n",
      "train loss:0.04857706894554133\n",
      "train loss:0.01872905007572888\n",
      "train loss:0.02384680075320265\n",
      "train loss:0.003961876829290417\n",
      "train loss:0.0040752206624696\n",
      "train loss:0.01531426919728746\n",
      "train loss:0.005296025413470422\n",
      "train loss:0.07256872014412408\n",
      "train loss:0.0050098964940233715\n",
      "train loss:0.014583088795351857\n",
      "train loss:0.0033468838394876783\n",
      "train loss:0.009201644987973224\n",
      "train loss:0.0054459404686144\n",
      "train loss:0.0011657715930143975\n",
      "train loss:0.006463411937951703\n",
      "train loss:0.0018402934043350492\n",
      "train loss:0.009985077878995139\n",
      "train loss:0.009135961930771706\n",
      "train loss:0.008306444892463363\n",
      "train loss:0.05051877474025843\n",
      "train loss:0.002715113040627518\n",
      "train loss:0.009975729225443972\n",
      "train loss:0.01641351269039868\n",
      "train loss:0.016928938440917904\n",
      "train loss:0.0032362444573425953\n",
      "train loss:0.011645821444017435\n",
      "train loss:0.01909573635354369\n",
      "train loss:0.007179914186819515\n",
      "train loss:0.01886032458993524\n",
      "train loss:0.01044779322161637\n",
      "train loss:0.08384702502260051\n",
      "train loss:0.004747828119187169\n",
      "train loss:0.005618850330839718\n",
      "train loss:0.04593846073134919\n",
      "train loss:0.024669901720866236\n",
      "train loss:0.014578941128816135\n",
      "train loss:0.024694489453931604\n",
      "train loss:0.009292767177735082\n",
      "train loss:0.002603813426382087\n",
      "train loss:0.014183270869877012\n",
      "train loss:0.014826404282225458\n",
      "train loss:0.017797418620034186\n",
      "train loss:0.009524829948078177\n",
      "train loss:0.009505094392181269\n",
      "train loss:0.007787853847108801\n",
      "train loss:0.0446306593238508\n",
      "train loss:0.005665314414044244\n",
      "train loss:0.004332465147387643\n",
      "train loss:0.030404481758477445\n",
      "train loss:0.0022497717876093803\n",
      "train loss:0.02421710950314809\n",
      "train loss:0.003670633029221857\n",
      "train loss:0.03805799802165273\n",
      "train loss:0.0023656582175917147\n",
      "train loss:0.007348828110605279\n",
      "train loss:0.001869140016695467\n",
      "train loss:0.03836107661212362\n",
      "train loss:0.018286062873432433\n",
      "train loss:0.01122458476817429\n",
      "train loss:0.029511027079265742\n",
      "train loss:0.0234128917788479\n",
      "train loss:0.010225484913215264\n",
      "train loss:0.014034686643941727\n",
      "train loss:0.011026450513046255\n",
      "train loss:0.002713694527086338\n",
      "train loss:0.007887323386263818\n",
      "train loss:0.03420449623979844\n",
      "train loss:0.02092705906850837\n",
      "train loss:0.010298781480337806\n",
      "train loss:0.02420671255598218\n",
      "train loss:0.005653538539525247\n",
      "train loss:0.005452558845475092\n",
      "train loss:0.019079454019229992\n",
      "train loss:0.01705871804770834\n",
      "train loss:0.05101516120559315\n",
      "train loss:0.004817101409998117\n",
      "train loss:0.02033033351762743\n",
      "train loss:0.007023189800146742\n",
      "train loss:0.012112436571914182\n",
      "train loss:0.010943009051661791\n",
      "train loss:0.002535778690983265\n",
      "train loss:0.028914062533849923\n",
      "train loss:0.003436706827574524\n",
      "train loss:0.011081263340452573\n",
      "train loss:0.009453809921663647\n",
      "train loss:0.008703065519308552\n",
      "train loss:0.003573468116030949\n",
      "train loss:0.0017231333994899506\n",
      "train loss:0.009975953477736244\n",
      "train loss:0.015281735102472872\n",
      "train loss:0.012708058949607621\n",
      "train loss:0.029444938818467284\n",
      "train loss:0.03207894287270938\n",
      "train loss:0.008523605473223818\n",
      "train loss:0.03270698620200319\n",
      "train loss:0.0018273387121059814\n",
      "train loss:0.015327087715976266\n",
      "train loss:0.0021158795730048595\n",
      "train loss:0.06588490252484515\n",
      "train loss:0.00645591980398753\n",
      "train loss:0.004367472349550255\n",
      "train loss:0.023022659299246327\n",
      "train loss:0.048221184341551086\n",
      "train loss:0.03891637466186639\n",
      "train loss:0.03655694281805214\n",
      "train loss:0.003925315475015027\n",
      "train loss:0.02122927861174861\n",
      "train loss:0.011108976784252846\n",
      "train loss:0.02687275636235709\n",
      "train loss:0.012866155610164827\n",
      "train loss:0.013109894434648672\n",
      "train loss:0.03021997849583955\n",
      "train loss:0.012787098789084638\n",
      "train loss:0.027077643148635287\n",
      "train loss:0.008966979192011114\n",
      "train loss:0.009367254247278845\n",
      "train loss:0.009026188007709704\n",
      "train loss:0.006984995112844267\n",
      "train loss:0.006719430489419774\n",
      "train loss:0.004918797465557691\n",
      "train loss:0.015695316289455388\n",
      "train loss:0.003654542141728295\n",
      "train loss:0.1710882461170626\n",
      "train loss:0.003805157750619488\n",
      "train loss:0.00956124968125316\n",
      "train loss:0.013689394579328005\n",
      "train loss:0.0036307022489242423\n",
      "train loss:0.03258147106267927\n",
      "train loss:0.006198893482295408\n",
      "train loss:0.01620534409838632\n",
      "train loss:0.02823918107562197\n",
      "train loss:0.004160014380290902\n",
      "train loss:0.04052567254455032\n",
      "train loss:0.009921721609003176\n",
      "train loss:0.032654954852448986\n",
      "train loss:0.030507970637293068\n",
      "train loss:0.0028782122808796305\n",
      "train loss:0.0053708404700633485\n",
      "train loss:0.055195810041605765\n",
      "train loss:0.005314739931952123\n",
      "train loss:0.0008918411061039352\n",
      "train loss:0.010010478953186703\n",
      "train loss:0.015242439568669528\n",
      "train loss:0.03502564038051086\n",
      "train loss:0.0028378152116987597\n",
      "train loss:0.01450758209295383\n",
      "train loss:0.04539084273048915\n",
      "train loss:0.02901448149934325\n",
      "train loss:0.017875104495923177\n",
      "train loss:0.012106340693631631\n",
      "train loss:0.029697784393732968\n",
      "train loss:0.027304911073333347\n",
      "train loss:0.008972619314480174\n",
      "train loss:0.008471033580140043\n",
      "train loss:0.003717799083547307\n",
      "train loss:0.0022746760534201375\n",
      "train loss:0.011570292605894593\n",
      "train loss:0.014724505219026717\n",
      "train loss:0.009183234757841779\n",
      "train loss:0.012974828916066621\n",
      "train loss:0.020816912480516172\n",
      "train loss:0.006205928135178162\n",
      "train loss:0.038782260651311094\n",
      "train loss:0.009040720214108311\n",
      "train loss:0.0021635221662978533\n",
      "train loss:0.020918393535488692\n",
      "train loss:0.0028459975638429873\n",
      "train loss:0.0155690932501771\n",
      "train loss:0.03689066643040174\n",
      "train loss:0.004479529756280691\n",
      "train loss:0.0032228266609104993\n",
      "train loss:0.006145886321412815\n",
      "train loss:0.007237796132617304\n",
      "train loss:0.011156867562814117\n",
      "train loss:0.0061455320937765165\n",
      "train loss:0.0011428911188359767\n",
      "train loss:0.036332124185451856\n",
      "train loss:0.02732491269118474\n",
      "train loss:0.016277671140915807\n",
      "train loss:0.010597904600387138\n",
      "train loss:0.009326967991044413\n",
      "train loss:0.009826754139241264\n",
      "train loss:0.008988639173567506\n",
      "train loss:0.048669739420119144\n",
      "train loss:0.023417749263396286\n",
      "train loss:0.021527892956949294\n",
      "train loss:0.018874309045081705\n",
      "train loss:0.005295270024672752\n",
      "train loss:0.01614926547532873\n",
      "train loss:0.004663022073698887\n",
      "train loss:0.004096148871316595\n",
      "train loss:0.0022654551782760332\n",
      "train loss:0.006863489270496002\n",
      "train loss:0.01868549593780319\n",
      "train loss:0.010880644481001529\n",
      "train loss:0.003916624538966103\n",
      "train loss:0.007395065432435376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.015632790234602296\n",
      "train loss:0.011271899447032031\n",
      "train loss:0.042110866492191416\n",
      "train loss:0.011406441442433812\n",
      "train loss:0.009290788498514202\n",
      "train loss:0.006332747924771085\n",
      "train loss:0.054817847317144\n",
      "train loss:0.05145332342008652\n",
      "train loss:0.006902038904059831\n",
      "train loss:0.0010834520916682268\n",
      "train loss:0.016471592104183766\n",
      "train loss:0.023302896254878084\n",
      "train loss:0.008015332472982847\n",
      "train loss:0.004059196841283575\n",
      "train loss:0.007370875070808922\n",
      "train loss:0.0015869309382640431\n",
      "train loss:0.009492397869297857\n",
      "train loss:0.012781611157829382\n",
      "train loss:0.004305521152285319\n",
      "train loss:0.0006941056228350977\n",
      "train loss:0.011515443952616033\n",
      "train loss:0.0036045795723655227\n",
      "train loss:0.01904417138900937\n",
      "train loss:0.007695055198987437\n",
      "train loss:0.00723140917035118\n",
      "train loss:0.005222394502765522\n",
      "train loss:0.004153626596233485\n",
      "train loss:0.03680377363834624\n",
      "train loss:0.012325089558565188\n",
      "train loss:0.01972731187121435\n",
      "train loss:0.0047934027755283486\n",
      "train loss:0.007790256197723342\n",
      "train loss:0.01227267188384732\n",
      "train loss:0.001237856406150728\n",
      "train loss:0.0017690436467747703\n",
      "train loss:0.004240737400163725\n",
      "train loss:0.007240469075731598\n",
      "train loss:0.010910775591664893\n",
      "train loss:0.005272266373755908\n",
      "train loss:0.058141162763986454\n",
      "train loss:0.0030849382391630216\n",
      "train loss:0.00547598760920946\n",
      "train loss:0.0247337530132175\n",
      "train loss:0.0060798856957643135\n",
      "train loss:0.0030820146955475762\n",
      "train loss:0.0383871663089969\n",
      "train loss:0.01374156281356956\n",
      "train loss:0.012750930055150685\n",
      "train loss:0.009121750928154032\n",
      "train loss:0.005007049090404026\n",
      "train loss:0.016852049930813386\n",
      "train loss:0.0013216724700833087\n",
      "train loss:0.005868553258752358\n",
      "train loss:0.01774827413403181\n",
      "train loss:0.010517027803208867\n",
      "train loss:0.0018011887604247481\n",
      "train loss:0.003854265633398236\n",
      "train loss:0.004266631150799709\n",
      "train loss:0.017218013196629016\n",
      "train loss:0.0456786586950296\n",
      "train loss:0.006274937428243686\n",
      "train loss:0.013104566758855393\n",
      "train loss:0.005575015212919493\n",
      "train loss:0.0026502791538687977\n",
      "train loss:0.007701953132572101\n",
      "train loss:0.021311230362139028\n",
      "train loss:0.009917360068728403\n",
      "train loss:0.008901984856576865\n",
      "train loss:0.002283914514713397\n",
      "train loss:0.012183753886174886\n",
      "train loss:0.005368259148942256\n",
      "train loss:0.028524475315170213\n",
      "train loss:0.006536603809955934\n",
      "train loss:0.004918672201107424\n",
      "train loss:0.0030963778024829464\n",
      "train loss:0.004506851514815509\n",
      "train loss:0.01931069499513092\n",
      "train loss:0.008188961296560354\n",
      "train loss:0.005536474777283992\n",
      "train loss:0.007590177730446782\n",
      "train loss:0.005425200590613568\n",
      "train loss:0.026716172298220067\n",
      "train loss:0.00401882943233252\n",
      "train loss:0.003217286059456285\n",
      "train loss:0.011095655817906124\n",
      "train loss:0.022664547203246874\n",
      "train loss:0.011933145046682424\n",
      "train loss:0.005537221417855328\n",
      "train loss:0.0132026728594428\n",
      "train loss:0.0008215710861455444\n",
      "train loss:0.008521830016725815\n",
      "train loss:0.0019523548025452352\n",
      "train loss:0.0056680247471587175\n",
      "train loss:0.0019225463419380428\n",
      "train loss:0.05024422554525357\n",
      "train loss:0.017607346970600988\n",
      "train loss:0.01434826763240909\n",
      "train loss:0.006037283056510385\n",
      "train loss:0.008943135051383362\n",
      "train loss:0.06644205697462383\n",
      "train loss:0.005368410718900928\n",
      "train loss:0.0021093134627067026\n",
      "train loss:0.0036999801834213418\n",
      "train loss:0.02524391757137876\n",
      "train loss:0.018218471512915085\n",
      "train loss:0.0024197485252267737\n",
      "train loss:0.003537318495079003\n",
      "train loss:0.0010416016486699247\n",
      "train loss:0.02404759852987732\n",
      "train loss:0.0037982948219534053\n",
      "train loss:0.025149410145160547\n",
      "train loss:0.014594657637370086\n",
      "train loss:0.05127166375065977\n",
      "train loss:0.008686832174363996\n",
      "train loss:0.0029085643193280334\n",
      "train loss:0.004986703204837593\n",
      "train loss:0.015681871064391215\n",
      "train loss:0.06906115786915155\n",
      "train loss:0.011967095208082893\n",
      "train loss:0.004900040353992699\n",
      "train loss:0.011563039457814148\n",
      "train loss:0.0046283373666325235\n",
      "train loss:0.0067791114451196755\n",
      "train loss:0.007221614271860676\n",
      "train loss:0.010128339701092406\n",
      "train loss:0.010044209046593866\n",
      "train loss:0.01249338786995931\n",
      "train loss:0.005631580420162985\n",
      "train loss:0.005033866429614267\n",
      "train loss:0.005778731759053216\n",
      "train loss:0.011935640782527533\n",
      "train loss:0.013100885361523484\n",
      "train loss:0.02840974200895206\n",
      "train loss:0.0038875316450572854\n",
      "train loss:0.011067269172596688\n",
      "train loss:0.0039014372167930356\n",
      "train loss:0.017837973247414023\n",
      "train loss:0.029536059346487925\n",
      "train loss:0.01713564785553752\n",
      "train loss:0.004101762022817327\n",
      "train loss:0.039767134385969814\n",
      "train loss:0.007141768235078711\n",
      "train loss:0.002624823760251598\n",
      "train loss:0.005052932368895872\n",
      "train loss:0.009377044767294954\n",
      "train loss:0.006632380306746785\n",
      "train loss:0.01146374473492611\n",
      "train loss:0.02336301916477639\n",
      "train loss:0.016163750951229558\n",
      "train loss:0.002489941076779312\n",
      "train loss:0.006950377802395752\n",
      "train loss:0.0022267415939716704\n",
      "train loss:0.008213880629834141\n",
      "train loss:0.004200571472019833\n",
      "train loss:0.00498692133944101\n",
      "train loss:0.0025411643863338103\n",
      "train loss:0.015582651093842319\n",
      "train loss:0.0020088733387130958\n",
      "train loss:0.010315441245738566\n",
      "train loss:0.008210745735360908\n",
      "train loss:0.007186083314327798\n",
      "train loss:0.010029608565465172\n",
      "train loss:0.005603328415061325\n",
      "train loss:0.0068985476335101615\n",
      "train loss:0.00427377173303869\n",
      "train loss:0.0057014453388359795\n",
      "train loss:0.01481022821998345\n",
      "train loss:0.0082148884163524\n",
      "train loss:0.02748116073839917\n",
      "train loss:0.00173989867989781\n",
      "train loss:0.00511812099529756\n",
      "train loss:0.02827171327393679\n",
      "train loss:0.008112123303119154\n",
      "train loss:0.009386590329006928\n",
      "train loss:0.01039591880812963\n",
      "train loss:0.009220980318711184\n",
      "train loss:0.004250074942848744\n",
      "train loss:0.002644673388547351\n",
      "train loss:0.06445535613617014\n",
      "train loss:0.007395744562268199\n",
      "train loss:0.0027922885735624896\n",
      "train loss:0.010630487184604888\n",
      "train loss:0.02403203307569874\n",
      "train loss:0.015083224417017593\n",
      "train loss:0.010660971812970694\n",
      "train loss:0.01497524046095528\n",
      "train loss:0.02545710103284613\n",
      "train loss:0.003433651779742179\n",
      "train loss:0.007533524394396326\n",
      "train loss:0.031743101687237\n",
      "train loss:0.014477025958333547\n",
      "train loss:0.01735963918899854\n",
      "train loss:0.01193462784103302\n",
      "train loss:0.010825121482257043\n",
      "train loss:0.03928711786685071\n",
      "train loss:0.011133487937072811\n",
      "train loss:0.00733941529752158\n",
      "train loss:0.010298976518614653\n",
      "train loss:0.010148458291648715\n",
      "train loss:0.006511561364838875\n",
      "train loss:0.017260095588344255\n",
      "train loss:0.004454660474399416\n",
      "train loss:0.0049571411787069485\n",
      "train loss:0.005904200021677568\n",
      "train loss:0.006658134234155667\n",
      "train loss:0.004162822566070518\n",
      "train loss:0.009946539978193445\n",
      "train loss:0.006344289369412729\n",
      "train loss:0.03579050375455036\n",
      "train loss:0.018995828536247095\n",
      "train loss:0.04044217953646566\n",
      "train loss:0.023277456044783148\n",
      "train loss:0.003918692378886839\n",
      "train loss:0.009140940357911496\n",
      "train loss:0.002544501066840315\n",
      "train loss:0.014877917926013172\n",
      "train loss:0.008727646515934231\n",
      "train loss:0.017981493179769947\n",
      "train loss:0.00958103902441905\n",
      "train loss:0.007036068199512469\n",
      "train loss:0.010026589929385427\n",
      "train loss:0.003454064613705934\n",
      "train loss:0.006685462765281281\n",
      "train loss:0.004525622650536672\n",
      "train loss:0.010345803811134265\n",
      "train loss:0.02416546491261267\n",
      "train loss:0.016272274712655844\n",
      "train loss:0.0052749590492938\n",
      "train loss:0.01049397914054889\n",
      "train loss:0.010896757944392219\n",
      "train loss:0.006361107415076951\n",
      "train loss:0.002482214344694483\n",
      "train loss:0.0024905907243338394\n",
      "train loss:0.0073508181440962925\n",
      "train loss:0.020804794351161327\n",
      "train loss:0.05925390041516452\n",
      "train loss:0.050647380174924275\n",
      "train loss:0.005550709795989785\n",
      "train loss:0.0035128127769817902\n",
      "train loss:0.011994756764002166\n",
      "train loss:0.005614162332012038\n",
      "train loss:0.0020733769297015875\n",
      "train loss:0.022116129818025257\n",
      "train loss:0.007666813370082405\n",
      "train loss:0.008155965438445047\n",
      "train loss:0.037801255558486194\n",
      "train loss:0.013976385341727612\n",
      "train loss:0.016565133672318415\n",
      "train loss:0.006000774275596424\n",
      "train loss:0.010347558978614675\n",
      "train loss:0.009650961216128066\n",
      "train loss:0.026668848521388636\n",
      "train loss:0.004882680297393202\n",
      "train loss:0.01047270422427325\n",
      "train loss:0.03787077901519351\n",
      "train loss:0.0014218514782836605\n",
      "train loss:0.005050967817856444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00325666464359246\n",
      "train loss:0.009309580312733077\n",
      "train loss:0.0035529091303633403\n",
      "train loss:0.07150653711626913\n",
      "train loss:0.013255428142358978\n",
      "train loss:0.027713142958231237\n",
      "train loss:0.014286693251528424\n",
      "train loss:0.0047941530682772725\n",
      "train loss:0.011132713270475507\n",
      "train loss:0.043022618803760765\n",
      "train loss:0.011610564024645421\n",
      "train loss:0.007221851279723477\n",
      "train loss:0.009674952244398134\n",
      "train loss:0.0021235489823033327\n",
      "train loss:0.006913517328432019\n",
      "train loss:0.01636547639510045\n",
      "train loss:0.0463464248286938\n",
      "train loss:0.0042901030401152375\n",
      "train loss:0.004026352008201568\n",
      "train loss:0.0013384765836428935\n",
      "=== epoch:8, train acc:0.992, test acc:0.992 ===\n",
      "train loss:0.005892822548435239\n",
      "train loss:0.0035511172296078665\n",
      "train loss:0.002726159086214529\n",
      "train loss:0.003854752406430999\n",
      "train loss:0.0037678234664982207\n",
      "train loss:0.010314307340375271\n",
      "train loss:0.014619863738920129\n",
      "train loss:0.001750532313769486\n",
      "train loss:0.012147676388316507\n",
      "train loss:0.007018452625142998\n",
      "train loss:0.006846502645856649\n",
      "train loss:0.022311838291180774\n",
      "train loss:0.011717709819747896\n",
      "train loss:0.006767158406394147\n",
      "train loss:0.01328192345133322\n",
      "train loss:0.002415268650549918\n",
      "train loss:0.011140930827920037\n",
      "train loss:0.005936902091395582\n",
      "train loss:0.05666103065019064\n",
      "train loss:0.01016633510507824\n",
      "train loss:0.044602119629395996\n",
      "train loss:0.035566118036209515\n",
      "train loss:0.010366294064586645\n",
      "train loss:0.006518615573575062\n",
      "train loss:0.015904596196011155\n",
      "train loss:0.016438754038019886\n",
      "train loss:0.003901968942908023\n",
      "train loss:0.004635601741291826\n",
      "train loss:0.010959130735671953\n",
      "train loss:0.012600658528063066\n",
      "train loss:0.0026317580747271395\n",
      "train loss:0.008882410218173748\n",
      "train loss:0.011930485054399222\n",
      "train loss:0.0011059210996004012\n",
      "train loss:0.017347165750863945\n",
      "train loss:0.013039129333292312\n",
      "train loss:0.015418864962188649\n",
      "train loss:0.0021754094728906413\n",
      "train loss:0.009605193563534597\n",
      "train loss:0.007939285307776265\n",
      "train loss:0.040168228100767076\n",
      "train loss:0.005239424820643499\n",
      "train loss:0.003537354927744416\n",
      "train loss:0.00209777580003198\n",
      "train loss:0.012787571081383675\n",
      "train loss:0.010124846350901228\n",
      "train loss:0.009557989420476398\n",
      "train loss:0.005439698844742019\n",
      "train loss:0.008735907125476287\n",
      "train loss:0.007502190782534601\n",
      "train loss:0.0028341005137661533\n",
      "train loss:0.01647689961053013\n",
      "train loss:0.01035659349550361\n",
      "train loss:0.017102546710970463\n",
      "train loss:0.01739454526052807\n",
      "train loss:0.00970902931269252\n",
      "train loss:0.09277444267593697\n",
      "train loss:0.0052690217133465386\n",
      "train loss:0.002378228466016634\n",
      "train loss:0.00757859407734361\n",
      "train loss:0.0033702816695799108\n",
      "train loss:0.016166925658740096\n",
      "train loss:0.00752703051586174\n",
      "train loss:0.004631329751602342\n",
      "train loss:0.02177922436280043\n",
      "train loss:0.009647194772277446\n",
      "train loss:0.024381852524304744\n",
      "train loss:0.016526785229941457\n",
      "train loss:0.005716437402922315\n",
      "train loss:0.012271012955219582\n",
      "train loss:0.0039914127090488714\n",
      "train loss:0.005443977865913491\n",
      "train loss:0.007615322156641344\n",
      "train loss:0.012812788571256088\n",
      "train loss:0.0038665484968073817\n",
      "train loss:0.02725062538009881\n",
      "train loss:0.0035291601974911956\n",
      "train loss:0.006555471952037762\n",
      "train loss:0.015446074430610206\n",
      "train loss:0.03326065186226167\n",
      "train loss:0.002612239738844835\n",
      "train loss:0.006933113176290674\n",
      "train loss:0.002137558167933952\n",
      "train loss:0.007512893591551707\n",
      "train loss:0.001361479268429799\n",
      "train loss:0.013197760055575774\n",
      "train loss:0.002158947173457885\n",
      "train loss:0.02802495374244508\n",
      "train loss:0.01059812683549425\n",
      "train loss:0.0023829038398173828\n",
      "train loss:0.03305366225839826\n",
      "train loss:0.008037881128839105\n",
      "train loss:0.0019169175689936183\n",
      "train loss:0.004347796405158119\n",
      "train loss:0.016282920558483162\n",
      "train loss:0.00703272302362965\n",
      "train loss:0.0048416048735932075\n",
      "train loss:0.014689676110677891\n",
      "train loss:0.006086085041915646\n",
      "train loss:0.003661071674165568\n",
      "train loss:0.003985530491235787\n",
      "train loss:0.043066963312354656\n",
      "train loss:0.04575905871444954\n",
      "train loss:0.010565888992558862\n",
      "train loss:0.03259172082443238\n",
      "train loss:0.007667855363783215\n",
      "train loss:0.005043742387194534\n",
      "train loss:0.0019833657111851515\n",
      "train loss:0.017370625589121804\n",
      "train loss:0.015215049875818353\n",
      "train loss:0.010787026049545343\n",
      "train loss:0.01239186826515004\n",
      "train loss:0.009959320385624684\n",
      "train loss:0.01199289135647193\n",
      "train loss:0.008286935608054347\n",
      "train loss:0.013740965667406258\n",
      "train loss:0.01385660101839247\n",
      "train loss:0.0034127868739148165\n",
      "train loss:0.001795585307576848\n",
      "train loss:0.04737117111014513\n",
      "train loss:0.006152154032231064\n",
      "train loss:0.01607863143684268\n",
      "train loss:0.012600614956656282\n",
      "train loss:0.006749848941603864\n",
      "train loss:0.02552147521366767\n",
      "train loss:0.00957202837451695\n",
      "train loss:0.0075472704557481155\n",
      "train loss:0.012536690869213147\n",
      "train loss:0.003587563541863451\n",
      "train loss:0.0019971031381299837\n",
      "train loss:0.0136011258583409\n",
      "train loss:0.006740909834740325\n",
      "train loss:0.014611531080584113\n",
      "train loss:0.002413758814073061\n",
      "train loss:0.00572200061634569\n",
      "train loss:0.018764864675671507\n",
      "train loss:0.028842926689653953\n",
      "train loss:0.02569483282947969\n",
      "train loss:0.0032589137310328675\n",
      "train loss:0.0044955230444608816\n",
      "train loss:0.006783958939738059\n",
      "train loss:0.012165670509135147\n",
      "train loss:0.00849399825220986\n",
      "train loss:0.007288031040397408\n",
      "train loss:0.012434189626976006\n",
      "train loss:0.013845104552346355\n",
      "train loss:0.0026784398442154145\n",
      "train loss:0.01159638960168468\n",
      "train loss:0.0022120245608170837\n",
      "train loss:0.0060512053949832965\n",
      "train loss:0.0028809484720200788\n",
      "train loss:0.0056436490682716615\n",
      "train loss:0.019687470508947036\n",
      "train loss:0.0034558133940031975\n",
      "train loss:0.003911613496118844\n",
      "train loss:0.02115514830550304\n",
      "train loss:0.005801033363590824\n",
      "train loss:0.0016468128594352535\n",
      "train loss:0.00283499082486449\n",
      "train loss:0.0038333094701725073\n",
      "train loss:0.0040903566453674685\n",
      "train loss:0.005873645867182578\n",
      "train loss:0.0019189389096011809\n",
      "train loss:0.015591717716275407\n",
      "train loss:0.00771460957673065\n",
      "train loss:0.004086993027046304\n",
      "train loss:0.0030026511479386946\n",
      "train loss:0.004897312521600564\n",
      "train loss:0.004840790787908229\n",
      "train loss:0.024485306872453684\n",
      "train loss:0.011683377935413797\n",
      "train loss:0.006136655455656269\n",
      "train loss:0.006094474149013224\n",
      "train loss:0.0028184011315557835\n",
      "train loss:0.0035912545151874278\n",
      "train loss:0.0077229989424945\n",
      "train loss:0.005890106448565244\n",
      "train loss:0.0077086506416200185\n",
      "train loss:0.0040505304325434005\n",
      "train loss:0.012708077517471012\n",
      "train loss:0.015811133624117072\n",
      "train loss:0.016325960634966653\n",
      "train loss:0.008513546996289244\n",
      "train loss:0.007937076694652961\n",
      "train loss:0.0037030662890178063\n",
      "train loss:0.026335826672204642\n",
      "train loss:0.0031977456389631624\n",
      "train loss:0.005373043760970215\n",
      "train loss:0.010266137398211412\n",
      "train loss:0.02657687537811745\n",
      "train loss:0.00392478250419475\n",
      "train loss:0.0034995802499247827\n",
      "train loss:0.0016925619715540035\n",
      "train loss:0.02396724753868134\n",
      "train loss:0.017315242807024064\n",
      "train loss:0.0029130951732132485\n",
      "train loss:0.03721009051394589\n",
      "train loss:0.0034713262621988024\n",
      "train loss:0.011722659177256345\n",
      "train loss:0.010157875371526248\n",
      "train loss:0.003392634405756268\n",
      "train loss:0.02812292342989396\n",
      "train loss:0.006602894213291566\n",
      "train loss:0.006832234961097179\n",
      "train loss:0.0018661758994433558\n",
      "train loss:0.004520015386849072\n",
      "train loss:0.0032582129161077204\n",
      "train loss:0.0036548121950380845\n",
      "train loss:0.008933401118734372\n",
      "train loss:0.009052743550379423\n",
      "train loss:0.031344096703386184\n",
      "train loss:0.006767679528231351\n",
      "train loss:0.013171286928820605\n",
      "train loss:0.012404361945361288\n",
      "train loss:0.010253490151886297\n",
      "train loss:0.0006651090823706844\n",
      "train loss:0.015344719717566166\n",
      "train loss:0.01941561409645753\n",
      "train loss:0.008218019923013402\n",
      "train loss:0.0022731953707007383\n",
      "train loss:0.002001351822659117\n",
      "train loss:0.07050856705240802\n",
      "train loss:0.0019010618525815842\n",
      "train loss:0.0035028664718987678\n",
      "train loss:0.010111650478401957\n",
      "train loss:0.009153115776697215\n",
      "train loss:0.010614378097995168\n",
      "train loss:0.001768163659571395\n",
      "train loss:0.017977544990688397\n",
      "train loss:0.0008046304281674182\n",
      "train loss:0.06897160347680932\n",
      "train loss:0.007326830731377586\n",
      "train loss:0.0178261067857485\n",
      "train loss:0.006467807920931174\n",
      "train loss:0.01827123914540967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.02884564840370397\n",
      "train loss:0.010340341435123468\n",
      "train loss:0.007709415302695777\n",
      "train loss:0.012235321092081575\n",
      "train loss:0.0012287221690548697\n",
      "train loss:0.009731105755035408\n",
      "train loss:0.0030761921196366003\n",
      "train loss:0.025131230114634678\n",
      "train loss:0.01350634066462869\n",
      "train loss:0.01027561493974261\n",
      "train loss:0.016753142318634305\n",
      "train loss:0.02280284595671126\n",
      "train loss:0.007380155769744945\n",
      "train loss:0.007783024992085868\n",
      "train loss:0.042853468578973805\n",
      "train loss:0.001689392610724903\n",
      "train loss:0.0013022350596387023\n",
      "train loss:0.0012361490405127292\n",
      "train loss:0.012267279941864918\n",
      "train loss:0.016682487578141735\n",
      "train loss:0.004429445967815297\n",
      "train loss:0.0024299485026067023\n",
      "train loss:0.00409232796557475\n",
      "train loss:0.008542636727296908\n",
      "train loss:0.010010490502349598\n",
      "train loss:0.005882029496317932\n",
      "train loss:0.006897450986851256\n",
      "train loss:0.005603991226854983\n",
      "train loss:0.0034263789885594347\n",
      "train loss:0.005416971237734617\n",
      "train loss:0.00807869587939804\n",
      "train loss:0.002360464232059035\n",
      "train loss:0.0025611186231546874\n",
      "train loss:0.00180480596423894\n",
      "train loss:0.035906276116670445\n",
      "train loss:0.0047319709460601446\n",
      "train loss:0.0027448500321319395\n",
      "train loss:0.03364705204769132\n",
      "train loss:0.003972572548402007\n",
      "train loss:0.002724066626412469\n",
      "train loss:0.0010564737564413525\n",
      "train loss:0.003433516729393055\n",
      "train loss:0.013006782164716407\n",
      "train loss:0.0057534287031813834\n",
      "train loss:0.07629976179275007\n",
      "train loss:0.0029138904621438745\n",
      "train loss:0.004730043506081885\n",
      "train loss:0.01874883130973872\n",
      "train loss:0.003258720507837636\n",
      "train loss:0.006780385348949713\n",
      "train loss:0.008316213431206903\n",
      "train loss:0.002640643967956703\n",
      "train loss:0.0012807838438518807\n",
      "train loss:0.005426318767314443\n",
      "train loss:0.04219145232308323\n",
      "train loss:0.017091061385021096\n",
      "train loss:0.0012269762586248378\n",
      "train loss:0.020470906485152103\n",
      "train loss:0.024335028331555975\n",
      "train loss:0.017735065116817033\n",
      "train loss:0.012747939499327605\n",
      "train loss:0.001318161719538134\n",
      "train loss:0.008545071981445268\n",
      "train loss:0.02016982118838463\n",
      "train loss:0.05020297614634631\n",
      "train loss:0.0032148412773891767\n",
      "train loss:0.014505770616665066\n",
      "train loss:0.0038688108667826234\n",
      "train loss:0.009184381184171598\n",
      "train loss:0.00195679741951181\n",
      "train loss:0.00991028828518474\n",
      "train loss:0.03278062521134937\n",
      "train loss:0.00261745547324477\n",
      "train loss:0.015689784514863386\n",
      "train loss:0.036186764539712396\n",
      "train loss:0.012728531209300602\n",
      "train loss:0.003935383985812261\n",
      "train loss:0.0014268560107204308\n",
      "train loss:0.02298914848428697\n",
      "train loss:0.007721614681925429\n",
      "train loss:0.025389203447118033\n",
      "train loss:0.0035986431811745752\n",
      "train loss:0.006079825804522352\n",
      "train loss:0.0027302610473512543\n",
      "train loss:0.005077620847793462\n",
      "train loss:0.007253002514446363\n",
      "train loss:0.008320981926668235\n",
      "train loss:0.007937154242853177\n",
      "train loss:0.001118522532466229\n",
      "train loss:0.010606444738816244\n",
      "train loss:0.0017752687262815932\n",
      "train loss:0.004175629495847014\n",
      "train loss:0.007665494817789394\n",
      "train loss:0.004629177575992582\n",
      "train loss:0.02058481097438263\n",
      "train loss:0.009789651434594406\n",
      "train loss:0.0025731713182183757\n",
      "train loss:0.023078874587333514\n",
      "train loss:0.003844527252208944\n",
      "train loss:0.008051665959747023\n",
      "train loss:0.0036597028735590024\n",
      "train loss:0.001009129687067757\n",
      "train loss:0.004690831380472281\n",
      "train loss:0.008458048777941896\n",
      "train loss:0.004322330471268284\n",
      "train loss:0.016079587652988968\n",
      "train loss:0.04775101321864614\n",
      "train loss:0.012438586994656841\n",
      "train loss:0.00538903887262625\n",
      "train loss:0.008675577059795445\n",
      "train loss:0.0008405980724084506\n",
      "train loss:0.017095199684559532\n",
      "train loss:0.0008479633279415462\n",
      "train loss:0.007391095035562907\n",
      "train loss:0.003779747407166941\n",
      "train loss:0.011868347917729404\n",
      "train loss:0.01616539726232168\n",
      "train loss:0.007316250559526861\n",
      "train loss:0.006504596557164819\n",
      "train loss:0.0015969511264424144\n",
      "train loss:0.020308692535100085\n",
      "train loss:0.010532920364809151\n",
      "train loss:0.0070125136864197845\n",
      "train loss:0.0075514492282157475\n",
      "train loss:0.0010219073149269852\n",
      "train loss:0.02548001536581701\n",
      "train loss:0.002902134684814025\n",
      "train loss:0.007776748036258636\n",
      "train loss:0.02244859599146476\n",
      "train loss:0.023105673734378107\n",
      "train loss:0.013990094550283967\n",
      "train loss:0.009663974688438494\n",
      "train loss:0.005193186388468839\n",
      "train loss:0.00808831734412475\n",
      "train loss:0.025174559181852983\n",
      "train loss:0.019966225772664575\n",
      "train loss:0.002064448904560484\n",
      "train loss:0.0007009968760892169\n",
      "train loss:0.02615580635530184\n",
      "train loss:0.038440978632870465\n",
      "train loss:0.012711600512205361\n",
      "train loss:0.0017084486841206664\n",
      "train loss:0.0014069817727929551\n",
      "train loss:0.005129189036620656\n",
      "train loss:0.013070304379381831\n",
      "train loss:0.008711747455661499\n",
      "train loss:0.006252238633343029\n",
      "train loss:0.013424164943539698\n",
      "train loss:0.009100306003301693\n",
      "train loss:0.007741641245727455\n",
      "train loss:0.006018009081784491\n",
      "train loss:0.0023624980784624915\n",
      "train loss:0.010466047875304084\n",
      "train loss:0.001551003297232889\n",
      "train loss:0.005631924973737154\n",
      "train loss:0.005531762431295764\n",
      "train loss:0.0077344869737319575\n",
      "train loss:0.0057453872827332355\n",
      "train loss:0.026939476388241256\n",
      "train loss:0.001115121311287476\n",
      "train loss:0.01745053945627705\n",
      "train loss:0.0052524275101833795\n",
      "train loss:0.0030466647039113087\n",
      "train loss:0.000529072078418671\n",
      "train loss:0.0022575273109502634\n",
      "train loss:0.006059275456992883\n",
      "train loss:0.009085026217350524\n",
      "train loss:0.0074142520924226985\n",
      "train loss:0.00253661442001244\n",
      "train loss:0.041197315834581485\n",
      "train loss:0.039340447541448116\n",
      "train loss:0.06757627835473996\n",
      "train loss:0.012338139458920316\n",
      "train loss:0.015134648249190445\n",
      "train loss:0.007030534537790229\n",
      "train loss:0.002543875037575591\n",
      "train loss:0.0028441193218579856\n",
      "train loss:0.009882782657241351\n",
      "train loss:0.007196322914796204\n",
      "train loss:0.005399745040373929\n",
      "train loss:0.011221892015157943\n",
      "train loss:0.0023559880940823112\n",
      "train loss:0.011083299184284794\n",
      "train loss:0.004064131063171628\n",
      "train loss:0.004112074995191889\n",
      "train loss:0.004318024355857145\n",
      "train loss:0.026263218904732443\n",
      "train loss:0.010998369267676014\n",
      "train loss:0.037830174340229415\n",
      "train loss:0.004559067331600014\n",
      "train loss:0.01177650974254482\n",
      "train loss:0.001264816941668779\n",
      "train loss:0.0024702912992716403\n",
      "train loss:0.012433531330420815\n",
      "train loss:0.006280576808586795\n",
      "train loss:0.022275284452098892\n",
      "train loss:0.025911683763254402\n",
      "train loss:0.0016388268602160125\n",
      "train loss:0.025816330564757697\n",
      "train loss:0.0026533567056311203\n",
      "train loss:0.02863927259203377\n",
      "train loss:0.0022907135837783765\n",
      "train loss:0.022144814187874205\n",
      "train loss:0.0031949293859806914\n",
      "train loss:0.0020515428022748693\n",
      "train loss:0.01369662825101178\n",
      "train loss:0.01087641600485399\n",
      "train loss:0.045520383253379794\n",
      "train loss:0.008838098402572237\n",
      "train loss:0.00800792833933579\n",
      "train loss:0.006373094771415541\n",
      "train loss:0.008515954291868967\n",
      "train loss:0.007668285372545792\n",
      "train loss:0.003779965106776494\n",
      "train loss:0.009310800188920052\n",
      "train loss:0.0024475914356531666\n",
      "train loss:0.00810095030458584\n",
      "train loss:0.0027294456462434924\n",
      "train loss:0.001191848163666271\n",
      "train loss:0.006243676761886201\n",
      "train loss:0.008634661197576146\n",
      "train loss:0.005824886363333821\n",
      "train loss:0.0035531157162786813\n",
      "train loss:0.026796970936897462\n",
      "train loss:0.0477152752359451\n",
      "train loss:0.04669591597416772\n",
      "train loss:0.019789403208221507\n",
      "train loss:0.009360198392996422\n",
      "train loss:0.006535343054014811\n",
      "train loss:0.0026163297333565904\n",
      "train loss:0.05107929145681893\n",
      "train loss:0.0036377617232829233\n",
      "train loss:0.005242925209882957\n",
      "train loss:0.01920949674548853\n",
      "train loss:0.032355755528845405\n",
      "train loss:0.004764560836246893\n",
      "train loss:0.02567289260117779\n",
      "train loss:0.051193427294611925\n",
      "train loss:0.003223244402374281\n",
      "train loss:0.008616781210301312\n",
      "train loss:0.012126547465622212\n",
      "train loss:0.01618476507709089\n",
      "train loss:0.022768162585864594\n",
      "train loss:0.010520845602368482\n",
      "train loss:0.00299355948650052\n",
      "train loss:0.04401485396678044\n",
      "train loss:0.016377582537109314\n",
      "train loss:0.02459250218597489\n",
      "train loss:0.02314135973795888\n",
      "train loss:0.02185260318446538\n",
      "train loss:0.024871306802932494\n",
      "train loss:0.006668482023307256\n",
      "train loss:0.0028075052247507736\n",
      "train loss:0.027810869499735946\n",
      "train loss:0.003093537478498362\n",
      "train loss:0.059324753200863695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.011047013244396447\n",
      "train loss:0.00557977019313915\n",
      "train loss:0.007006305271223502\n",
      "train loss:0.006805638577762252\n",
      "train loss:0.019118927675283934\n",
      "train loss:0.024014118470806332\n",
      "train loss:0.020468991293483344\n",
      "train loss:0.0034662166665045085\n",
      "train loss:0.014075866389280756\n",
      "train loss:0.0027194286328205784\n",
      "train loss:0.031951843452267197\n",
      "train loss:0.009010604863399161\n",
      "train loss:0.024009200331680355\n",
      "train loss:0.012427256303176336\n",
      "train loss:0.004718684359769934\n",
      "train loss:0.0013083378792279274\n",
      "train loss:0.0017876272567915886\n",
      "train loss:0.019093350373237353\n",
      "train loss:0.005343829830160729\n",
      "train loss:0.002807244888026121\n",
      "train loss:0.020496052637782616\n",
      "train loss:0.01750410314567718\n",
      "train loss:0.0063965604278788816\n",
      "train loss:0.0010345551299737329\n",
      "train loss:0.0035400828795729457\n",
      "train loss:0.014013360488408228\n",
      "train loss:0.010081875820157982\n",
      "train loss:0.006702941513478138\n",
      "train loss:0.015337556540323984\n",
      "train loss:0.009457052097184369\n",
      "train loss:0.005191835186430249\n",
      "train loss:0.004885072726447108\n",
      "train loss:0.0022343484815512456\n",
      "train loss:0.0602001921614726\n",
      "train loss:0.02561911343636851\n",
      "train loss:0.007536536403172286\n",
      "train loss:0.017136808523325657\n",
      "train loss:0.0009493184670296988\n",
      "train loss:0.001544023999093409\n",
      "train loss:0.004387314127759407\n",
      "train loss:0.004117311088491065\n",
      "train loss:0.004477668410679425\n",
      "train loss:0.004598071373674834\n",
      "train loss:0.012500731911988099\n",
      "train loss:0.0035112774685431415\n",
      "train loss:0.006557945613557683\n",
      "train loss:0.03425267673070349\n",
      "train loss:0.0033121937779152714\n",
      "train loss:0.009063226565319778\n",
      "train loss:0.004436613561141818\n",
      "train loss:0.0041237436642403286\n",
      "train loss:0.004230567207047089\n",
      "train loss:0.010209279700633504\n",
      "train loss:0.0057107310486446804\n",
      "train loss:0.004594159029360558\n",
      "train loss:0.08211136050438743\n",
      "train loss:0.012674177603523795\n",
      "train loss:0.022561177981253105\n",
      "train loss:0.003806343009848066\n",
      "train loss:0.01605918262945527\n",
      "train loss:0.0021180964289989946\n",
      "train loss:0.014770962130613607\n",
      "train loss:0.009391231532910303\n",
      "train loss:0.002782308353759812\n",
      "train loss:0.006600896003282035\n",
      "train loss:0.005833065059309378\n",
      "train loss:0.015334727918901727\n",
      "train loss:0.021424158069072063\n",
      "train loss:0.003178004935199985\n",
      "train loss:0.006370258461552787\n",
      "train loss:0.07753260019954056\n",
      "train loss:0.05318824541090602\n",
      "train loss:0.0012244804474316727\n",
      "train loss:0.019977908093596758\n",
      "train loss:0.002519767911866146\n",
      "train loss:0.0012608970733145224\n",
      "train loss:0.003467713303485773\n",
      "train loss:0.004326795658133532\n",
      "train loss:0.008162531230169252\n",
      "train loss:0.01459154646831458\n",
      "train loss:0.0013367421255743373\n",
      "train loss:0.010426469710574437\n",
      "train loss:0.00931655854892609\n",
      "train loss:0.02543686112044514\n",
      "train loss:0.003245047791217107\n",
      "train loss:0.005730504255354817\n",
      "train loss:0.004522068370783516\n",
      "train loss:0.015157302781102586\n",
      "train loss:0.004457677203424457\n",
      "train loss:0.004461758065373578\n",
      "train loss:0.010536164115276858\n",
      "train loss:0.016815764207059526\n",
      "train loss:0.002054565900266579\n",
      "train loss:0.009435221061149881\n",
      "train loss:0.0021441344588151736\n",
      "train loss:0.0025876626930578087\n",
      "train loss:0.009446453706222017\n",
      "train loss:0.009853478713715778\n",
      "train loss:0.019120210445689137\n",
      "train loss:0.0016882040142260685\n",
      "train loss:0.022796491123717302\n",
      "train loss:0.003269570560847752\n",
      "train loss:0.024615469886576383\n",
      "train loss:0.005567897598708407\n",
      "train loss:0.006114106976764898\n",
      "train loss:0.00746163753563694\n",
      "train loss:0.00958595665970875\n",
      "train loss:0.005246662635061029\n",
      "train loss:0.006072292206821317\n",
      "=== epoch:9, train acc:0.993, test acc:0.991 ===\n",
      "train loss:0.006868821120952301\n",
      "train loss:0.022872626947616274\n",
      "train loss:0.0022120174086544464\n",
      "train loss:0.0005879328336330329\n",
      "train loss:0.0008194090790793688\n",
      "train loss:0.05893144608799707\n",
      "train loss:0.009595976024222321\n",
      "train loss:0.02004714504298147\n",
      "train loss:0.015427658739223386\n",
      "train loss:0.004423228167687348\n",
      "train loss:0.043199057337376806\n",
      "train loss:0.019830935373466353\n",
      "train loss:0.005836434452035295\n",
      "train loss:0.0031238476015957224\n",
      "train loss:0.036700858409923695\n",
      "train loss:0.010216255760604318\n",
      "train loss:0.004322093718325869\n",
      "train loss:0.00586738702181211\n",
      "train loss:0.0013240116235586727\n",
      "train loss:0.007821369276777618\n",
      "train loss:0.0088849170011563\n",
      "train loss:0.0032243723391323113\n",
      "train loss:0.014999090778205073\n",
      "train loss:0.0062644218038452595\n",
      "train loss:0.008606159820795765\n",
      "train loss:0.003914116725710736\n",
      "train loss:0.02297738367103405\n",
      "train loss:0.006683922196085079\n",
      "train loss:0.0026431952037653966\n",
      "train loss:0.029691603351024193\n",
      "train loss:0.0076587669162946174\n",
      "train loss:0.0013233657381871275\n",
      "train loss:0.02381989333837017\n",
      "train loss:0.0034118931114071466\n",
      "train loss:0.0019307006419933368\n",
      "train loss:0.02888169391937093\n",
      "train loss:0.05101336520592141\n",
      "train loss:0.0092592681597155\n",
      "train loss:0.003032254719951684\n",
      "train loss:0.002319599718940118\n",
      "train loss:0.042759598953628\n",
      "train loss:0.004302823877820021\n",
      "train loss:0.009935318041477896\n",
      "train loss:0.01098296999343126\n",
      "train loss:0.009701743516063429\n",
      "train loss:0.0008460101813130822\n",
      "train loss:0.004612963517134058\n",
      "train loss:0.021465333243522032\n",
      "train loss:0.014360390795963043\n",
      "train loss:0.005832783676829236\n",
      "train loss:0.008752273274328032\n",
      "train loss:0.10058378653221994\n",
      "train loss:0.004375533642810157\n",
      "train loss:0.011565956613371928\n",
      "train loss:0.005426107291818253\n",
      "train loss:0.003494232047692158\n",
      "train loss:0.003000706008579762\n",
      "train loss:0.004386317261600263\n",
      "train loss:0.02065959746439367\n",
      "train loss:0.002070721023756648\n",
      "train loss:0.024271829190979154\n",
      "train loss:0.015891815843041383\n",
      "train loss:0.010263965631572754\n",
      "train loss:0.007766206326540902\n",
      "train loss:0.01105702995428392\n",
      "train loss:0.009560499813865008\n",
      "train loss:0.06168201387236476\n",
      "train loss:0.004114015559729851\n",
      "train loss:0.017536147717078995\n",
      "train loss:0.014659887749672324\n",
      "train loss:0.018720882980407666\n",
      "train loss:0.009787414627083518\n",
      "train loss:0.014339117654902192\n",
      "train loss:0.0035066347485734413\n",
      "train loss:0.030442674486279055\n",
      "train loss:0.008215809840442175\n",
      "train loss:0.005564188270568281\n",
      "train loss:0.012416116404852384\n",
      "train loss:0.0036816612221245064\n",
      "train loss:0.03339398349704363\n",
      "train loss:0.0013806313776695753\n",
      "train loss:0.005448580847104322\n",
      "train loss:0.010081148487363112\n",
      "train loss:0.004824000744739728\n",
      "train loss:0.0038117232750211768\n",
      "train loss:0.011472221720201847\n",
      "train loss:0.0014217457444592083\n",
      "train loss:0.001407615237645809\n",
      "train loss:0.01198590109748428\n",
      "train loss:0.0026694495916397987\n",
      "train loss:0.0062200480732072065\n",
      "train loss:0.002958459077047506\n",
      "train loss:0.026047460956684115\n",
      "train loss:0.025575558538400912\n",
      "train loss:0.010494275552143363\n",
      "train loss:0.02044813837018762\n",
      "train loss:0.004721015724799394\n",
      "train loss:0.017740734708120622\n",
      "train loss:0.001611904802731609\n",
      "train loss:0.00435603284956283\n",
      "train loss:0.005617403871016593\n",
      "train loss:0.0005999469804264717\n",
      "train loss:0.023349510632601125\n",
      "train loss:0.07176911542626085\n",
      "train loss:0.031780536015818206\n",
      "train loss:0.008063223342064973\n",
      "train loss:0.003722632376270019\n",
      "train loss:0.0033854461915028\n",
      "train loss:0.003971747949995157\n",
      "train loss:0.007572813264434057\n",
      "train loss:0.004126027796522298\n",
      "train loss:0.005126315761327212\n",
      "train loss:0.006735957957006179\n",
      "train loss:0.002161896909393111\n",
      "train loss:0.0028399809146303547\n",
      "train loss:0.005916140309977919\n",
      "train loss:0.004527552601410233\n",
      "train loss:0.004313692966228646\n",
      "train loss:0.003563013044385243\n",
      "train loss:0.007083501651574711\n",
      "train loss:0.0012474149008620348\n",
      "train loss:0.006978979786541565\n",
      "train loss:0.0013413678251008813\n",
      "train loss:0.027686557346869915\n",
      "train loss:0.003790510658084503\n",
      "train loss:0.004233093778458592\n",
      "train loss:0.002669027018612513\n",
      "train loss:0.0034779838299312943\n",
      "train loss:0.005799064871560958\n",
      "train loss:0.006812094422613204\n",
      "train loss:0.02169174883728377\n",
      "train loss:0.004128614250700999\n",
      "train loss:0.008151920899452887\n",
      "train loss:0.0005846335928878335\n",
      "train loss:0.0019351259009012176\n",
      "train loss:0.006800085630142964\n",
      "train loss:0.01566760631627226\n",
      "train loss:0.0025176933921554202\n",
      "train loss:0.003163744685663247\n",
      "train loss:0.009132241488072061\n",
      "train loss:0.004301604261550392\n",
      "train loss:0.002735826884186539\n",
      "train loss:0.026992261296739973\n",
      "train loss:0.013928406500057633\n",
      "train loss:0.0016399956040858117\n",
      "train loss:0.0038914194008168703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0028259233201928823\n",
      "train loss:0.0020634588413286055\n",
      "train loss:0.01905998202207405\n",
      "train loss:0.0033105456108143754\n",
      "train loss:0.008364914232040613\n",
      "train loss:0.00653553604159325\n",
      "train loss:0.020174045907379496\n",
      "train loss:0.006667427240710058\n",
      "train loss:0.013901493883133815\n",
      "train loss:0.003398808684717569\n",
      "train loss:0.0023062082251437722\n",
      "train loss:0.025194689118604653\n",
      "train loss:0.019403116608193362\n",
      "train loss:0.019325297729456837\n",
      "train loss:0.024512645246027604\n",
      "train loss:0.006895527177176119\n",
      "train loss:0.002031567492695016\n",
      "train loss:0.008447615869078155\n",
      "train loss:0.01139901656096123\n",
      "train loss:0.011224907539829023\n",
      "train loss:0.006940287418265159\n",
      "train loss:0.017363658020747172\n",
      "train loss:0.0030621848815918255\n",
      "train loss:0.00933141356770244\n",
      "train loss:0.012723834219575576\n",
      "train loss:0.007261874867865228\n",
      "train loss:0.0042041969847774535\n",
      "train loss:0.0026859464348194966\n",
      "train loss:0.038538554902987604\n",
      "train loss:0.0017873435879499303\n",
      "train loss:0.057746697888795294\n",
      "train loss:0.00375564826918247\n",
      "train loss:0.004401889996966859\n",
      "train loss:0.08023767590790234\n",
      "train loss:0.006299516559980909\n",
      "train loss:0.0241710652875727\n",
      "train loss:0.013182224777073447\n",
      "train loss:0.001650383042916653\n",
      "train loss:0.0056434318490645625\n",
      "train loss:0.010734389371752131\n",
      "train loss:0.007015726276132228\n",
      "train loss:0.03945887823915105\n",
      "train loss:0.02599736259441835\n",
      "train loss:0.005830106013047239\n",
      "train loss:0.006711257477913008\n",
      "train loss:0.02622756033064717\n",
      "train loss:0.0026620205938998782\n",
      "train loss:0.002329915411399491\n",
      "train loss:0.00587110054031562\n",
      "train loss:0.0038914440625469676\n",
      "train loss:0.027523917248950716\n",
      "train loss:0.02284841631075508\n",
      "train loss:0.005089980771324593\n",
      "train loss:0.012736056267926999\n",
      "train loss:0.004756336670873981\n",
      "train loss:0.0012771510799703093\n",
      "train loss:0.003467799846709452\n",
      "train loss:0.009586858044625153\n",
      "train loss:0.006248210139678936\n",
      "train loss:0.007038001871550323\n",
      "train loss:0.0144686911010524\n",
      "train loss:0.001128125849982678\n",
      "train loss:0.004022211449064808\n",
      "train loss:0.008411398677782895\n",
      "train loss:0.00867548248758711\n",
      "train loss:0.0025347108806173402\n",
      "train loss:0.002458217100921428\n",
      "train loss:0.001102121511436832\n",
      "train loss:0.002782205319223034\n",
      "train loss:0.004370781327292575\n",
      "train loss:0.014010256849595398\n",
      "train loss:0.04130198871190939\n",
      "train loss:0.0032343302377792183\n",
      "train loss:0.003459733406075768\n",
      "train loss:0.009182780887553093\n",
      "train loss:0.0013061783169969457\n",
      "train loss:0.007943647152352596\n",
      "train loss:0.0005264207701631194\n",
      "train loss:0.03970166721780675\n",
      "train loss:0.00830206202075068\n",
      "train loss:0.0036848698637869525\n",
      "train loss:0.005130927427408359\n",
      "train loss:0.0008358287807554919\n",
      "train loss:0.011377135305929723\n",
      "train loss:0.0029762386384568932\n",
      "train loss:0.019837550509031774\n",
      "train loss:0.004885194091775782\n",
      "train loss:0.0022539525440958435\n",
      "train loss:0.011448917396720064\n",
      "train loss:0.009959428023194682\n",
      "train loss:0.014107529733029995\n",
      "train loss:0.0015856707851848372\n",
      "train loss:0.0021432344077770486\n",
      "train loss:0.008487301761172274\n",
      "train loss:0.002214873625848695\n",
      "train loss:0.006791181837322731\n",
      "train loss:0.0026827763025355166\n",
      "train loss:0.010072632239550355\n",
      "train loss:0.0035036806010986165\n",
      "train loss:0.007421095375399819\n",
      "train loss:0.001955249343246824\n",
      "train loss:0.014180789271661854\n",
      "train loss:0.003353437320594696\n",
      "train loss:0.023539729101764367\n",
      "train loss:0.007967840957629696\n",
      "train loss:0.003954578652454913\n",
      "train loss:0.008097608580595567\n",
      "train loss:0.048799728677884235\n",
      "train loss:0.002633830715419552\n",
      "train loss:0.012737561491725866\n",
      "train loss:0.004565959251361772\n",
      "train loss:0.0015583300313553327\n",
      "train loss:0.0033185538256464532\n",
      "train loss:0.007342278759389342\n",
      "train loss:0.0026767306003165126\n",
      "train loss:0.006788911365714602\n",
      "train loss:0.014589214582516689\n",
      "train loss:0.013486624987750944\n",
      "train loss:0.009306968315843744\n",
      "train loss:0.0011135484677921783\n",
      "train loss:0.002626401685429261\n",
      "train loss:0.012635472001221748\n",
      "train loss:0.0029531057643469466\n",
      "train loss:0.004178842907161484\n",
      "train loss:0.009011114962510567\n",
      "train loss:0.01479322625405857\n",
      "train loss:0.05598072430312438\n",
      "train loss:0.007364104718762877\n",
      "train loss:0.0075605107213072235\n",
      "train loss:0.009775141314074991\n",
      "train loss:0.003424430028644583\n",
      "train loss:0.001328149254099734\n",
      "train loss:0.0007633779026143867\n",
      "train loss:0.013374931885038127\n",
      "train loss:0.002155855037457588\n",
      "train loss:0.00545478663582383\n",
      "train loss:0.009687919168027002\n",
      "train loss:0.026407175580754463\n",
      "train loss:0.0023826477123415814\n",
      "train loss:0.006908450255376803\n",
      "train loss:0.010664898918746814\n",
      "train loss:0.010759197085620764\n",
      "train loss:0.012740301749106831\n",
      "train loss:0.004493854838574962\n",
      "train loss:0.0006794991418372604\n",
      "train loss:0.041639803861269885\n",
      "train loss:0.016343280223950058\n",
      "train loss:0.0006830430579139468\n",
      "train loss:0.0025090175146728956\n",
      "train loss:0.005210037627819683\n",
      "train loss:0.004904212099857732\n",
      "train loss:0.00494140884641218\n",
      "train loss:0.0018061205378274118\n",
      "train loss:0.00663399517928269\n",
      "train loss:0.002778914151940817\n",
      "train loss:0.009732894838847693\n",
      "train loss:0.0018997522182440725\n",
      "train loss:0.0025277941297998756\n",
      "train loss:0.0015360324821930096\n",
      "train loss:0.004506184466877465\n",
      "train loss:0.005769964416399875\n",
      "train loss:0.026803457514197566\n",
      "train loss:0.004487426031839074\n",
      "train loss:0.0015363533396708865\n",
      "train loss:0.007500703770425398\n",
      "train loss:0.03462193090168846\n",
      "train loss:0.0030502199524883623\n",
      "train loss:0.008111184804833171\n",
      "train loss:0.0011715860401967963\n",
      "train loss:0.0031944035806694745\n",
      "train loss:0.0006204173032115207\n",
      "train loss:0.013436863257954323\n",
      "train loss:0.006868012368159673\n",
      "train loss:0.0061519360301749626\n",
      "train loss:0.0024328352957447945\n",
      "train loss:0.006367509201502452\n",
      "train loss:0.051866127464577944\n",
      "train loss:0.009109972984243426\n",
      "train loss:0.001409150940162749\n",
      "train loss:0.018052392216063154\n",
      "train loss:0.002375653638932452\n",
      "train loss:0.013492210939087595\n",
      "train loss:0.010083833323304361\n",
      "train loss:0.00404907548576012\n",
      "train loss:0.0062576458471264584\n",
      "train loss:0.0010049162134225245\n",
      "train loss:0.0032124393207492124\n",
      "train loss:0.003159898257068144\n",
      "train loss:0.006818139359801939\n",
      "train loss:0.001162997582723541\n",
      "train loss:0.0058848096643325555\n",
      "train loss:0.0025484222249463817\n",
      "train loss:0.005446741152204721\n",
      "train loss:0.023594519027179014\n",
      "train loss:0.02579419011737503\n",
      "train loss:0.029591051811869294\n",
      "train loss:0.007730423129246357\n",
      "train loss:0.005577442552586539\n",
      "train loss:0.002052191879594752\n",
      "train loss:0.0046612161219272705\n",
      "train loss:0.010164152585716504\n",
      "train loss:0.0024149474484566934\n",
      "train loss:0.003113739511469559\n",
      "train loss:0.005423549364946102\n",
      "train loss:0.006457387675887011\n",
      "train loss:0.026233771294319367\n",
      "train loss:0.007466129807157067\n",
      "train loss:0.007863531559507213\n",
      "train loss:0.005241076340234898\n",
      "train loss:0.014857613195500946\n",
      "train loss:0.0031858026863547054\n",
      "train loss:0.0022654863281314293\n",
      "train loss:0.004569491954059069\n",
      "train loss:0.0029121765549106086\n",
      "train loss:0.0032642313652264314\n",
      "train loss:0.0011816022834019234\n",
      "train loss:0.0016290052924627268\n",
      "train loss:0.0027277704646119128\n",
      "train loss:0.0063758167853771655\n",
      "train loss:0.0034960579436187043\n",
      "train loss:0.009122333369190183\n",
      "train loss:0.00565685150162579\n",
      "train loss:0.0018965234140759495\n",
      "train loss:0.0033444462037744943\n",
      "train loss:0.002949761513189052\n",
      "train loss:0.010555756561033773\n",
      "train loss:0.003113569266825847\n",
      "train loss:0.008978011796416585\n",
      "train loss:0.002200640914103979\n",
      "train loss:0.005765998716631456\n",
      "train loss:0.003969957092421973\n",
      "train loss:0.004870642977047161\n",
      "train loss:0.004232944084379528\n",
      "train loss:0.004732528997634166\n",
      "train loss:0.0024556047759709985\n",
      "train loss:0.008083609326525503\n",
      "train loss:0.0038119973247089144\n",
      "train loss:0.003591963104576777\n",
      "train loss:0.022697903759557318\n",
      "train loss:0.006576878052176774\n",
      "train loss:0.005748729293064241\n",
      "train loss:0.0008187470572621662\n",
      "train loss:0.005791348193881607\n",
      "train loss:0.005197803659059107\n",
      "train loss:0.0012834417427149373\n",
      "train loss:0.003491421723518716\n",
      "train loss:0.003506569041430209\n",
      "train loss:0.0018342831792934752\n",
      "train loss:0.019012387478153366\n",
      "train loss:0.003138642454464219\n",
      "train loss:0.0012274607252049782\n",
      "train loss:0.0014550235582792958\n",
      "train loss:0.00310601437771079\n",
      "train loss:0.015490836806380774\n",
      "train loss:0.004805248344003559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0011964306153738017\n",
      "train loss:0.0027227036398503263\n",
      "train loss:0.0012480048207606015\n",
      "train loss:0.004855602098454736\n",
      "train loss:0.001381391437017169\n",
      "train loss:0.0018223383174212618\n",
      "train loss:0.024907542209641188\n",
      "train loss:0.00660879936477728\n",
      "train loss:0.0019106296204996816\n",
      "train loss:0.006823926138814257\n",
      "train loss:0.00069570188245196\n",
      "train loss:0.0011858226480191442\n",
      "train loss:0.004421939660181339\n",
      "train loss:0.03474199509023418\n",
      "train loss:0.004898367586655716\n",
      "train loss:0.0031769945732099264\n",
      "train loss:0.00013713501218997248\n",
      "train loss:0.0015690776046186816\n",
      "train loss:0.013960761359760073\n",
      "train loss:0.005817643809390747\n",
      "train loss:0.015005577822491569\n",
      "train loss:0.0024209936860958925\n",
      "train loss:0.001505552663396361\n",
      "train loss:0.00044672428946906874\n",
      "train loss:0.0246818153752508\n",
      "train loss:0.0034182025822854394\n",
      "train loss:0.014495060450180479\n",
      "train loss:0.0017214571485391628\n",
      "train loss:0.005584897797453244\n",
      "train loss:0.002830085719489091\n",
      "train loss:0.009472659933929407\n",
      "train loss:0.0015431739837094068\n",
      "train loss:0.0010873101294601533\n",
      "train loss:0.002040269706012556\n",
      "train loss:0.0035563631522334315\n",
      "train loss:0.021240314919061934\n",
      "train loss:0.045171356661240517\n",
      "train loss:0.003908740464486006\n",
      "train loss:0.00302318204852877\n",
      "train loss:0.0012710348835524657\n",
      "train loss:0.004151028498027149\n",
      "train loss:0.005610247461898599\n",
      "train loss:0.006169069691697653\n",
      "train loss:0.0035868800365547447\n",
      "train loss:0.012906042552252894\n",
      "train loss:0.03317327776284257\n",
      "train loss:0.01738849082289237\n",
      "train loss:0.003366074318570375\n",
      "train loss:0.005432202721903353\n",
      "train loss:0.0008757018094236994\n",
      "train loss:0.006701609176998956\n",
      "train loss:0.001575294522156802\n",
      "train loss:0.00233930643727711\n",
      "train loss:0.014184834503502584\n",
      "train loss:0.010759662603909658\n",
      "train loss:0.001992079613612933\n",
      "train loss:0.008260540735159883\n",
      "train loss:0.0004883754771399207\n",
      "train loss:0.005299930251700973\n",
      "train loss:0.01595683966529321\n",
      "train loss:0.031639145856535864\n",
      "train loss:0.0038827679551607336\n",
      "train loss:0.005578477970680749\n",
      "train loss:0.006649290238927736\n",
      "train loss:0.005155548936032594\n",
      "train loss:0.12698219125100785\n",
      "train loss:0.0030263502285447687\n",
      "train loss:0.01368638119566557\n",
      "train loss:0.006744227897057734\n",
      "train loss:0.009131013610273799\n",
      "train loss:0.005873435679799761\n",
      "train loss:0.013283995586610371\n",
      "train loss:0.0027017333944123274\n",
      "train loss:0.001781895839298146\n",
      "train loss:0.016043716311229046\n",
      "train loss:0.0047813146234835825\n",
      "train loss:0.0035834106577985686\n",
      "train loss:0.0066849208956906315\n",
      "train loss:0.007289041698667954\n",
      "train loss:0.006654867256618463\n",
      "train loss:0.008828046189624201\n",
      "train loss:0.0009826690935136836\n",
      "train loss:0.006599740902760237\n",
      "train loss:0.022335169533582055\n",
      "train loss:0.004804044616082001\n",
      "train loss:0.00555749718942098\n",
      "train loss:0.00455527724374743\n",
      "train loss:0.0012728722199752537\n",
      "train loss:0.0012963414157868935\n",
      "train loss:0.02274113518225699\n",
      "train loss:0.0019199834557971653\n",
      "train loss:0.007244082938098607\n",
      "train loss:0.0029412369278973417\n",
      "train loss:0.004336958852703429\n",
      "train loss:0.012641370402439046\n",
      "train loss:0.003800279672330568\n",
      "train loss:0.0038593285633097946\n",
      "train loss:0.005415587385240082\n",
      "train loss:0.0172195401822379\n",
      "train loss:0.005657883241072943\n",
      "train loss:0.0026068720485503934\n",
      "train loss:0.0014143208014589556\n",
      "train loss:0.009756181872208496\n",
      "train loss:0.005696662284834728\n",
      "train loss:0.02873252411439021\n",
      "train loss:0.0029448361184692446\n",
      "train loss:0.014771197926996207\n",
      "train loss:0.025839550484163986\n",
      "train loss:0.0019507377135149389\n",
      "train loss:0.0033439851471098996\n",
      "train loss:0.016875188779957605\n",
      "train loss:0.0012054098177456266\n",
      "train loss:0.007166850968220198\n",
      "train loss:0.02787004227721941\n",
      "train loss:0.016590892062528423\n",
      "train loss:0.004109400851411267\n",
      "train loss:0.014113915928590442\n",
      "train loss:0.02835871164116123\n",
      "train loss:0.0012236688510330834\n",
      "train loss:0.008793365383881379\n",
      "train loss:0.006173686045892547\n",
      "train loss:0.011220758890243687\n",
      "train loss:0.026064150721022025\n",
      "train loss:0.05139464988447429\n",
      "train loss:0.019624589081526145\n",
      "train loss:0.002036604425891132\n",
      "train loss:0.06108587153496495\n",
      "train loss:0.005281647114034547\n",
      "train loss:0.01659569643244021\n",
      "train loss:0.002281696721929903\n",
      "train loss:0.002263585015436539\n",
      "train loss:0.002979941701201898\n",
      "train loss:0.002490229803953012\n",
      "train loss:0.008050180832435812\n",
      "train loss:0.004644855988702995\n",
      "train loss:0.007365530301321954\n",
      "train loss:0.006579330873969061\n",
      "train loss:0.004003795634911944\n",
      "train loss:0.004752271843129537\n",
      "train loss:0.012206703112951049\n",
      "train loss:0.004742777508722386\n",
      "train loss:0.013065397864387178\n",
      "train loss:0.01216663426025049\n",
      "train loss:0.004695077050208062\n",
      "train loss:0.00244546334369032\n",
      "train loss:0.007102093009819739\n",
      "train loss:0.011867152197247982\n",
      "train loss:0.01195602753776675\n",
      "train loss:0.001040352706209692\n",
      "train loss:0.012257189987872777\n",
      "train loss:0.03369708580273911\n",
      "train loss:0.0019710947084464487\n",
      "train loss:0.009446414639973862\n",
      "train loss:0.012278001222800919\n",
      "train loss:0.013923407010265575\n",
      "train loss:0.00220666618927959\n",
      "train loss:0.03000497390792634\n",
      "train loss:0.001929037171303549\n",
      "train loss:0.003076823540153962\n",
      "train loss:0.007449642250971535\n",
      "train loss:0.004160689157923858\n",
      "train loss:0.016151017385033613\n",
      "train loss:0.023838508905966616\n",
      "train loss:0.010164334839916172\n",
      "train loss:0.009149700228834507\n",
      "train loss:0.0021349778228341196\n",
      "train loss:0.003262559425241498\n",
      "train loss:0.05203283211126669\n",
      "train loss:0.006883402307129903\n",
      "train loss:0.002151155919422702\n",
      "train loss:0.011919981075312735\n",
      "train loss:0.0048688631187488625\n",
      "train loss:0.0018394946303080953\n",
      "train loss:0.0033267601784036567\n",
      "train loss:0.011950512369693972\n",
      "train loss:0.0018390402117709453\n",
      "train loss:0.002888768984740745\n",
      "train loss:0.0015180449052679046\n",
      "train loss:0.008213419436843502\n",
      "train loss:0.007954285573014287\n",
      "train loss:0.004977906640377266\n",
      "train loss:0.011904279339459305\n",
      "train loss:0.0028304460781719302\n",
      "train loss:0.006683136412981947\n",
      "train loss:0.004936562602901878\n",
      "train loss:0.005083200035875179\n",
      "train loss:0.000675085009026654\n",
      "train loss:0.02500226305785674\n",
      "train loss:0.011899929061121327\n",
      "train loss:0.0028014951599922137\n",
      "train loss:0.0012248542994041133\n",
      "train loss:0.002555396661669548\n",
      "train loss:0.0019930780336883613\n",
      "train loss:0.0013271712562516655\n",
      "train loss:0.006243005732375558\n",
      "train loss:0.0025207651283324023\n",
      "train loss:0.005264036070434083\n",
      "train loss:0.010291299783752117\n",
      "train loss:0.03451397246999278\n",
      "=== epoch:10, train acc:0.994, test acc:0.989 ===\n",
      "train loss:0.007169553631725611\n",
      "train loss:0.012624379044771188\n",
      "train loss:0.05470216393326004\n",
      "train loss:0.0069092565091857785\n",
      "train loss:0.002835201644646916\n",
      "train loss:0.000928992723588234\n",
      "train loss:0.0007380926139339499\n",
      "train loss:0.08357334490806899\n",
      "train loss:0.007449732427061388\n",
      "train loss:0.0010238861697270335\n",
      "train loss:0.00408868483667174\n",
      "train loss:0.030081393173699587\n",
      "train loss:0.014403445526664999\n",
      "train loss:0.0009112901917798038\n",
      "train loss:0.013282732679412738\n",
      "train loss:0.008714431870686658\n",
      "train loss:0.0006355172437911224\n",
      "train loss:0.02647981134094229\n",
      "train loss:0.013847422761799413\n",
      "train loss:0.0027525831222633963\n",
      "train loss:0.0037021118610120773\n",
      "train loss:0.005967276155947842\n",
      "train loss:0.0015673142021947846\n",
      "train loss:0.004842223667106166\n",
      "train loss:0.02507547793213816\n",
      "train loss:0.002186199495215924\n",
      "train loss:0.0055757527029919665\n",
      "train loss:0.006679182768443459\n",
      "train loss:0.0042217419492280375\n",
      "train loss:0.002340658739745709\n",
      "train loss:0.012291040232901024\n",
      "train loss:0.004455560730471641\n",
      "train loss:0.04233522657173739\n",
      "train loss:0.008249391767231462\n",
      "train loss:0.002092935349680777\n",
      "train loss:0.013461343641747565\n",
      "train loss:0.010122686427545033\n",
      "train loss:0.009692754768896516\n",
      "train loss:0.0018128600215007444\n",
      "train loss:0.0070022379815460655\n",
      "train loss:0.030257470919487797\n",
      "train loss:0.001680096381347522\n",
      "train loss:0.005863488832541595\n",
      "train loss:0.0041590853687382\n",
      "train loss:0.002574300798094728\n",
      "train loss:0.0011780600892355693\n",
      "train loss:0.0002788131607331798\n",
      "train loss:0.012002678812488263\n",
      "train loss:0.005174602446193315\n",
      "train loss:0.012359959398572868\n",
      "train loss:0.0024364228366507033\n",
      "train loss:0.0016976095528324737\n",
      "train loss:0.0022712737009940235\n",
      "train loss:0.009325918872995638\n",
      "train loss:0.012706215072685007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0011823047851736645\n",
      "train loss:0.003036192430205375\n",
      "train loss:0.005431908521845969\n",
      "train loss:0.013010108886215595\n",
      "train loss:0.0056813372109046955\n",
      "train loss:0.0024341567479934934\n",
      "train loss:0.010839990339489064\n",
      "train loss:0.017141405567175784\n",
      "train loss:0.00688277480547403\n",
      "train loss:0.002855077383396643\n",
      "train loss:0.01475186709876209\n",
      "train loss:0.01681517991591317\n",
      "train loss:0.001859774707670614\n",
      "train loss:0.009918952136070133\n",
      "train loss:0.0028659637565552143\n",
      "train loss:0.003898093971321213\n",
      "train loss:0.00456025145198324\n",
      "train loss:0.016049520996592667\n",
      "train loss:0.010000996919557893\n",
      "train loss:0.014547374735419673\n",
      "train loss:0.00391033601079317\n",
      "train loss:0.012375274770976472\n",
      "train loss:0.008558712974204413\n",
      "train loss:0.005137394954254712\n",
      "train loss:0.001090059286824289\n",
      "train loss:0.002484754026391643\n",
      "train loss:0.0018976463038546376\n",
      "train loss:0.004391838723131386\n",
      "train loss:0.005880052514084931\n",
      "train loss:0.0055927094111519636\n",
      "train loss:0.0027513679572895274\n",
      "train loss:0.0023054317595156324\n",
      "train loss:0.014322475791976486\n",
      "train loss:0.022159625878301087\n",
      "train loss:0.0033095832774521694\n",
      "train loss:0.005615879009024581\n",
      "train loss:0.0017656518560122787\n",
      "train loss:0.004588972966389947\n",
      "train loss:0.005463170058568056\n",
      "train loss:0.004306903587319477\n",
      "train loss:0.0032562576969694663\n",
      "train loss:0.011539374366274559\n",
      "train loss:0.002443554464744364\n",
      "train loss:0.005930256947775948\n",
      "train loss:0.006805762420287004\n",
      "train loss:0.008467646111578131\n",
      "train loss:0.003965645158391684\n",
      "train loss:0.021357508978089922\n",
      "train loss:0.0009822399528587344\n",
      "train loss:0.0033760211737863806\n",
      "train loss:0.005181129400137779\n",
      "train loss:0.003144973890945456\n",
      "train loss:0.0032533689992897017\n",
      "train loss:0.0024138396587767012\n",
      "train loss:0.010508449970800995\n",
      "train loss:0.003911709491715028\n",
      "train loss:0.008132653034418388\n",
      "train loss:0.06478817877941248\n",
      "train loss:0.0010515019890038606\n",
      "train loss:0.0018667568773486887\n",
      "train loss:0.00148573143250328\n",
      "train loss:0.020351899870123837\n",
      "train loss:0.002370530165106404\n",
      "train loss:0.003022557777624419\n",
      "train loss:0.0027293589561923678\n",
      "train loss:0.003799330328944901\n",
      "train loss:0.004403060333889569\n",
      "train loss:0.027410929831052328\n",
      "train loss:0.02215535137087407\n",
      "train loss:0.00040533633293608567\n",
      "train loss:0.02064549648727027\n",
      "train loss:0.051567086697021675\n",
      "train loss:0.0027813206882522797\n",
      "train loss:0.00824130259270705\n",
      "train loss:0.00734735894224984\n",
      "train loss:0.0031406727144345304\n",
      "train loss:0.007105266619297608\n",
      "train loss:0.0008739428747373238\n",
      "train loss:0.005805349465323632\n",
      "train loss:0.004995578858740671\n",
      "train loss:0.0064630719660867956\n",
      "train loss:0.0048270447519322005\n",
      "train loss:0.007335565072632011\n",
      "train loss:0.00300798398040413\n",
      "train loss:0.006355429889029734\n",
      "train loss:0.0009921951428026377\n",
      "train loss:0.0752228155482971\n",
      "train loss:0.0071732109352426665\n",
      "train loss:0.0018765762624822874\n",
      "train loss:0.0035170437110919367\n",
      "train loss:0.005971898298412791\n",
      "train loss:0.0015065337765492377\n",
      "train loss:0.003326244008110898\n",
      "train loss:0.001021065300900551\n",
      "train loss:0.03101827382348317\n",
      "train loss:0.0007739136200967799\n",
      "train loss:0.010669547382099576\n",
      "train loss:0.0019741779905167963\n",
      "train loss:0.02342960035674534\n",
      "train loss:0.008119745929855721\n",
      "train loss:0.008709441279831214\n",
      "train loss:0.014295352032001591\n",
      "train loss:0.0023961695562667038\n",
      "train loss:0.0009704435613718537\n",
      "train loss:0.005217292193484764\n",
      "train loss:0.0025350731341518963\n",
      "train loss:0.0012550951143265113\n",
      "train loss:0.007072932381493329\n",
      "train loss:0.004899575594022554\n",
      "train loss:0.010588604329203893\n",
      "train loss:0.005663953563789557\n",
      "train loss:0.007496259556549589\n",
      "train loss:0.002339704973541025\n",
      "train loss:0.003961824780411594\n",
      "train loss:0.006858887200113304\n",
      "train loss:0.0023129141834037493\n",
      "train loss:0.004147003401385655\n",
      "train loss:0.0034473518085931763\n",
      "train loss:0.003766670277116042\n",
      "train loss:0.012224194294469222\n",
      "train loss:0.034414260757002546\n",
      "train loss:0.012013999422297078\n",
      "train loss:0.02338329035886515\n",
      "train loss:0.006432761678242423\n",
      "train loss:0.003432041309980425\n",
      "train loss:0.0010845075569742737\n",
      "train loss:0.00995010755436324\n",
      "train loss:0.007663044212715065\n",
      "train loss:0.0018934472417971853\n",
      "train loss:0.00648498451383229\n",
      "train loss:0.0037659260751984093\n",
      "train loss:0.004961368962120231\n",
      "train loss:0.0698324805375711\n",
      "train loss:0.0006372142765318885\n",
      "train loss:0.009021023981791287\n",
      "train loss:0.001748650073602698\n",
      "train loss:0.03548490794306027\n",
      "train loss:0.00034410721681031625\n",
      "train loss:0.0018521881278807872\n",
      "train loss:0.00541671029571051\n",
      "train loss:0.004102094284902037\n",
      "train loss:0.000964507664751245\n",
      "train loss:0.01267297644695637\n",
      "train loss:0.0005470915575367278\n",
      "train loss:0.012672583639558022\n",
      "train loss:0.010766531418996896\n",
      "train loss:0.008078445682891382\n",
      "train loss:0.003963870571141797\n",
      "train loss:0.004742682758213275\n",
      "train loss:0.008322826151139376\n",
      "train loss:0.01379692307268586\n",
      "train loss:0.002089215677880205\n",
      "train loss:0.007276723173972386\n",
      "train loss:0.009529323578488473\n",
      "train loss:0.0007283341126947654\n",
      "train loss:0.000800036051623858\n",
      "train loss:0.0005598594083432335\n",
      "train loss:0.0008874757242547208\n",
      "train loss:0.004695209244452546\n",
      "train loss:0.008921459701010463\n",
      "train loss:0.003177639271933666\n",
      "train loss:0.002916793457227685\n",
      "train loss:0.0006126191340900008\n",
      "train loss:0.00588885594914877\n",
      "train loss:0.01565133453333896\n",
      "train loss:0.008231612710184723\n",
      "train loss:0.007703098522591639\n",
      "train loss:0.004224095408720704\n",
      "train loss:0.006963479378158888\n",
      "train loss:0.022138883569451432\n",
      "train loss:0.004125932404001779\n",
      "train loss:0.006397636277733129\n",
      "train loss:0.025597550115813262\n",
      "train loss:0.014940895397102803\n",
      "train loss:0.003690520380268896\n",
      "train loss:0.00808430758068878\n",
      "train loss:0.002429077130357706\n",
      "train loss:0.0039639577783220385\n",
      "train loss:0.026993888084500813\n",
      "train loss:0.0025585847104662484\n",
      "train loss:0.010819714041941602\n",
      "train loss:0.025781804946140664\n",
      "train loss:0.011250118086933613\n",
      "train loss:0.005465381849621865\n",
      "train loss:0.026580175845325005\n",
      "train loss:0.005437370237370184\n",
      "train loss:0.0024046206351370173\n",
      "train loss:0.03445650576604951\n",
      "train loss:0.004462454861369871\n",
      "train loss:0.014719442646824179\n",
      "train loss:0.013341378441094145\n",
      "train loss:0.004236861723123896\n",
      "train loss:0.020546510460921076\n",
      "train loss:0.023084583411936324\n",
      "train loss:0.0021102306665090834\n",
      "train loss:0.0006093527957005742\n",
      "train loss:0.0024088840197009926\n",
      "train loss:0.011750969766514609\n",
      "train loss:0.0013911939608523848\n",
      "train loss:0.0031955820351145608\n",
      "train loss:0.01265775766532893\n",
      "train loss:0.0006346725517958887\n",
      "train loss:0.009688253469982415\n",
      "train loss:0.021047472149214045\n",
      "train loss:0.0567159242724805\n",
      "train loss:0.0013289796693901435\n",
      "train loss:0.00462539014511422\n",
      "train loss:0.0023115774436021598\n",
      "train loss:0.005268695285418713\n",
      "train loss:0.005779607207751272\n",
      "train loss:0.0029960311491482577\n",
      "train loss:0.0009699139561006237\n",
      "train loss:0.010665702099087754\n",
      "train loss:0.022905604412464937\n",
      "train loss:0.010456051851943513\n",
      "train loss:0.008663361939073622\n",
      "train loss:0.004764436129479897\n",
      "train loss:0.008612354021684962\n",
      "train loss:0.002170610062948218\n",
      "train loss:0.025497282562411995\n",
      "train loss:0.00754766444270096\n",
      "train loss:0.0008643564160098659\n",
      "train loss:0.0031813322636390696\n",
      "train loss:0.0035086200242239476\n",
      "train loss:0.017070717195738362\n",
      "train loss:0.003394940537013302\n",
      "train loss:0.013564500983180879\n",
      "train loss:0.0031227268809038695\n",
      "train loss:0.006533044795206798\n",
      "train loss:0.011186075005327693\n",
      "train loss:0.006400287379896192\n",
      "train loss:0.0028934739342456562\n",
      "train loss:0.005691095459858512\n",
      "train loss:0.0004626681351229578\n",
      "train loss:0.0012570429153598093\n",
      "train loss:0.0006565619845776191\n",
      "train loss:0.0009309904750642555\n",
      "train loss:0.004764043589795835\n",
      "train loss:0.0009615087930408796\n",
      "train loss:0.007184524594955347\n",
      "train loss:0.0006275042829611317\n",
      "train loss:0.022873081935100414\n",
      "train loss:0.014692442724761683\n",
      "train loss:0.010347953012559849\n",
      "train loss:0.001532098093420375\n",
      "train loss:0.003308159675733256\n",
      "train loss:0.0023266386522840716\n",
      "train loss:0.005333681796365243\n",
      "train loss:0.004328488614712975\n",
      "train loss:0.002109498722546528\n",
      "train loss:0.017599717865715497\n",
      "train loss:0.02063728446086691\n",
      "train loss:0.0067790154606605525\n",
      "train loss:0.0009672943127626713\n",
      "train loss:0.0010083112206002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00210917164966883\n",
      "train loss:0.01708796814010907\n",
      "train loss:0.015121720887195642\n",
      "train loss:0.024825778217735444\n",
      "train loss:0.0022292397908965852\n",
      "train loss:0.010129656715207484\n",
      "train loss:0.0014724390938960327\n",
      "train loss:0.010754680045098634\n",
      "train loss:0.0032200948327666522\n",
      "train loss:0.007855632312665742\n",
      "train loss:0.013396283681947849\n",
      "train loss:0.004929075701247816\n",
      "train loss:0.0019514882134111231\n",
      "train loss:0.02769523797139842\n",
      "train loss:0.004162095137740293\n",
      "train loss:0.0018607586663419709\n",
      "train loss:0.016805973275841574\n",
      "train loss:0.002328392811174693\n",
      "train loss:0.006042454891811176\n",
      "train loss:0.0058910279171725454\n",
      "train loss:0.001925678616875749\n",
      "train loss:0.010069600695948972\n",
      "train loss:0.0012486490103531063\n",
      "train loss:0.014176895738238665\n",
      "train loss:0.003852946028847464\n",
      "train loss:0.006068804384938268\n",
      "train loss:0.006948736891122623\n",
      "train loss:0.0031147030809886064\n",
      "train loss:0.008209076393788272\n",
      "train loss:0.0010832051005200502\n",
      "train loss:0.0013668705904521577\n",
      "train loss:0.006267656327299357\n",
      "train loss:0.0016213901140239913\n",
      "train loss:0.007479399136002752\n",
      "train loss:0.004947048116207264\n",
      "train loss:0.0012186613788795861\n",
      "train loss:0.003533886789545209\n",
      "train loss:0.00768901298066994\n",
      "train loss:0.007858398078172091\n",
      "train loss:0.0013327469502957218\n",
      "train loss:0.005033717364586268\n",
      "train loss:0.010008720678153733\n",
      "train loss:0.0002681444117322342\n",
      "train loss:0.007192841097093964\n",
      "train loss:0.002084408479214904\n",
      "train loss:0.011733427404334903\n",
      "train loss:0.0025127403123821122\n",
      "train loss:0.006176350450904181\n",
      "train loss:0.0037398190782888803\n",
      "train loss:0.010116801458848173\n",
      "train loss:0.0059792273798946385\n",
      "train loss:0.0011109030978007947\n",
      "train loss:0.004996008664476488\n",
      "train loss:0.0036141081948829136\n",
      "train loss:0.0011424318238802717\n",
      "train loss:0.001663652357613696\n",
      "train loss:0.020434047885860295\n",
      "train loss:0.005089209114965072\n",
      "train loss:0.003621260772310558\n",
      "train loss:0.0015859088126920463\n",
      "train loss:0.0017015028257201545\n",
      "train loss:0.0027301159512189933\n",
      "train loss:0.004437500848083809\n",
      "train loss:0.0020168447253439696\n",
      "train loss:0.004164619447044788\n",
      "train loss:0.03133891043212081\n",
      "train loss:0.004261152008024022\n",
      "train loss:0.02457333776284234\n",
      "train loss:0.003269527732151498\n",
      "train loss:0.013560905894543136\n",
      "train loss:0.016720004707121986\n",
      "train loss:0.001207912355443177\n",
      "train loss:0.001978426426621728\n",
      "train loss:0.03504161686848087\n",
      "train loss:0.007661920163805105\n",
      "train loss:0.0016144076961223928\n",
      "train loss:0.008274765345709699\n",
      "train loss:0.0017890341156332201\n",
      "train loss:0.002434438949513812\n",
      "train loss:0.006774275762061852\n",
      "train loss:0.0021348296810703433\n",
      "train loss:0.0009722619532054284\n",
      "train loss:0.017927002017259226\n",
      "train loss:0.0011861484801643253\n",
      "train loss:0.04856854468254128\n",
      "train loss:0.001511348051157665\n",
      "train loss:0.005864971524748927\n",
      "train loss:0.0032543463495536868\n",
      "train loss:0.006866437484374598\n",
      "train loss:0.00451183303296907\n",
      "train loss:0.004227899774897409\n",
      "train loss:0.001912723236245897\n",
      "train loss:0.007964799133729085\n",
      "train loss:0.007978384851448977\n",
      "train loss:0.0012341279175998516\n",
      "train loss:0.0038356596047093594\n",
      "train loss:0.0026240208442655437\n",
      "train loss:0.003365712840047599\n",
      "train loss:0.0010887168406533896\n",
      "train loss:0.012290115711292628\n",
      "train loss:0.005866892220183495\n",
      "train loss:0.00705141955467053\n",
      "train loss:0.034630173764211576\n",
      "train loss:0.004836697488914011\n",
      "train loss:0.03085526271986255\n",
      "train loss:0.009381661940497228\n",
      "train loss:0.009969054511664991\n",
      "train loss:0.026471081673393532\n",
      "train loss:0.0202742450029983\n",
      "train loss:0.032163032456979664\n",
      "train loss:0.0012267313933197845\n",
      "train loss:0.001935254292666069\n",
      "train loss:0.0033550179272553954\n",
      "train loss:0.01530882782395834\n",
      "train loss:0.004623880882796229\n",
      "train loss:0.009971279096189946\n",
      "train loss:0.013162356633089853\n",
      "train loss:0.0007033838084207297\n",
      "train loss:0.01395189409383206\n",
      "train loss:0.006287930440841489\n",
      "train loss:0.010476787333271509\n",
      "train loss:0.0024571695083279005\n",
      "train loss:0.006634762094621034\n",
      "train loss:0.0028895508564865365\n",
      "train loss:0.0003318249610221155\n",
      "train loss:0.002720478714997689\n",
      "train loss:0.0073988087127469845\n",
      "train loss:0.004023430465401634\n",
      "train loss:0.0044245115357499365\n",
      "train loss:0.0007742506666268324\n",
      "train loss:0.005098688189002148\n",
      "train loss:0.013127549775274458\n",
      "train loss:0.0025705109043173756\n",
      "train loss:0.005600878137657178\n",
      "train loss:0.005838454613454432\n",
      "train loss:0.0037565988269558487\n",
      "train loss:0.0018471617482475058\n",
      "train loss:0.00595612975232247\n",
      "train loss:0.0031972616973705626\n",
      "train loss:0.004226262755965389\n",
      "train loss:0.047188450536153906\n",
      "train loss:0.023798646459852718\n",
      "train loss:0.0119154260259842\n",
      "train loss:0.002841728363754427\n",
      "train loss:0.001693546772228722\n",
      "train loss:0.002599804606034496\n",
      "train loss:0.0037916899388627683\n",
      "train loss:0.003247654026195513\n",
      "train loss:0.010004983677674268\n",
      "train loss:0.002158785041196464\n",
      "train loss:0.00133245404387917\n",
      "train loss:0.0013600444033657819\n",
      "train loss:0.002988940052567928\n",
      "train loss:0.0034152977230899094\n",
      "train loss:0.00562631093420151\n",
      "train loss:0.0010195910538529083\n",
      "train loss:0.00480604156183734\n",
      "train loss:0.001771397711129237\n",
      "train loss:0.002782040838125343\n",
      "train loss:0.0034657908232442417\n",
      "train loss:0.005908137588627372\n",
      "train loss:0.020828634398295565\n",
      "train loss:0.000758216645557328\n",
      "train loss:0.005586135953490956\n",
      "train loss:0.009174828644793253\n",
      "train loss:0.00041309933152866915\n",
      "train loss:0.0013818624175665872\n",
      "train loss:0.002625582032407502\n",
      "train loss:0.0030973398281672034\n",
      "train loss:0.008203429519147471\n",
      "train loss:0.0009554693273971755\n",
      "train loss:0.010330325487286886\n",
      "train loss:0.0013746008780178437\n",
      "train loss:0.0005606205734475441\n",
      "train loss:0.0014458116525060502\n",
      "train loss:0.003441300788804896\n",
      "train loss:0.010958247679577683\n",
      "train loss:0.0040113397468169035\n",
      "train loss:0.0016044043646643363\n",
      "train loss:0.004395249039885219\n",
      "train loss:0.010368986978364927\n",
      "train loss:0.003389906793559314\n",
      "train loss:0.002870449163241537\n",
      "train loss:0.005299508664622715\n",
      "train loss:0.00978612288413655\n",
      "train loss:0.0007822018025891323\n",
      "train loss:0.0017218731471305747\n",
      "train loss:0.0028605470858255066\n",
      "train loss:0.02076520809137234\n",
      "train loss:0.0004711858437006988\n",
      "train loss:0.0021186736884992964\n",
      "train loss:0.00037390873358132177\n",
      "train loss:0.0011849845113090485\n",
      "train loss:0.006305130892668025\n",
      "train loss:0.0024774657840355018\n",
      "train loss:0.0006170896814973459\n",
      "train loss:0.0005697347479803953\n",
      "train loss:0.005783282866855141\n",
      "train loss:0.0668122585485163\n",
      "train loss:0.011618100189959768\n",
      "train loss:0.007619963391847914\n",
      "train loss:0.0019138001856824033\n",
      "train loss:0.0027463041967799775\n",
      "train loss:0.002274033657735957\n",
      "train loss:0.011407330644141638\n",
      "train loss:0.008149511235540542\n",
      "train loss:0.006088273066737328\n",
      "train loss:0.0025153816793253166\n",
      "train loss:0.0028829855013760286\n",
      "train loss:0.0013430259163809443\n",
      "train loss:0.002256006665192563\n",
      "train loss:0.0016789643629585202\n",
      "train loss:0.004321401355532741\n",
      "train loss:0.0018952665343910102\n",
      "train loss:0.0025654924482068813\n",
      "train loss:0.0006503820964982662\n",
      "train loss:0.003149312646946942\n",
      "train loss:0.005977838153577159\n",
      "train loss:0.00745725710945866\n",
      "train loss:0.0006290874432937603\n",
      "train loss:0.0139047063081483\n",
      "train loss:0.002329708933056964\n",
      "train loss:0.00190433070474557\n",
      "train loss:0.0032215505685442326\n",
      "train loss:0.008954124059348851\n",
      "train loss:0.007129184230282477\n",
      "train loss:0.0017439217848169955\n",
      "train loss:0.002139506338858874\n",
      "train loss:0.010415912373865448\n",
      "train loss:0.009648886558301319\n",
      "train loss:0.005152960377072625\n",
      "train loss:0.008980063328838847\n",
      "train loss:0.004473334955390453\n",
      "train loss:0.005552999710542272\n",
      "train loss:0.0069657698254632075\n",
      "train loss:0.0049858729556922325\n",
      "train loss:0.011747341028596743\n",
      "train loss:0.009603914629098311\n",
      "train loss:0.0436410807483334\n",
      "train loss:0.0017407115637364532\n",
      "train loss:0.005891886950028936\n",
      "train loss:0.0031164773360395437\n",
      "train loss:0.002694564844470851\n",
      "train loss:0.007654081255827323\n",
      "train loss:0.004219977765888963\n",
      "train loss:0.0024825392487183916\n",
      "train loss:0.0003783786956082259\n",
      "train loss:0.009779257735035617\n",
      "train loss:0.002805150619923282\n",
      "train loss:0.0033149391336394166\n",
      "train loss:0.017701455990197772\n",
      "train loss:0.0004837027446035313\n",
      "train loss:0.007022381643067172\n",
      "train loss:0.009679764356060092\n",
      "train loss:0.0018811278953057868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.008284217040594944\n",
      "train loss:0.0018148219436919352\n",
      "train loss:0.00894310615242345\n",
      "train loss:0.002377375419598636\n",
      "train loss:0.000660140420117428\n",
      "train loss:0.0042095981284451115\n",
      "train loss:0.004620744460846513\n",
      "train loss:0.0013692959437760974\n",
      "train loss:0.007397733235625617\n",
      "train loss:0.019965569473621905\n",
      "train loss:0.008366839698182279\n",
      "train loss:0.0032150342672105296\n",
      "train loss:0.002865613513874341\n",
      "train loss:0.012747302153878075\n",
      "train loss:0.005275782920184829\n",
      "train loss:0.002849932761522513\n",
      "train loss:0.0014222477063355165\n",
      "train loss:0.004576985034234223\n",
      "train loss:0.001802707899083827\n",
      "train loss:0.002269390133032025\n",
      "train loss:0.0026554379327138333\n",
      "train loss:0.004736407798741443\n",
      "train loss:0.0031521568966675\n",
      "train loss:0.020093126407512565\n",
      "train loss:0.021519051238491432\n",
      "train loss:0.0012666404012515074\n",
      "train loss:0.003974988434778569\n",
      "train loss:0.0007078475963596543\n",
      "train loss:0.001442213734789581\n",
      "train loss:0.0018186580497743727\n",
      "train loss:0.0014360598967438625\n",
      "train loss:0.013474549289553257\n",
      "train loss:0.009943749352412035\n",
      "train loss:0.009843133964960019\n",
      "train loss:0.0022228198380948405\n",
      "=== epoch:11, train acc:0.995, test acc:0.988 ===\n",
      "train loss:0.0016630441907123652\n",
      "train loss:0.012605778869770677\n",
      "train loss:0.006194666703556922\n",
      "train loss:0.00483021456488879\n",
      "train loss:0.010422572175520197\n",
      "train loss:0.0031901558400064052\n",
      "train loss:0.003501581759663232\n",
      "train loss:0.0020124928601625612\n",
      "train loss:0.007765693700790759\n",
      "train loss:0.003380468295088645\n",
      "train loss:0.0014828983381736782\n",
      "train loss:0.0024235065052824094\n",
      "train loss:0.009833111641647576\n",
      "train loss:0.008879893098615307\n",
      "train loss:0.002522783696683574\n",
      "train loss:0.004723735647450858\n",
      "train loss:0.005838493036228917\n",
      "train loss:0.02728264744709523\n",
      "train loss:0.001856327915948242\n",
      "train loss:0.0006855250190980702\n",
      "train loss:0.0036553508483668454\n",
      "train loss:0.0030925384121224943\n",
      "train loss:0.002350125513306619\n",
      "train loss:0.004578918966824822\n",
      "train loss:0.0032567240602725755\n",
      "train loss:0.006975056523149774\n",
      "train loss:0.0043650566750498285\n",
      "train loss:0.0016501711940087437\n",
      "train loss:0.012094991328332624\n",
      "train loss:0.002669711903339266\n",
      "train loss:0.0037148316785860173\n",
      "train loss:0.008694819059108481\n",
      "train loss:0.00969000029800537\n",
      "train loss:0.002715688939958633\n",
      "train loss:0.015421243444624344\n",
      "train loss:0.011323520416062091\n",
      "train loss:0.0001386016042267132\n",
      "train loss:0.0037044433408717696\n",
      "train loss:0.0059558398273373715\n",
      "train loss:0.005101796696782793\n",
      "train loss:0.005921268338337848\n",
      "train loss:0.0003408681068765036\n",
      "train loss:0.008972601835201597\n",
      "train loss:0.010899763215734264\n",
      "train loss:0.003294645222313571\n",
      "train loss:0.0015110127542630658\n",
      "train loss:0.0024841365118097995\n",
      "train loss:0.002284953824695355\n",
      "train loss:0.002071848133491242\n",
      "train loss:0.005655836113946136\n",
      "train loss:0.02026785277678693\n",
      "train loss:0.0008020458089688338\n",
      "train loss:0.0007831412786719897\n",
      "train loss:0.041831498689408206\n",
      "train loss:0.0025868778239975902\n",
      "train loss:0.0008103973780340246\n",
      "train loss:0.0011685947228712845\n",
      "train loss:0.003364648407522309\n",
      "train loss:0.0006507053943772332\n",
      "train loss:0.003648152324488707\n",
      "train loss:0.016959278426130122\n",
      "train loss:0.011463370973749219\n",
      "train loss:0.0070543233467231115\n",
      "train loss:0.0007663448686483948\n",
      "train loss:0.0022963540835452033\n",
      "train loss:0.0008412075087210426\n",
      "train loss:0.016177659222990075\n",
      "train loss:0.003795491201649203\n",
      "train loss:0.00580759998124513\n",
      "train loss:0.02016569465375713\n",
      "train loss:0.01906597132360204\n",
      "train loss:0.005092697116976609\n",
      "train loss:0.008280946143300619\n",
      "train loss:0.0066106884082282776\n",
      "train loss:0.020297234412845998\n",
      "train loss:0.005060486714533258\n",
      "train loss:0.016822795770361217\n",
      "train loss:0.002219142916547796\n",
      "train loss:0.0030671428789480963\n",
      "train loss:0.005810267324176467\n",
      "train loss:0.008484025997134763\n",
      "train loss:0.002708572856026591\n",
      "train loss:0.0009267987269648461\n",
      "train loss:0.0010995508108593132\n",
      "train loss:0.012283306323827846\n",
      "train loss:0.0035866563731245505\n",
      "train loss:0.006366598602292389\n",
      "train loss:0.028923174507217375\n",
      "train loss:0.009306803065249267\n",
      "train loss:0.027013736882144767\n",
      "train loss:0.00621709250343146\n",
      "train loss:0.010448977588769734\n",
      "train loss:0.007520399175032313\n",
      "train loss:0.04331803404398524\n",
      "train loss:0.0016342272696237838\n",
      "train loss:0.02510716979632527\n",
      "train loss:0.002121730274827681\n",
      "train loss:0.008678872035495904\n",
      "train loss:0.01321171285762702\n",
      "train loss:0.004221733489290255\n",
      "train loss:0.002283804981666869\n",
      "train loss:0.008403805623218987\n",
      "train loss:0.005856619430571129\n",
      "train loss:0.007705890761512258\n",
      "train loss:0.008846560938666023\n",
      "train loss:0.0030897880284814776\n",
      "train loss:0.011984417963103183\n",
      "train loss:0.0016782671835511823\n",
      "train loss:0.004090099683137375\n",
      "train loss:0.0020842106795260214\n",
      "train loss:0.006024554128129039\n",
      "train loss:0.016435563344454795\n",
      "train loss:0.004493666221333946\n",
      "train loss:0.008447206470743884\n",
      "train loss:0.02145099624877701\n",
      "train loss:0.0073729907452429145\n",
      "train loss:0.0009500830067113955\n",
      "train loss:0.009681012170466692\n",
      "train loss:0.005756914076954753\n",
      "train loss:0.03803602349630287\n",
      "train loss:0.0011622795894790058\n",
      "train loss:0.024602253668327245\n",
      "train loss:0.005270288496514368\n",
      "train loss:0.00891381871845788\n",
      "train loss:0.062317226287981045\n",
      "train loss:0.02834476316448867\n",
      "train loss:0.04791739806742343\n",
      "train loss:0.06644344008524532\n",
      "train loss:0.010940690447198649\n",
      "train loss:0.00405473646691184\n",
      "train loss:0.0009442130991439417\n",
      "train loss:0.03971421788657435\n",
      "train loss:0.009891095908089296\n",
      "train loss:0.009748409951707272\n",
      "train loss:0.001675080252692272\n",
      "train loss:0.004805467361881841\n",
      "train loss:0.013917966233117206\n",
      "train loss:0.001485800918183154\n",
      "train loss:0.004695421950713195\n",
      "train loss:0.01437039342654448\n",
      "train loss:0.024684440719896342\n",
      "train loss:0.0016147224880717424\n",
      "train loss:0.01360152792696847\n",
      "train loss:0.012168805267459431\n",
      "train loss:0.003848818950840436\n",
      "train loss:0.004168998338596413\n",
      "train loss:0.0023458968668644163\n",
      "train loss:0.0016000952604586323\n",
      "train loss:0.008570281506325965\n",
      "train loss:0.0028860800206176552\n",
      "train loss:0.004974596729189226\n",
      "train loss:0.004905138794521651\n",
      "train loss:0.0012552831680865929\n",
      "train loss:0.008936923703450322\n",
      "train loss:0.0025152732354536333\n",
      "train loss:0.0070964904821160715\n",
      "train loss:0.011069741985650123\n",
      "train loss:0.004813500376523863\n",
      "train loss:0.004883525990787574\n",
      "train loss:0.009585259503827511\n",
      "train loss:0.0049610054753080265\n",
      "train loss:0.01088387009928556\n",
      "train loss:0.003085677732384668\n",
      "train loss:0.0013058872499387836\n",
      "train loss:0.0003393730235747364\n",
      "train loss:0.002974997767970173\n",
      "train loss:0.0052059848646529485\n",
      "train loss:0.006275406050150511\n",
      "train loss:0.004481795213771607\n",
      "train loss:0.0026665999038997484\n",
      "train loss:0.0005660319087073575\n",
      "train loss:0.00401656641100665\n",
      "train loss:0.0011531296874371958\n",
      "train loss:0.00895550660445608\n",
      "train loss:0.011465324244699012\n",
      "train loss:0.0011565466087111497\n",
      "train loss:0.008075578427190451\n",
      "train loss:0.0020984556093866253\n",
      "train loss:0.0005353218264640833\n",
      "train loss:0.004811191673763679\n",
      "train loss:0.0019821055785715982\n",
      "train loss:0.0002487448885288516\n",
      "train loss:0.005066873540139563\n",
      "train loss:0.00716862279135095\n",
      "train loss:0.0011433839187735245\n",
      "train loss:0.009061803388998977\n",
      "train loss:0.0005259718704416522\n",
      "train loss:0.004454665733916361\n",
      "train loss:0.001678733025363038\n",
      "train loss:0.003769405640431403\n",
      "train loss:0.0020419466857400682\n",
      "train loss:0.0011657529707637846\n",
      "train loss:0.01111085796644362\n",
      "train loss:0.0036536429778186814\n",
      "train loss:0.004517915030989117\n",
      "train loss:0.03155080455411941\n",
      "train loss:0.009516352693428161\n",
      "train loss:0.001412235905181076\n",
      "train loss:0.0009059531351566732\n",
      "train loss:0.004187229179121893\n",
      "train loss:0.0025796045875049567\n",
      "train loss:0.010768343686029011\n",
      "train loss:0.0034610109867020396\n",
      "train loss:0.05712768225557408\n",
      "train loss:0.00036226097155980466\n",
      "train loss:0.0017509235833755657\n",
      "train loss:0.013443608487028257\n",
      "train loss:0.016157071574845305\n",
      "train loss:0.0027706795889609116\n",
      "train loss:0.0011480131532541943\n",
      "train loss:0.0016644052685372704\n",
      "train loss:0.004895500742088016\n",
      "train loss:0.0014859907245151486\n",
      "train loss:0.0037609160248397518\n",
      "train loss:0.019246118875148165\n",
      "train loss:0.0016859338184773498\n",
      "train loss:0.0027930323382068306\n",
      "train loss:0.0017393254586023127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0008339517622521136\n",
      "train loss:0.025211855694247873\n",
      "train loss:0.06851439286650397\n",
      "train loss:0.0019293490388772483\n",
      "train loss:0.006645808858380068\n",
      "train loss:0.004293328666940656\n",
      "train loss:0.0036665955791873044\n",
      "train loss:0.009726967541139182\n",
      "train loss:0.0026491535778256432\n",
      "train loss:0.003574894241188743\n",
      "train loss:0.003216667407914674\n",
      "train loss:0.005628978151157521\n",
      "train loss:0.006894988260973361\n",
      "train loss:0.0032396245409746314\n",
      "train loss:0.019661694096790836\n",
      "train loss:0.0016901465863812348\n",
      "train loss:0.012961766348116471\n",
      "train loss:0.0020038216758665717\n",
      "train loss:0.013256087669313585\n",
      "train loss:0.0021766853203869724\n",
      "train loss:0.0014546357666613543\n",
      "train loss:0.0009576663954875697\n",
      "train loss:0.0030765214132299334\n",
      "train loss:0.003245832712698101\n",
      "train loss:0.006789373404141255\n",
      "train loss:0.007526249743673168\n",
      "train loss:0.0011490247697766673\n",
      "train loss:0.0032807016466942732\n",
      "train loss:0.006676327073915244\n",
      "train loss:0.007696532095700702\n",
      "train loss:0.01629129657880777\n",
      "train loss:0.0007468474479372608\n",
      "train loss:0.005052188949819897\n",
      "train loss:0.008586378049783808\n",
      "train loss:0.009613680825583872\n",
      "train loss:0.0014348373233334715\n",
      "train loss:0.00435788459012813\n",
      "train loss:0.0015069712950829981\n",
      "train loss:0.0019158361859930263\n",
      "train loss:0.026851058719276046\n",
      "train loss:0.002391777619260069\n",
      "train loss:0.005427223228863188\n",
      "train loss:0.0016029644940912633\n",
      "train loss:0.01772411132132095\n",
      "train loss:0.005258025560491051\n",
      "train loss:0.00546227774637884\n",
      "train loss:0.003093930649868713\n",
      "train loss:0.002018738207135279\n",
      "train loss:0.01492671151731898\n",
      "train loss:0.005968116034866582\n",
      "train loss:0.009431917598301842\n",
      "train loss:0.005764426637293989\n",
      "train loss:0.004642720876094865\n",
      "train loss:0.013043709087566921\n",
      "train loss:0.002475145967580556\n",
      "train loss:0.0008536059706856795\n",
      "train loss:0.005456983928587396\n",
      "train loss:0.003224533960173788\n",
      "train loss:0.002205506607818497\n",
      "train loss:0.003635494202813699\n",
      "train loss:0.0006353454203682475\n",
      "train loss:0.003918644368738211\n",
      "train loss:0.003587810961250706\n",
      "train loss:0.003616061356539433\n",
      "train loss:0.009409550985856484\n",
      "train loss:0.0005485494085704833\n",
      "train loss:0.0007655007339015288\n",
      "train loss:0.0062583327533629\n",
      "train loss:0.0009492168506692957\n",
      "train loss:0.0016972729327838154\n",
      "train loss:0.010103869939366437\n",
      "train loss:0.007986812111481223\n",
      "train loss:0.0012303184109549532\n",
      "train loss:0.004723041147539738\n",
      "train loss:0.002184209415349756\n",
      "train loss:0.008303015809344262\n",
      "train loss:0.0032785748065172443\n",
      "train loss:0.0012082935550340444\n",
      "train loss:0.006144284553867587\n",
      "train loss:0.008553167500946632\n",
      "train loss:0.0006555093193511634\n",
      "train loss:0.00930236012906286\n",
      "train loss:0.0058213526667514615\n",
      "train loss:0.0027032597233127625\n",
      "train loss:0.0038926413902089165\n",
      "train loss:0.003051438749778744\n",
      "train loss:0.00036118067526869\n",
      "train loss:0.010387378491841192\n",
      "train loss:0.0029600990857699084\n",
      "train loss:0.0020591768544830445\n",
      "train loss:0.00463951854420526\n",
      "train loss:0.004823299076926551\n",
      "train loss:0.00039122228082729695\n",
      "train loss:0.00938638621236402\n",
      "train loss:0.0028754208563059264\n",
      "train loss:0.00771722233355633\n",
      "train loss:0.0046159154764816475\n",
      "train loss:0.006314032686648022\n",
      "train loss:0.021297705698188722\n",
      "train loss:0.0006122073921364172\n",
      "train loss:0.0071094273902575335\n",
      "train loss:0.009667835530965469\n",
      "train loss:0.020169162085422968\n",
      "train loss:0.001028782183796343\n",
      "train loss:0.0011723471177476246\n",
      "train loss:0.0033862979238814843\n",
      "train loss:0.002690087717096021\n",
      "train loss:0.001172198319058398\n",
      "train loss:0.00313445903305065\n",
      "train loss:0.013022488357092205\n",
      "train loss:0.012070416672541296\n",
      "train loss:0.001987295345318129\n",
      "train loss:0.0033706965370477663\n",
      "train loss:0.00705244343655928\n",
      "train loss:0.0050992051432467884\n",
      "train loss:0.004332989594630925\n",
      "train loss:0.00506798187878216\n",
      "train loss:0.00822448556449703\n",
      "train loss:0.0007098823601048119\n",
      "train loss:0.00203322518178943\n",
      "train loss:0.0026579465836308173\n",
      "train loss:0.03219369917114901\n",
      "train loss:0.003351313798359465\n",
      "train loss:0.01126009599575252\n",
      "train loss:0.001663920408995866\n",
      "train loss:0.005171658401524413\n",
      "train loss:0.01582426606939286\n",
      "train loss:0.0030942008172481273\n",
      "train loss:0.004925892445593954\n",
      "train loss:0.00450080563674463\n",
      "train loss:0.005814586884055317\n",
      "train loss:0.013047700920898384\n",
      "train loss:0.005813607690211816\n",
      "train loss:0.010500956873581435\n",
      "train loss:0.00019684175557033455\n",
      "train loss:0.00028995218256155247\n",
      "train loss:0.002328766988605429\n",
      "train loss:0.0017697937321526109\n",
      "train loss:0.01005811658960767\n",
      "train loss:0.000794504294378196\n",
      "train loss:0.0012561295420193022\n",
      "train loss:0.0003802984736213315\n",
      "train loss:0.004721260525238983\n",
      "train loss:0.00414233656756689\n",
      "train loss:0.003534413588098976\n",
      "train loss:0.000983855221902087\n",
      "train loss:0.0043505925621706\n",
      "train loss:0.005938913738077856\n",
      "train loss:0.0031003248239918264\n",
      "train loss:0.0051667491493612785\n",
      "train loss:0.0031937651550722744\n",
      "train loss:0.00552575322589413\n",
      "train loss:0.01087168140557932\n",
      "train loss:0.004883113003233035\n",
      "train loss:0.027949811231436462\n",
      "train loss:0.0007337399920649305\n",
      "train loss:0.0009986448553404826\n",
      "train loss:0.0005112272956649761\n",
      "train loss:0.002736624475799284\n",
      "train loss:0.004401710468758214\n",
      "train loss:0.0012710112769112154\n",
      "train loss:0.0017572873462071467\n",
      "train loss:0.001118130722831154\n",
      "train loss:0.0030635742658600006\n",
      "train loss:0.004653576129974828\n",
      "train loss:0.005425939144010353\n",
      "train loss:0.0012427982973236386\n",
      "train loss:0.002124113378841835\n",
      "train loss:0.0017544937842759072\n",
      "train loss:0.011230510875755977\n",
      "train loss:0.015178373483677012\n",
      "train loss:0.0008658368327278856\n",
      "train loss:0.005742375699660122\n",
      "train loss:0.002052391300637751\n",
      "train loss:0.0029501269076756906\n",
      "train loss:0.010869716473823295\n",
      "train loss:0.0162672609625422\n",
      "train loss:0.00020189125957262066\n",
      "train loss:0.016547897632403382\n",
      "train loss:7.478736236584026e-05\n",
      "train loss:0.002206529130401613\n",
      "train loss:0.0023218906550596485\n",
      "train loss:0.004231437519101146\n",
      "train loss:0.0018302244989238494\n",
      "train loss:0.0009287570898341415\n",
      "train loss:0.005839443743869644\n",
      "train loss:0.0002846128005111452\n",
      "train loss:0.006683279913312361\n",
      "train loss:0.0017218769334072723\n",
      "train loss:0.005845996758731333\n",
      "train loss:0.0036843013796164833\n",
      "train loss:0.0011973537045207898\n",
      "train loss:0.004974273050535255\n",
      "train loss:0.004862048393039545\n",
      "train loss:0.0007498536715089641\n",
      "train loss:0.060683222516060786\n",
      "train loss:0.0026639147960185326\n",
      "train loss:0.0012605373616757707\n",
      "train loss:0.0021898338333882967\n",
      "train loss:0.0030978733446528368\n",
      "train loss:0.003939339476285098\n",
      "train loss:0.001735730644601263\n",
      "train loss:0.00516751326243208\n",
      "train loss:0.0013153167348907615\n",
      "train loss:0.014408227773903692\n",
      "train loss:0.016132997988894907\n",
      "train loss:0.0011811722906797594\n",
      "train loss:0.016581182447117822\n",
      "train loss:0.0055002271523275125\n",
      "train loss:0.0011611107362098385\n",
      "train loss:0.0010307812979042158\n",
      "train loss:0.011538161329498184\n",
      "train loss:0.004087840752983254\n",
      "train loss:0.0024665695051993013\n",
      "train loss:0.004105442686387459\n",
      "train loss:0.0019870838178361917\n",
      "train loss:0.003382793647462034\n",
      "train loss:0.004208385373542191\n",
      "train loss:0.01077778783040874\n",
      "train loss:0.003181725953108255\n",
      "train loss:0.00048040354597819843\n",
      "train loss:0.0006063265666281534\n",
      "train loss:0.0031363389232134426\n",
      "train loss:0.0008805710057848851\n",
      "train loss:0.0016852994507156765\n",
      "train loss:0.009953405182417413\n",
      "train loss:0.0018041972421892444\n",
      "train loss:0.04352257085306286\n",
      "train loss:0.003627981605931459\n",
      "train loss:0.0025155648373601886\n",
      "train loss:0.0029141989435065357\n",
      "train loss:0.003555219384407907\n",
      "train loss:0.0011178422352418485\n",
      "train loss:0.0011354789191271493\n",
      "train loss:0.0022730354235798236\n",
      "train loss:0.005292942171532861\n",
      "train loss:0.000190881985870173\n",
      "train loss:0.0004126571400632401\n",
      "train loss:0.009185549904884568\n",
      "train loss:0.004893388670119969\n",
      "train loss:0.0020378889786503186\n",
      "train loss:0.001515116133712524\n",
      "train loss:0.013122817663058926\n",
      "train loss:0.002436449677198464\n",
      "train loss:0.002828841946271228\n",
      "train loss:0.008883562500765904\n",
      "train loss:0.006652554742551623\n",
      "train loss:0.0043938682617216075\n",
      "train loss:0.003374614163734112\n",
      "train loss:0.0005675580749957322\n",
      "train loss:0.004936456349493501\n",
      "train loss:0.00033910883162285036\n",
      "train loss:0.00853348893316175\n",
      "train loss:0.006094884724230246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0015616908247537214\n",
      "train loss:0.006703230649013336\n",
      "train loss:0.0055298238000631925\n",
      "train loss:0.0082616246817261\n",
      "train loss:0.002134410834031045\n",
      "train loss:0.015371428043990262\n",
      "train loss:0.0014037402152950482\n",
      "train loss:0.018583176410426897\n",
      "train loss:0.0018556566798661257\n",
      "train loss:0.00033627327412750726\n",
      "train loss:0.006947573314743237\n",
      "train loss:0.015942947949850364\n",
      "train loss:0.003398536103351214\n",
      "train loss:0.03220181769488896\n",
      "train loss:0.01212065522248562\n",
      "train loss:0.003602346153444313\n",
      "train loss:0.0015874042093994923\n",
      "train loss:0.0012772321512622168\n",
      "train loss:0.0041850385348425655\n",
      "train loss:0.019680434478271426\n",
      "train loss:0.000914547170245702\n",
      "train loss:0.0016561489089189604\n",
      "train loss:0.0005916646158129505\n",
      "train loss:0.016669502832556124\n",
      "train loss:0.007347880555081022\n",
      "train loss:0.005362992588163882\n",
      "train loss:0.06130378746825145\n",
      "train loss:0.0037669109090976006\n",
      "train loss:0.001092327915736284\n",
      "train loss:0.004894451563788604\n",
      "train loss:0.0009062422605736005\n",
      "train loss:0.02277139457388423\n",
      "train loss:0.002871976968914853\n",
      "train loss:0.0012197914097803713\n",
      "train loss:0.013941031825605526\n",
      "train loss:0.0031918609473212383\n",
      "train loss:0.018518234798604292\n",
      "train loss:0.029961314618676148\n",
      "train loss:0.003423270033583055\n",
      "train loss:0.004394847652423949\n",
      "train loss:0.015467312612819407\n",
      "train loss:0.00037321050556817013\n",
      "train loss:0.0036473887106763777\n",
      "train loss:0.0011399584672238754\n",
      "train loss:0.016179161399471377\n",
      "train loss:0.0010249854272320724\n",
      "train loss:0.00543804711729195\n",
      "train loss:0.0022113431962445724\n",
      "train loss:0.1685134365180367\n",
      "train loss:0.0013629334682693842\n",
      "train loss:0.00222128991989653\n",
      "train loss:0.0034691220713760408\n",
      "train loss:0.001975940303165393\n",
      "train loss:0.013037153437668232\n",
      "train loss:0.005759903417019695\n",
      "train loss:0.01391752008781725\n",
      "train loss:0.0038316051056282107\n",
      "train loss:0.02867967854434934\n",
      "train loss:0.0026653122723332132\n",
      "train loss:0.01290864123877483\n",
      "train loss:0.00037515773302811015\n",
      "train loss:0.0012139383503058845\n",
      "train loss:0.0005508493608308019\n",
      "train loss:0.008577995471984921\n",
      "train loss:0.005381157405571986\n",
      "train loss:0.0008853205495896842\n",
      "train loss:0.013474834777069195\n",
      "train loss:0.002657926295720864\n",
      "train loss:0.0027941523408039266\n",
      "train loss:0.006286299116219009\n",
      "train loss:0.0015592453370163494\n",
      "train loss:0.005629129022134537\n",
      "train loss:0.0038154841066860828\n",
      "train loss:0.0008724804519656187\n",
      "train loss:0.00127235426962268\n",
      "train loss:0.011952525601953888\n",
      "train loss:0.006826908854797871\n",
      "train loss:0.0013237862076679707\n",
      "train loss:0.007250675393460201\n",
      "train loss:0.000252569849535258\n",
      "train loss:0.002863226208964884\n",
      "train loss:0.005982335174031993\n",
      "train loss:0.0035681824974386684\n",
      "train loss:0.0010141727599007244\n",
      "train loss:0.004197639869175337\n",
      "train loss:0.005120821286454544\n",
      "train loss:0.000596737575772218\n",
      "train loss:0.0037519354794330797\n",
      "train loss:0.004372090197060761\n",
      "train loss:0.00039002170592752065\n",
      "train loss:0.00901756927701331\n",
      "train loss:0.004282995084601805\n",
      "train loss:0.0035283400615912317\n",
      "train loss:0.0027062214405432715\n",
      "train loss:0.0025132402205470753\n",
      "train loss:0.000927641784035656\n",
      "train loss:0.009417996632682453\n",
      "train loss:0.0039765685931291515\n",
      "train loss:0.0003789366043045249\n",
      "train loss:0.004441042461851738\n",
      "train loss:0.0007380046795042063\n",
      "train loss:0.0351523644785702\n",
      "train loss:0.0014629800734019625\n",
      "train loss:0.0037897253890918966\n",
      "train loss:0.014375116923305667\n",
      "train loss:0.0020508994487531745\n",
      "train loss:0.0010013816221348974\n",
      "train loss:0.0012505603661303417\n",
      "train loss:0.008499242014577342\n",
      "train loss:0.007845033005083206\n",
      "train loss:0.0244565806123043\n",
      "train loss:0.007178911332215235\n",
      "train loss:0.0021431649141387316\n",
      "train loss:0.004369095555806947\n",
      "train loss:0.0022984901658917255\n",
      "train loss:0.007989224621735297\n",
      "train loss:0.0035120967137936263\n",
      "train loss:0.0008361107417310526\n",
      "train loss:0.0012085689074565246\n",
      "train loss:0.005440036006694039\n",
      "train loss:0.004335838667107903\n",
      "train loss:0.00872031595875543\n",
      "train loss:0.004088369183051484\n",
      "train loss:0.0035229792283143968\n",
      "train loss:0.002285448104001755\n",
      "train loss:0.0007653199548657963\n",
      "train loss:0.0015419415085103974\n",
      "train loss:0.0049606981988778364\n",
      "=== epoch:12, train acc:0.995, test acc:0.987 ===\n",
      "train loss:0.003498710548131818\n",
      "train loss:0.009308372861405139\n",
      "train loss:0.0062747475354977345\n",
      "train loss:0.002011842704298926\n",
      "train loss:0.001710650863367032\n",
      "train loss:0.004796906507266117\n",
      "train loss:0.0014012824241729613\n",
      "train loss:0.004712463711303669\n",
      "train loss:0.0008631915962611267\n",
      "train loss:0.0006306255793138234\n",
      "train loss:0.005239388914967048\n",
      "train loss:0.009826227072428601\n",
      "train loss:0.0021563688727912643\n",
      "train loss:0.002912315405741771\n",
      "train loss:0.008097008993443691\n",
      "train loss:0.0036469380901919986\n",
      "train loss:0.17619498214173962\n",
      "train loss:0.008260405007004194\n",
      "train loss:0.0025260754593768196\n",
      "train loss:0.009763240068040677\n",
      "train loss:0.01170366150912367\n",
      "train loss:0.00618647153493732\n",
      "train loss:0.0009835526445923309\n",
      "train loss:0.003464269320597217\n",
      "train loss:0.0061343815017465275\n",
      "train loss:0.0021413236137325675\n",
      "train loss:0.0036460698927854424\n",
      "train loss:0.0034836344371282344\n",
      "train loss:0.004194687971574592\n",
      "train loss:0.007213253512544117\n",
      "train loss:0.005248229267256394\n",
      "train loss:0.011603368832916112\n",
      "train loss:0.003952256353404424\n",
      "train loss:0.005815576280237924\n",
      "train loss:0.0024295770404116996\n",
      "train loss:0.010908670604268684\n",
      "train loss:0.0014882645871166578\n",
      "train loss:0.00550955918532655\n",
      "train loss:0.014430769115219136\n",
      "train loss:0.011165084674748636\n",
      "train loss:0.0032042941984129635\n",
      "train loss:0.005237337749265999\n",
      "train loss:0.010049703591183339\n",
      "train loss:0.0011502781216190243\n",
      "train loss:0.0027538005286288593\n",
      "train loss:0.0017353730559948224\n",
      "train loss:0.0005593517734684502\n",
      "train loss:0.005223656446385008\n",
      "train loss:0.006289230291526853\n",
      "train loss:0.0044034581784777845\n",
      "train loss:0.004584511640241404\n",
      "train loss:0.004245708539507411\n",
      "train loss:0.00537880153885723\n",
      "train loss:0.0028561800435568667\n",
      "train loss:0.0001927466610941688\n",
      "train loss:0.008847922992659463\n",
      "train loss:0.013970121124265635\n",
      "train loss:0.001590668799802778\n",
      "train loss:0.0010762688546576082\n",
      "train loss:0.0026323268674287325\n",
      "train loss:0.001119584316258661\n",
      "train loss:0.0033449163084592424\n",
      "train loss:0.0006346046118251516\n",
      "train loss:0.0059613595778154616\n",
      "train loss:0.003703647830666962\n",
      "train loss:0.02098053048761119\n",
      "train loss:0.0009032984406002381\n",
      "train loss:0.0054755242905151595\n",
      "train loss:0.0078057535368196065\n",
      "train loss:0.0042496802680843\n",
      "train loss:0.00906153008365127\n",
      "train loss:0.0005287313812335457\n",
      "train loss:0.0034560987360864187\n",
      "train loss:0.00429562719118926\n",
      "train loss:0.007331301553417684\n",
      "train loss:0.008655475489782237\n",
      "train loss:0.003254590727121375\n",
      "train loss:0.011971695696973992\n",
      "train loss:0.003350109044836115\n",
      "train loss:0.004717177430645083\n",
      "train loss:0.0025134689225401346\n",
      "train loss:0.0029789324198217114\n",
      "train loss:0.009937919807825948\n",
      "train loss:0.0005513467667066087\n",
      "train loss:0.0016743786316192858\n",
      "train loss:0.009487399329043172\n",
      "train loss:0.0010346774463932814\n",
      "train loss:0.0020045982201183604\n",
      "train loss:0.0008010442011147748\n",
      "train loss:0.0011075747448381359\n",
      "train loss:0.0006428110908370402\n",
      "train loss:0.008486127965559843\n",
      "train loss:0.00040626071134072724\n",
      "train loss:0.011996009320036628\n",
      "train loss:0.0010896647021547768\n",
      "train loss:0.0020875221382103647\n",
      "train loss:0.0011532225704831843\n",
      "train loss:0.0018884528826531072\n",
      "train loss:0.016693131023595514\n",
      "train loss:0.012212341373839284\n",
      "train loss:0.006103955895119858\n",
      "train loss:0.004989508239603887\n",
      "train loss:0.0029726908549471387\n",
      "train loss:0.0008837508985273701\n",
      "train loss:0.011046249587943863\n",
      "train loss:0.01334623872355861\n",
      "train loss:0.0043904130896757\n",
      "train loss:0.030318052926572775\n",
      "train loss:0.0020484855176940452\n",
      "train loss:0.004860877959620851\n",
      "train loss:0.001266276512941928\n",
      "train loss:0.0024468089561431026\n",
      "train loss:0.0037044637410067784\n",
      "train loss:0.009898530895561058\n",
      "train loss:0.0006132507524354467\n",
      "train loss:0.0009989090183112187\n",
      "train loss:0.0009947883990229314\n",
      "train loss:0.0009043271583440956\n",
      "train loss:0.0018635392614886742\n",
      "train loss:0.004123886716914357\n",
      "train loss:0.00401905577452379\n",
      "train loss:0.0013939744196083729\n",
      "train loss:0.014730866669090853\n",
      "train loss:0.01498051978154867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00273616624186664\n",
      "train loss:0.0011467864562423322\n",
      "train loss:0.013443293046901254\n",
      "train loss:0.009006644778673096\n",
      "train loss:0.002121705193516003\n",
      "train loss:0.0073542709188767295\n",
      "train loss:0.010527228261477315\n",
      "train loss:0.000981938121342848\n",
      "train loss:0.0016496641206023624\n",
      "train loss:0.005595251570187936\n",
      "train loss:0.0057776619433380005\n",
      "train loss:0.0035936967561282208\n",
      "train loss:0.0015854593768403025\n",
      "train loss:0.00447081035093602\n",
      "train loss:0.003641799566686972\n",
      "train loss:0.0032179824656434057\n",
      "train loss:0.012242879847418666\n",
      "train loss:0.02316064980398991\n",
      "train loss:0.0014121883703818905\n",
      "train loss:0.0014481998074948796\n",
      "train loss:0.004723762947372831\n",
      "train loss:0.0008138701796359804\n",
      "train loss:0.0019917044903914314\n",
      "train loss:0.0009181300145578189\n",
      "train loss:0.013627449818601329\n",
      "train loss:0.0050708801598774765\n",
      "train loss:0.0019042506910614864\n",
      "train loss:0.0012882310206595534\n",
      "train loss:0.0030895143471744092\n",
      "train loss:0.00419633642723034\n",
      "train loss:0.003039169239584561\n",
      "train loss:0.00428953939619218\n",
      "train loss:0.001967490370738767\n",
      "train loss:0.0016607922448632273\n",
      "train loss:0.002783308175880754\n",
      "train loss:0.020362006431979697\n",
      "train loss:0.005688170936134461\n",
      "train loss:0.0025824776217971915\n",
      "train loss:0.005380918136307875\n",
      "train loss:0.004504975260982329\n",
      "train loss:0.006511828347190853\n",
      "train loss:0.0034551320121185302\n",
      "train loss:0.0016027889980563435\n",
      "train loss:0.0017428896236669994\n",
      "train loss:0.0015784776634122954\n",
      "train loss:0.00386087085675898\n",
      "train loss:0.00297710770928082\n",
      "train loss:0.0023350791443658174\n",
      "train loss:0.001398865890541159\n",
      "train loss:0.04973087065699963\n",
      "train loss:0.004016846037033997\n",
      "train loss:0.012450049681063755\n",
      "train loss:0.0028661021723877696\n",
      "train loss:0.004246869999264214\n",
      "train loss:0.0005442967243122481\n",
      "train loss:0.00775624398822254\n",
      "train loss:0.0023857769138282818\n",
      "train loss:0.002402721663373422\n",
      "train loss:0.03770330149628359\n",
      "train loss:0.00444783728722989\n",
      "train loss:0.02365549487399529\n",
      "train loss:0.01656100117117497\n",
      "train loss:0.003954304735507759\n",
      "train loss:0.007492374468504787\n",
      "train loss:0.002911700717946491\n",
      "train loss:0.00343646928624624\n",
      "train loss:0.011872758966630863\n",
      "train loss:0.0012568460432181663\n",
      "train loss:0.004642971429062413\n",
      "train loss:0.0019043931568959744\n",
      "train loss:0.004607502294618159\n",
      "train loss:0.001079176327314448\n",
      "train loss:0.016522286945921665\n",
      "train loss:0.004418540322935923\n",
      "train loss:0.014942852271525076\n",
      "train loss:0.0014278132984650671\n",
      "train loss:0.00041657854390219593\n",
      "train loss:0.010669736850998637\n",
      "train loss:0.0020222776802809937\n",
      "train loss:0.00328368146963683\n",
      "train loss:0.005907457913405142\n",
      "train loss:0.006437307456306368\n",
      "train loss:0.0017905928058271103\n",
      "train loss:0.013706682078629542\n",
      "train loss:0.0042609954726329355\n",
      "train loss:0.001712961378706826\n",
      "train loss:0.0015088414162156003\n",
      "train loss:0.0060780576984802125\n",
      "train loss:0.0024986153259856985\n",
      "train loss:0.009897621976689409\n",
      "train loss:0.000929100490152636\n",
      "train loss:0.011970988088762928\n",
      "train loss:0.007603709912048211\n",
      "train loss:0.001010231188910046\n",
      "train loss:0.03090633311979407\n",
      "train loss:0.004638007275977176\n",
      "train loss:0.0005837150762113979\n",
      "train loss:0.014464296145101576\n",
      "train loss:0.02141689714550953\n",
      "train loss:0.0054037064099089335\n",
      "train loss:0.003761365803183835\n",
      "train loss:0.00451677055821113\n",
      "train loss:0.004103864194133783\n",
      "train loss:0.0007134853195271863\n",
      "train loss:0.006029634863474065\n",
      "train loss:0.004066948861012238\n",
      "train loss:0.1276805206721147\n",
      "train loss:0.002698409167696962\n",
      "train loss:0.0019626593564629684\n",
      "train loss:0.0007861659971006861\n",
      "train loss:0.018745217767647485\n",
      "train loss:0.02985413039906827\n",
      "train loss:0.0030058674768653902\n",
      "train loss:0.011121116564860114\n",
      "train loss:0.0005223536327847282\n",
      "train loss:0.0014400077163362129\n",
      "train loss:0.014793520268367522\n",
      "train loss:0.002352595811161668\n",
      "train loss:0.0033959901048641076\n",
      "train loss:0.0112318852292393\n",
      "train loss:0.011062060777518106\n",
      "train loss:0.004254354663953563\n",
      "train loss:0.008447804748342433\n",
      "train loss:0.004782847229854195\n",
      "train loss:0.006555355250535146\n",
      "train loss:0.00040917789420664817\n",
      "train loss:0.011729879193095214\n",
      "train loss:0.0032517234906557202\n",
      "train loss:0.0030326605964783163\n",
      "train loss:0.004522510267593647\n",
      "train loss:0.0020807735393313016\n",
      "train loss:0.0005887028302447983\n",
      "train loss:0.005191112180223615\n",
      "train loss:0.022499375142386625\n",
      "train loss:0.0014027033611652999\n",
      "train loss:0.0010956933244455499\n",
      "train loss:0.014370454717123813\n",
      "train loss:0.0025953935803944934\n",
      "train loss:0.16419441177453997\n",
      "train loss:0.0011404937540555951\n",
      "train loss:0.007128236040343984\n",
      "train loss:0.0015370715969630475\n",
      "train loss:0.014173474312698157\n",
      "train loss:0.0025229911884318283\n",
      "train loss:0.003840933373588524\n",
      "train loss:0.008073128854028033\n",
      "train loss:0.0010050081409281907\n",
      "train loss:0.0024861819073570064\n",
      "train loss:0.002290495114826481\n",
      "train loss:0.0019821593481698947\n",
      "train loss:0.04122358259498185\n",
      "train loss:0.003765806334963234\n",
      "train loss:0.0019298007580167884\n",
      "train loss:0.001337167373800773\n",
      "train loss:0.0043152251751117495\n",
      "train loss:0.007612597669474026\n",
      "train loss:0.0025523502035210257\n",
      "train loss:0.008935933607757242\n",
      "train loss:0.015564229995647699\n",
      "train loss:0.11022474058847706\n",
      "train loss:0.004136278607736736\n",
      "train loss:0.02263678022667392\n",
      "train loss:0.010901159972194395\n",
      "train loss:0.0025232716699051115\n",
      "train loss:0.010274730870105052\n",
      "train loss:0.012433528516947172\n",
      "train loss:0.003502592822170654\n",
      "train loss:0.012079371420863017\n",
      "train loss:0.004032913459130466\n",
      "train loss:0.0034506535270894755\n",
      "train loss:0.0018164949672540623\n",
      "train loss:0.007907082666551291\n",
      "train loss:0.005563510399024625\n",
      "train loss:0.0004801347100376583\n",
      "train loss:0.017322015754588225\n",
      "train loss:0.0016886581627573222\n",
      "train loss:0.008117407487906405\n",
      "train loss:0.0050271731842109904\n",
      "train loss:0.002855977695385182\n",
      "train loss:0.008240075650560248\n",
      "train loss:0.0016917547715975872\n",
      "train loss:0.0020422648545686825\n",
      "train loss:0.020926166599519704\n",
      "train loss:0.02026926123687745\n",
      "train loss:0.0010184853038454704\n",
      "train loss:0.007210324608759586\n",
      "train loss:0.0032182826380263573\n",
      "train loss:0.04537556439760359\n",
      "train loss:0.026206685803299733\n",
      "train loss:0.0024978332318131443\n",
      "train loss:0.004170263560914274\n",
      "train loss:0.0031003952313252143\n",
      "train loss:0.0008717496003003656\n",
      "train loss:0.001485871586455928\n",
      "train loss:0.010876580354694854\n",
      "train loss:0.005554129192070406\n",
      "train loss:0.003147744667465664\n",
      "train loss:0.0030792800305249955\n",
      "train loss:0.005168993304488069\n",
      "train loss:0.006401993040327132\n",
      "train loss:0.0034216128666478326\n",
      "train loss:0.0025615866580818375\n",
      "train loss:0.0038567337161938605\n",
      "train loss:0.0061925862228754056\n",
      "train loss:0.002023322324773454\n",
      "train loss:0.002047874986035816\n",
      "train loss:0.006424310507703015\n",
      "train loss:0.0045010991941840765\n",
      "train loss:0.011398641995090789\n",
      "train loss:0.0024063628497748364\n",
      "train loss:0.0010354940156313357\n",
      "train loss:0.0018732391847495233\n",
      "train loss:0.011876772700527415\n",
      "train loss:0.0047491989953772065\n",
      "train loss:0.012323114719832627\n",
      "train loss:0.0036795981288474115\n",
      "train loss:0.00741377919353304\n",
      "train loss:0.004359418596370123\n",
      "train loss:0.018291220351459078\n",
      "train loss:0.001996147298660491\n",
      "train loss:0.00037436709442344033\n",
      "train loss:0.0020129382122905212\n",
      "train loss:0.0013930971548443366\n",
      "train loss:0.0025064318062597035\n",
      "train loss:0.02613242027237471\n",
      "train loss:0.012489708499173276\n",
      "train loss:0.0013611768413550906\n",
      "train loss:0.0014701918162986437\n",
      "train loss:0.0005245821571297413\n",
      "train loss:0.002543231957867856\n",
      "train loss:0.0011468642815173217\n",
      "train loss:0.003204336563533066\n",
      "train loss:0.018875732304754714\n",
      "train loss:0.025696153054515083\n",
      "train loss:0.0034740351816447647\n",
      "train loss:0.006484333578669999\n",
      "train loss:0.002200173722309758\n",
      "train loss:0.005177623997044456\n",
      "train loss:0.005480436478152024\n",
      "train loss:0.002723781526772282\n",
      "train loss:0.0031045645311856083\n",
      "train loss:0.016766113749506824\n",
      "train loss:0.002474823356621951\n",
      "train loss:0.007452047868532984\n",
      "train loss:0.014311264280726172\n",
      "train loss:0.003939340369760899\n",
      "train loss:0.0018387716131808723\n",
      "train loss:0.004226587516627214\n",
      "train loss:0.041506640238014585\n",
      "train loss:0.010411604362675282\n",
      "train loss:0.005482274837365408\n",
      "train loss:0.0006644905638304573\n",
      "train loss:0.005350395329875817\n",
      "train loss:0.0023939497629198764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.005559734767407566\n",
      "train loss:0.0003223303298428139\n",
      "train loss:0.0005180514636710052\n",
      "train loss:0.010408194176269115\n",
      "train loss:0.0006854557681313497\n",
      "train loss:0.0033601096171355467\n",
      "train loss:0.0007852405059296575\n",
      "train loss:0.002493553678737127\n",
      "train loss:0.002824333325010327\n",
      "train loss:0.0042977579338224475\n",
      "train loss:0.001938896913445172\n",
      "train loss:0.0016887418469757381\n",
      "train loss:0.001662650955459228\n",
      "train loss:0.015611369663627478\n",
      "train loss:0.006425152071183369\n",
      "train loss:0.0033762979916223397\n",
      "train loss:0.0023649428777778635\n",
      "train loss:0.0014858508742906335\n",
      "train loss:0.005698073408464357\n",
      "train loss:0.0050413946688901\n",
      "train loss:0.0006939447355758768\n",
      "train loss:0.0023258892922104735\n",
      "train loss:0.000420221434440828\n",
      "train loss:0.0010114827138772782\n",
      "train loss:0.003174066623119613\n",
      "train loss:0.0015030210833679564\n",
      "train loss:0.006332887429426924\n",
      "train loss:0.003943549025427313\n",
      "train loss:0.021039706054527336\n",
      "train loss:0.0018954382624193672\n",
      "train loss:0.005997317401345482\n",
      "train loss:0.0017818196677841268\n",
      "train loss:0.002977482196476182\n",
      "train loss:0.001915212860714021\n",
      "train loss:0.00044135234486517775\n",
      "train loss:0.001697503544549783\n",
      "train loss:0.0003795344302444772\n",
      "train loss:0.0005279370205041351\n",
      "train loss:0.0004030357745758682\n",
      "train loss:0.00047187030494492374\n",
      "train loss:0.0036197861692951337\n",
      "train loss:0.003788439765624457\n",
      "train loss:0.001689554688767039\n",
      "train loss:0.002586073485483326\n",
      "train loss:0.0028941760771261315\n",
      "train loss:0.004430477185235171\n",
      "train loss:0.0009425654645886421\n",
      "train loss:0.00236869208796633\n",
      "train loss:0.03359008770215404\n",
      "train loss:0.0007359858651471624\n",
      "train loss:0.002118884807238107\n",
      "train loss:0.0014617147497049893\n",
      "train loss:0.002348960916235701\n",
      "train loss:0.004927458016390993\n",
      "train loss:0.0034847019224823494\n",
      "train loss:0.003855216437030636\n",
      "train loss:0.0025159742443569195\n",
      "train loss:0.0036535878526217404\n",
      "train loss:0.0033176585908808592\n",
      "train loss:0.00102143255721192\n",
      "train loss:0.002664690336285058\n",
      "train loss:0.004611399605407098\n",
      "train loss:0.0024454680699939123\n",
      "train loss:0.0017232832844742657\n",
      "train loss:0.005070120532179205\n",
      "train loss:0.00329047949048468\n",
      "train loss:0.0008697735499385305\n",
      "train loss:0.0023674926684846814\n",
      "train loss:6.769288571247888e-05\n",
      "train loss:0.0004076499851392831\n",
      "train loss:0.0010603893728353179\n",
      "train loss:0.0030777117760017792\n",
      "train loss:0.0004015929797565103\n",
      "train loss:0.012451532783901367\n",
      "train loss:0.006528885587794726\n",
      "train loss:0.0014984687548308363\n",
      "train loss:0.0010224563937584821\n",
      "train loss:0.002070748634712732\n",
      "train loss:0.002038841783940945\n",
      "train loss:0.00014018537039936746\n",
      "train loss:0.00018934408669243696\n",
      "train loss:0.000724405819615637\n",
      "train loss:0.0028502072219723333\n",
      "train loss:0.004112807054048289\n",
      "train loss:0.0008282497750775047\n",
      "train loss:0.005810124600296848\n",
      "train loss:0.0032431543642799463\n",
      "train loss:0.016935818857816403\n",
      "train loss:0.013330981232455632\n",
      "train loss:0.004769638359011545\n",
      "train loss:0.001570924914870971\n",
      "train loss:0.0025405800258296927\n",
      "train loss:0.004136445214276208\n",
      "train loss:0.005373595681075824\n",
      "train loss:0.036743612062659935\n",
      "train loss:0.0027459222650549177\n",
      "train loss:0.005215953655502805\n",
      "train loss:0.0002701416327147995\n",
      "train loss:0.005297566084002777\n",
      "train loss:0.0016089718624946539\n",
      "train loss:0.0014846364518963733\n",
      "train loss:0.002108389747732329\n",
      "train loss:0.0070607408322411235\n",
      "train loss:0.001700424349009031\n",
      "train loss:0.001465636748306221\n",
      "train loss:0.0024945349171053392\n",
      "train loss:0.00754542006951087\n",
      "train loss:0.008524345734827975\n",
      "train loss:0.0077461633200923445\n",
      "train loss:0.0007072945105890631\n",
      "train loss:0.0032168568066505516\n",
      "train loss:0.0011902946052790495\n",
      "train loss:0.0017976394958063157\n",
      "train loss:0.0038018718667634983\n",
      "train loss:0.00024809244607931573\n",
      "train loss:0.0018688566479597463\n",
      "train loss:0.0024049263803600316\n",
      "train loss:0.005081487382890785\n",
      "train loss:0.004334557294651469\n",
      "train loss:0.0028202065454696014\n",
      "train loss:0.003944189691175593\n",
      "train loss:0.002668460913220229\n",
      "train loss:0.00028068074809405903\n",
      "train loss:0.0014534691906794163\n",
      "train loss:0.0026970832033162036\n",
      "train loss:0.012060723367473715\n",
      "train loss:0.003358033043400776\n",
      "train loss:0.005283712593909826\n",
      "train loss:0.001113000230703524\n",
      "train loss:0.0005257341668353112\n",
      "train loss:0.007549141048503519\n",
      "train loss:0.0024528717552160686\n",
      "train loss:0.0016261732589358357\n",
      "train loss:0.0012404994726928139\n",
      "train loss:0.001955725774366754\n",
      "train loss:0.03136890481679223\n",
      "train loss:0.003748293940664489\n",
      "train loss:0.00013910238166664558\n",
      "train loss:0.0007739171073026525\n",
      "train loss:0.004632046052925471\n",
      "train loss:0.01600202934163472\n",
      "train loss:0.004266392955483551\n",
      "train loss:0.005683805566338164\n",
      "train loss:0.005621945335493706\n",
      "train loss:0.003445943890996958\n",
      "train loss:0.0007090091192484147\n",
      "train loss:0.000972485879526651\n",
      "train loss:0.0005897769650051912\n",
      "train loss:0.0013212179160667819\n",
      "train loss:0.004020873161362793\n",
      "train loss:0.010267221310033117\n",
      "train loss:0.0011275280736361133\n",
      "train loss:0.0012624211110344352\n",
      "train loss:0.0018353283700631717\n",
      "train loss:0.007043399828437248\n",
      "train loss:0.0007342984110747332\n",
      "train loss:0.0013073791867905798\n",
      "train loss:0.002590380884941942\n",
      "train loss:0.014505500248805538\n",
      "train loss:0.009204254049812698\n",
      "train loss:0.0006451586220669106\n",
      "train loss:0.0009139165401192386\n",
      "train loss:0.0021620596830935358\n",
      "train loss:0.0008601940212791534\n",
      "train loss:0.008526126483861439\n",
      "train loss:0.0009195428096297655\n",
      "train loss:0.011910880458393815\n",
      "train loss:0.012300885820541568\n",
      "train loss:0.00044156195114463607\n",
      "train loss:0.00030735361995287437\n",
      "train loss:0.00035163471195382714\n",
      "train loss:0.0001938075375762523\n",
      "train loss:0.0006990568308857534\n",
      "train loss:0.0009533470066303841\n",
      "train loss:0.007352145118889781\n",
      "train loss:0.00038407963147352284\n",
      "train loss:0.0019047861332071687\n",
      "train loss:0.0035567968772698706\n",
      "train loss:0.06379152686716986\n",
      "train loss:0.0010701602751421776\n",
      "train loss:0.002668864361035535\n",
      "train loss:0.005320761202545841\n",
      "train loss:0.003412352282712418\n",
      "train loss:0.004447478635296523\n",
      "train loss:0.001173562217708551\n",
      "train loss:0.0028240838492237775\n",
      "train loss:0.0016951932167760203\n",
      "train loss:0.001264188751060928\n",
      "train loss:0.015960992219209505\n",
      "train loss:0.0039943926432863906\n",
      "train loss:0.0008027739731356746\n",
      "train loss:0.00043633467872895105\n",
      "train loss:0.0014220040651922727\n",
      "train loss:0.018052945741168436\n",
      "train loss:0.011616691877343486\n",
      "train loss:0.006774608081263865\n",
      "train loss:0.0016730259811565764\n",
      "train loss:0.00854527947631867\n",
      "train loss:0.004033021238132207\n",
      "train loss:0.0031574163668086404\n",
      "train loss:0.002991923207225316\n",
      "train loss:0.003465805991785642\n",
      "train loss:0.013078494201518529\n",
      "train loss:0.0038146489059324596\n",
      "train loss:0.008778541041047196\n",
      "train loss:0.0008098150484185142\n",
      "train loss:0.0005721699200633408\n",
      "train loss:0.009061508247127257\n",
      "train loss:0.0051511036627810425\n",
      "train loss:0.007587077403537823\n",
      "train loss:0.001590918655506942\n",
      "train loss:0.011080748782025062\n",
      "train loss:0.00265843611948792\n",
      "train loss:0.001674759602392701\n",
      "train loss:0.0014366359087120623\n",
      "train loss:0.0030460098028629954\n",
      "train loss:0.0014975864665432623\n",
      "train loss:0.001647448502549582\n",
      "train loss:0.0020308805187161734\n",
      "train loss:0.0033467386624192004\n",
      "train loss:0.006189358351419536\n",
      "train loss:0.0017922535529850312\n",
      "=== epoch:13, train acc:0.995, test acc:0.989 ===\n",
      "train loss:0.0013957855147061179\n",
      "train loss:0.0016498653684341238\n",
      "train loss:0.0008322714409968797\n",
      "train loss:0.001382878798313541\n",
      "train loss:0.0036215792185750758\n",
      "train loss:0.0013551365877485528\n",
      "train loss:0.003411662757610136\n",
      "train loss:0.007332282717129462\n",
      "train loss:0.0015119793077984249\n",
      "train loss:0.004487243297671705\n",
      "train loss:0.003346739866742893\n",
      "train loss:0.008571610088236516\n",
      "train loss:0.0022515951478078613\n",
      "train loss:0.0005668036219917408\n",
      "train loss:0.004517799929366493\n",
      "train loss:0.0009511117083433864\n",
      "train loss:0.0019510769480477743\n",
      "train loss:0.00044547921479111787\n",
      "train loss:0.001776369541496104\n",
      "train loss:0.000872412082395345\n",
      "train loss:0.10653581285925577\n",
      "train loss:0.0013482041761598781\n",
      "train loss:0.004964218851248653\n",
      "train loss:0.0165850418542879\n",
      "train loss:0.006511849743610454\n",
      "train loss:0.002991955233961075\n",
      "train loss:0.002500514940243902\n",
      "train loss:0.002439354618501427\n",
      "train loss:0.005370795411407599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002939620162857513\n",
      "train loss:6.529429002591873e-05\n",
      "train loss:0.003064719683988039\n",
      "train loss:0.0034812933436916393\n",
      "train loss:0.0018031397258114245\n",
      "train loss:0.0018206633200278483\n",
      "train loss:0.0017624458642091073\n",
      "train loss:0.00010450562499251034\n",
      "train loss:0.006808979726381671\n",
      "train loss:0.002064449035781602\n",
      "train loss:0.005118833076121798\n",
      "train loss:0.007294181711670865\n",
      "train loss:0.0029932050884067564\n",
      "train loss:0.003504766463457223\n",
      "train loss:0.0028979156412307677\n",
      "train loss:0.013621416142385233\n",
      "train loss:0.005357099670086878\n",
      "train loss:0.0006893667706947993\n",
      "train loss:0.0052513096451566885\n",
      "train loss:0.000571443619543003\n",
      "train loss:0.0016213325985588042\n",
      "train loss:0.003921618852870142\n",
      "train loss:0.0002918058905872848\n",
      "train loss:0.0011986071974833695\n",
      "train loss:0.0025186594602106876\n",
      "train loss:0.00041362602533627225\n",
      "train loss:0.0035581083912750965\n",
      "train loss:0.005015657391366037\n",
      "train loss:0.0012731570550160711\n",
      "train loss:0.003211566728095234\n",
      "train loss:0.003769229379106906\n",
      "train loss:0.00026956836996784047\n",
      "train loss:0.0018703656784137262\n",
      "train loss:0.0010278181060710363\n",
      "train loss:0.0024584284876174264\n",
      "train loss:0.0014558368015012136\n",
      "train loss:0.0029654489257833643\n",
      "train loss:0.0022815441883250105\n",
      "train loss:0.003739344605924494\n",
      "train loss:0.0018954168889680557\n",
      "train loss:0.0027917220716277037\n",
      "train loss:0.010312155270318302\n",
      "train loss:0.0014471167807088726\n",
      "train loss:0.013387521680949623\n",
      "train loss:0.0036367670120565697\n",
      "train loss:0.004889416052285717\n",
      "train loss:0.00410824035534344\n",
      "train loss:0.002306270946774377\n",
      "train loss:0.00175120380459395\n",
      "train loss:0.0018690552975315553\n",
      "train loss:0.00042956718314045197\n",
      "train loss:0.004887539629410643\n",
      "train loss:0.005057420606434313\n",
      "train loss:0.0012653352729940644\n",
      "train loss:0.0007087317608532488\n",
      "train loss:0.0015298754911346499\n",
      "train loss:0.0265480141230044\n",
      "train loss:0.0024499382929461847\n",
      "train loss:0.006878157886670241\n",
      "train loss:0.0011456654663602444\n",
      "train loss:0.0038632238532568097\n",
      "train loss:0.0011721910390343068\n",
      "train loss:0.0027304485502661585\n",
      "train loss:0.001246354975204336\n",
      "train loss:0.004703066765482591\n",
      "train loss:0.01025785078662003\n",
      "train loss:0.003810787725500959\n",
      "train loss:0.00018586036158438132\n",
      "train loss:0.02116341588568431\n",
      "train loss:0.0022608203321664118\n",
      "train loss:0.00042307682377311503\n",
      "train loss:0.015615129274850386\n",
      "train loss:0.001562674891895927\n",
      "train loss:0.000748014501804265\n",
      "train loss:0.01665690307000312\n",
      "train loss:0.012079855012082816\n",
      "train loss:0.0003754108268776561\n",
      "train loss:0.004027993799172336\n",
      "train loss:0.004275487641264303\n",
      "train loss:0.004938385970329682\n",
      "train loss:0.003334880759801311\n",
      "train loss:0.006500726958874215\n",
      "train loss:0.003840393909177348\n",
      "train loss:0.0003303817664670092\n",
      "train loss:0.0035136444781690875\n",
      "train loss:0.0023786779698740895\n",
      "train loss:0.004436222986746756\n",
      "train loss:0.00296286440159194\n",
      "train loss:0.007916011323379143\n",
      "train loss:0.0037459809880648638\n",
      "train loss:0.0021028739044571267\n",
      "train loss:0.0013967983063923703\n",
      "train loss:0.0036700264994481173\n",
      "train loss:0.006298938612683207\n",
      "train loss:0.0019914874671872577\n",
      "train loss:0.004294365855541514\n",
      "train loss:0.011748749850992906\n",
      "train loss:0.0008133219242052628\n",
      "train loss:0.002770012189597591\n",
      "train loss:0.00030522254510393374\n",
      "train loss:0.0016684308018678853\n",
      "train loss:0.0012020889208792119\n",
      "train loss:0.002778920496262684\n",
      "train loss:0.0010376608178299176\n",
      "train loss:0.0016302673118589928\n",
      "train loss:0.008294486140784414\n",
      "train loss:0.0006846777036576734\n",
      "train loss:0.0034204985360991834\n",
      "train loss:0.004005990127979418\n",
      "train loss:0.00239136672022601\n",
      "train loss:0.005061159548758038\n",
      "train loss:0.0016735084565385103\n",
      "train loss:0.0003630052241670664\n",
      "train loss:0.0010980076624640062\n",
      "train loss:0.0017582308370044544\n",
      "train loss:0.004088172209763912\n",
      "train loss:0.013363484449134369\n",
      "train loss:0.0024964812236116713\n",
      "train loss:0.0004649142937148625\n",
      "train loss:0.0015652737514862325\n",
      "train loss:0.0026098622633789507\n",
      "train loss:0.0005909058174467676\n",
      "train loss:0.00018692440306909437\n",
      "train loss:0.006530095005255385\n",
      "train loss:0.0008573233388890545\n",
      "train loss:0.00014630130815562663\n",
      "train loss:0.004499796029883004\n",
      "train loss:0.0006860995138662899\n",
      "train loss:0.003669031689158237\n",
      "train loss:0.0014137553421655052\n",
      "train loss:0.002186742412329811\n",
      "train loss:0.002518819853247895\n",
      "train loss:0.0011613269583860104\n",
      "train loss:0.0012452317059842017\n",
      "train loss:0.00046898166890397224\n",
      "train loss:0.0013095933649925858\n",
      "train loss:0.0023897543276333918\n",
      "train loss:0.008900730014357571\n",
      "train loss:0.0016317255985796061\n",
      "train loss:0.0003750422155766285\n",
      "train loss:0.0018468830106595647\n",
      "train loss:0.0008789242861852023\n",
      "train loss:7.109968120342264e-05\n",
      "train loss:0.002652902659211315\n",
      "train loss:0.00019102439612460976\n",
      "train loss:0.002471033706382048\n",
      "train loss:0.03238640324141645\n",
      "train loss:0.0019179770562710444\n",
      "train loss:0.008713641600453986\n",
      "train loss:0.0036857643335145985\n",
      "train loss:0.02450646882860765\n",
      "train loss:0.004914375730479645\n",
      "train loss:0.0049659073630757555\n",
      "train loss:0.004171264149619731\n",
      "train loss:0.0033895223059774494\n",
      "train loss:0.009250083006971964\n",
      "train loss:0.0045874155420596455\n",
      "train loss:0.004676468220986557\n",
      "train loss:0.0052651873179845885\n",
      "train loss:0.0007371019026271763\n",
      "train loss:0.0021923548692795516\n",
      "train loss:0.0019206776909502252\n",
      "train loss:0.005469287956924549\n",
      "train loss:0.002041197234274227\n",
      "train loss:0.00018819414144078\n",
      "train loss:0.0032473421839377516\n",
      "train loss:0.003000369841869962\n",
      "train loss:0.036003014064854885\n",
      "train loss:0.00714660776231493\n",
      "train loss:0.0037469455086747766\n",
      "train loss:0.008003713277072283\n",
      "train loss:0.025623468903369993\n",
      "train loss:0.00533930262837882\n",
      "train loss:0.0013998398190749237\n",
      "train loss:0.0010761300560787517\n",
      "train loss:0.0010339896806824827\n",
      "train loss:0.004074372759742334\n",
      "train loss:0.009941388837809755\n",
      "train loss:0.0027050573641659594\n",
      "train loss:0.002212452655271039\n",
      "train loss:0.0021714708698502227\n",
      "train loss:0.0009012773923309905\n",
      "train loss:0.0028948285962019306\n",
      "train loss:0.005222850763700132\n",
      "train loss:0.005366366760010658\n",
      "train loss:0.0016247663644584115\n",
      "train loss:0.005361243515296137\n",
      "train loss:0.0008106387179483038\n",
      "train loss:0.0029322122473906436\n",
      "train loss:0.004020166884176291\n",
      "train loss:0.011596829285290442\n",
      "train loss:0.007522395415378097\n",
      "train loss:0.0007218829625379692\n",
      "train loss:0.0028601767093750967\n",
      "train loss:0.0009940303535868748\n",
      "train loss:0.00044567805855281984\n",
      "train loss:0.0019850029238049987\n",
      "train loss:0.0017003604716737714\n",
      "train loss:0.0015276880031712629\n",
      "train loss:0.0034001453895472493\n",
      "train loss:0.007732097052359318\n",
      "train loss:0.0009665386519064824\n",
      "train loss:0.0021393593554267674\n",
      "train loss:0.0013511677995241603\n",
      "train loss:0.004328473774509084\n",
      "train loss:0.0004341286258998648\n",
      "train loss:0.0018332107043128121\n",
      "train loss:0.0018706963810117482\n",
      "train loss:0.0030704836203689096\n",
      "train loss:0.010851139741905554\n",
      "train loss:0.002909796337573088\n",
      "train loss:0.00498723792289579\n",
      "train loss:0.0005238486283563986\n",
      "train loss:0.0009074077432398605\n",
      "train loss:0.00206473253579764\n",
      "train loss:0.002096688230764212\n",
      "train loss:0.002338602229277992\n",
      "train loss:0.001069138543556638\n",
      "train loss:0.0015044374596168402\n",
      "train loss:0.001581786955128214\n",
      "train loss:0.0003306449160885322\n",
      "train loss:0.000805333762130193\n",
      "train loss:0.005798387830191452\n",
      "train loss:0.0012895792958171099\n",
      "train loss:0.0003294021550577657\n",
      "train loss:0.001960171824311151\n",
      "train loss:0.0008644277508582286\n",
      "train loss:0.004163490437624335\n",
      "train loss:0.0008331658029406324\n",
      "train loss:0.001274882031671466\n",
      "train loss:0.0014913677459348518\n",
      "train loss:0.02670288226224877\n",
      "train loss:0.003662129079557484\n",
      "train loss:0.0023748630483335677\n",
      "train loss:0.0008787544029098413\n",
      "train loss:0.001990331033811904\n",
      "train loss:0.009154268079789842\n",
      "train loss:0.0003861840326502241\n",
      "train loss:0.0022649226510182544\n",
      "train loss:0.0014850147680057573\n",
      "train loss:0.0001507818276807147\n",
      "train loss:0.0019701991423680424\n",
      "train loss:0.00046931604849767024\n",
      "train loss:0.0010671218186632625\n",
      "train loss:0.0012095830888005513\n",
      "train loss:0.0013651880948679458\n",
      "train loss:0.0006309015430621975\n",
      "train loss:0.0008772714706892535\n",
      "train loss:0.002321270543887398\n",
      "train loss:0.0010716162761246143\n",
      "train loss:0.0021434478403618605\n",
      "train loss:0.0058995827378689894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0006603200480509299\n",
      "train loss:0.0029867055703782126\n",
      "train loss:0.0007975285998266812\n",
      "train loss:0.004343988259509329\n",
      "train loss:0.0015785966725413516\n",
      "train loss:0.003754663341445603\n",
      "train loss:0.0010816959349045725\n",
      "train loss:0.015324352188034922\n",
      "train loss:0.008095750798861575\n",
      "train loss:0.0032160859135134967\n",
      "train loss:0.0010750974356434873\n",
      "train loss:0.00020992022057261128\n",
      "train loss:0.000966598771091204\n",
      "train loss:0.0007380810587620994\n",
      "train loss:0.004597603708278651\n",
      "train loss:0.001143467961173025\n",
      "train loss:0.00027176833011355355\n",
      "train loss:0.0019696030134938453\n",
      "train loss:0.0007877171378417741\n",
      "train loss:0.0013971569825643666\n",
      "train loss:0.0008076841039615163\n",
      "train loss:0.0026978468801584325\n",
      "train loss:0.0016624361392689438\n",
      "train loss:0.0036984642405240324\n",
      "train loss:0.0008997552063595282\n",
      "train loss:0.004204017016456162\n",
      "train loss:0.001336724219432666\n",
      "train loss:0.0005806072221732954\n",
      "train loss:0.0015061172077303656\n",
      "train loss:0.00218772991179375\n",
      "train loss:0.0015149750306454406\n",
      "train loss:0.00026008892749417067\n",
      "train loss:0.013784608677360512\n",
      "train loss:0.00020717640453055486\n",
      "train loss:0.008082877374739507\n",
      "train loss:0.0027401139947489093\n",
      "train loss:0.0008855390798565829\n",
      "train loss:0.010265498438445535\n",
      "train loss:0.010548996846601077\n",
      "train loss:0.002180518172138433\n",
      "train loss:0.04115550676200028\n",
      "train loss:0.001142601827945794\n",
      "train loss:0.005268407279663556\n",
      "train loss:0.005821807482508056\n",
      "train loss:0.003712236201477061\n",
      "train loss:0.0009803765735818817\n",
      "train loss:0.006337398184297698\n",
      "train loss:0.00026514582919732793\n",
      "train loss:0.0031837021190983224\n",
      "train loss:0.0008268595204919686\n",
      "train loss:0.007347257944990206\n",
      "train loss:0.0010797694061092326\n",
      "train loss:0.016931782393999964\n",
      "train loss:0.000333641719710947\n",
      "train loss:0.018873422074682667\n",
      "train loss:0.00164130633793167\n",
      "train loss:0.001227946541437971\n",
      "train loss:0.010068986207131645\n",
      "train loss:0.0014820703500874068\n",
      "train loss:0.0013717249370518692\n",
      "train loss:0.0036213002945060867\n",
      "train loss:0.00878976714353636\n",
      "train loss:0.0022595494252017024\n",
      "train loss:0.009867923130713479\n",
      "train loss:0.004623018884243266\n",
      "train loss:0.00030893316158590303\n",
      "train loss:0.004914036616539735\n",
      "train loss:0.0008296269568073562\n",
      "train loss:0.0010705121720332757\n",
      "train loss:0.00982570273904221\n",
      "train loss:0.0005765771664824513\n",
      "train loss:5.7041535583292104e-05\n",
      "train loss:0.00041099220393832147\n",
      "train loss:0.0018072053256597352\n",
      "train loss:0.003456159023144183\n",
      "train loss:0.002060899949212585\n",
      "train loss:0.002440024720844265\n",
      "train loss:0.002088488333370915\n",
      "train loss:0.002683126353065292\n",
      "train loss:0.00219148988692399\n",
      "train loss:0.002940331882647677\n",
      "train loss:0.0018468067233138937\n",
      "train loss:0.0007345693596524738\n",
      "train loss:0.0005938803373858815\n",
      "train loss:0.0018092783319776618\n",
      "train loss:0.0018694954280344975\n",
      "train loss:0.00023867361005833621\n",
      "train loss:0.0004211584290807837\n",
      "train loss:0.006351096781906192\n",
      "train loss:0.001957593935400818\n",
      "train loss:0.0017074740683358652\n",
      "train loss:0.006214500561442488\n",
      "train loss:0.001359741567232672\n",
      "train loss:0.0010167446341909539\n",
      "train loss:0.0043975459934866\n",
      "train loss:0.00026309413937686423\n",
      "train loss:0.004157108864542094\n",
      "train loss:0.0035719835099423326\n",
      "train loss:0.0015578004618976287\n",
      "train loss:0.0073676748050618005\n",
      "train loss:0.0028222523589124275\n",
      "train loss:0.006421401757671324\n",
      "train loss:0.0029944390552339856\n",
      "train loss:0.0019822336482134308\n",
      "train loss:0.002901352707154991\n",
      "train loss:0.0003974494249732744\n",
      "train loss:0.0015841120817897975\n",
      "train loss:0.0035421799526747667\n",
      "train loss:0.0020849553742893503\n",
      "train loss:0.0004266004436709056\n",
      "train loss:0.0002988025633655107\n",
      "train loss:0.00015163305668825365\n",
      "train loss:0.0023600256030044233\n",
      "train loss:0.01682691577301636\n",
      "train loss:0.0022296015787012223\n",
      "train loss:0.0014131479364485535\n",
      "train loss:0.005744122699193161\n",
      "train loss:0.0034815886174784636\n",
      "train loss:0.0006122814202249227\n",
      "train loss:0.00035259278097448635\n",
      "train loss:0.0013859905870838923\n",
      "train loss:0.008528981452302636\n",
      "train loss:0.0014642737673351708\n",
      "train loss:0.006394245893505311\n",
      "train loss:0.019809038775916003\n",
      "train loss:0.002106795423416863\n",
      "train loss:0.002979284489082486\n",
      "train loss:0.0019079604935879119\n",
      "train loss:0.00024921738470645076\n",
      "train loss:0.0005769301926233063\n",
      "train loss:0.0034452780343691525\n",
      "train loss:0.0036604994659819967\n",
      "train loss:0.0002030967128260728\n",
      "train loss:0.005910097616821988\n",
      "train loss:0.013421012118150881\n",
      "train loss:0.000838504339696801\n",
      "train loss:0.004152028018874321\n",
      "train loss:0.005776995725631479\n",
      "train loss:0.00400973160641575\n",
      "train loss:0.0036437198935412463\n",
      "train loss:0.0036927873586477798\n",
      "train loss:0.0025903676800008613\n",
      "train loss:0.002243781510388823\n",
      "train loss:0.0007019250521836989\n",
      "train loss:0.0005605271314476925\n",
      "train loss:0.0012842430131678989\n",
      "train loss:0.0009359249284790843\n",
      "train loss:0.00019392172666119416\n",
      "train loss:0.0007789720333838217\n",
      "train loss:0.005442143887240489\n",
      "train loss:0.0018229235964375124\n",
      "train loss:0.004463236490322416\n",
      "train loss:0.0019557218429422725\n",
      "train loss:0.0044822058340937216\n",
      "train loss:0.00045424756871593813\n",
      "train loss:0.017014401032121776\n",
      "train loss:0.00401420282577704\n",
      "train loss:0.0008838021858344952\n",
      "train loss:0.0040589837150607775\n",
      "train loss:0.015585598448351667\n",
      "train loss:0.005757281864905347\n",
      "train loss:0.0011635820192355075\n",
      "train loss:0.0018463418160590825\n",
      "train loss:0.00019088791279220775\n",
      "train loss:0.007472232126128215\n",
      "train loss:0.005031542729808467\n",
      "train loss:0.0025928748815932656\n",
      "train loss:0.0062544197609082095\n",
      "train loss:0.004319454947445019\n",
      "train loss:0.0013695793576840852\n",
      "train loss:0.006461495599554145\n",
      "train loss:0.0048372004299017364\n",
      "train loss:0.002688639091012521\n",
      "train loss:0.0006260570076655143\n",
      "train loss:0.006616178827802143\n",
      "train loss:0.004629505383904961\n",
      "train loss:0.005321452325391549\n",
      "train loss:0.004617088272045206\n",
      "train loss:0.00018289390586808042\n",
      "train loss:0.006739196626869222\n",
      "train loss:0.0734376590587247\n",
      "train loss:0.0006889908002440076\n",
      "train loss:0.005359027066108392\n",
      "train loss:0.0021906899930480062\n",
      "train loss:0.0008298175799712462\n",
      "train loss:0.010158922507205355\n",
      "train loss:0.002995772816075215\n",
      "train loss:0.003234926004735032\n",
      "train loss:0.001666297724853005\n",
      "train loss:0.13883090540550364\n",
      "train loss:0.0045863919364386805\n",
      "train loss:0.0027220464777261964\n",
      "train loss:0.00284693935112557\n",
      "train loss:0.0011164526225335733\n",
      "train loss:0.030180576481965763\n",
      "train loss:0.002779118555410296\n",
      "train loss:0.007082551511954217\n",
      "train loss:0.005158942288241337\n",
      "train loss:0.01966964615202309\n",
      "train loss:0.0038598266497912996\n",
      "train loss:0.000844732300333732\n",
      "train loss:0.002694460593298258\n",
      "train loss:0.0015161374702237903\n",
      "train loss:0.0018393417406163553\n",
      "train loss:0.0003578177315109085\n",
      "train loss:0.003669913962204146\n",
      "train loss:0.0011391235614747407\n",
      "train loss:0.007597795987778117\n",
      "train loss:0.00333128748776765\n",
      "train loss:0.0012897411722793276\n",
      "train loss:0.0007861224136292049\n",
      "train loss:0.010670717336300628\n",
      "train loss:0.0018625886738154126\n",
      "train loss:0.009308444859954187\n",
      "train loss:0.0009203908551337275\n",
      "train loss:0.02928572464227333\n",
      "train loss:0.000615529744911409\n",
      "train loss:0.0024224190670386033\n",
      "train loss:0.00202333250986621\n",
      "train loss:0.0009553049490199469\n",
      "train loss:0.0019702812595056183\n",
      "train loss:0.014655117011944243\n",
      "train loss:0.0004049656155243967\n",
      "train loss:0.007158262860478819\n",
      "train loss:0.003101492902495359\n",
      "train loss:0.004421316408930771\n",
      "train loss:0.0011971523984809463\n",
      "train loss:0.005962681727591832\n",
      "train loss:0.03866806286274362\n",
      "train loss:0.00030338232393293114\n",
      "train loss:0.00251678489820803\n",
      "train loss:0.001314893391662759\n",
      "train loss:0.002149841050654209\n",
      "train loss:0.0013464049368479907\n",
      "train loss:0.005238455157800639\n",
      "train loss:0.051594794533526646\n",
      "train loss:0.001580977386827953\n",
      "train loss:0.004597855798595851\n",
      "train loss:0.0010665011366614268\n",
      "train loss:0.01731152111959746\n",
      "train loss:0.039520678990573654\n",
      "train loss:0.0015358295364542667\n",
      "train loss:0.001775328590101709\n",
      "train loss:0.0016289668540103558\n",
      "train loss:0.02865936275103997\n",
      "train loss:0.010464862332699467\n",
      "train loss:0.016446994847703754\n",
      "train loss:0.0025899224661784493\n",
      "train loss:0.0030772919186895543\n",
      "train loss:0.0014576341154563085\n",
      "train loss:0.0006867881449287134\n",
      "train loss:0.006415003527650429\n",
      "train loss:0.002910552960560889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.005334197757014542\n",
      "train loss:0.005203662833816428\n",
      "train loss:0.0028455753115212107\n",
      "train loss:0.013176987998124614\n",
      "train loss:0.0031409281180723304\n",
      "train loss:0.0008641324351571258\n",
      "train loss:0.002551698114068206\n",
      "train loss:0.005544817376725805\n",
      "train loss:0.003278995980075186\n",
      "train loss:0.005247940480122002\n",
      "train loss:0.00430582477502072\n",
      "train loss:0.005353821073002783\n",
      "train loss:0.0005958376710034287\n",
      "train loss:0.0012410806191760866\n",
      "train loss:0.0034286011063027577\n",
      "train loss:0.00499851371597117\n",
      "train loss:0.00942297834049239\n",
      "train loss:0.001765954818877834\n",
      "train loss:0.0036875077578413435\n",
      "train loss:0.0022514740794909683\n",
      "train loss:0.0002525339649137797\n",
      "train loss:0.006280108650313251\n",
      "train loss:0.05387216359082931\n",
      "train loss:0.0046874011385025895\n",
      "train loss:0.003989691450920575\n",
      "train loss:0.0030924300615150983\n",
      "train loss:0.0007345676006015352\n",
      "train loss:0.000919593036133571\n",
      "train loss:0.009974887399521537\n",
      "train loss:0.003244468972659736\n",
      "train loss:0.003582889946324867\n",
      "train loss:0.0002337591403409703\n",
      "train loss:0.004195882515450121\n",
      "train loss:0.010812898481519234\n",
      "train loss:0.0024978273148440135\n",
      "train loss:0.007488190002700379\n",
      "train loss:0.0012268488917971355\n",
      "train loss:0.0013818755425522398\n",
      "train loss:0.003886729339919514\n",
      "train loss:0.0003554105111210229\n",
      "train loss:0.006557805838219376\n",
      "train loss:0.0024166889040225102\n",
      "train loss:0.054350253026405504\n",
      "train loss:0.02284497128806663\n",
      "train loss:0.00023062594419359382\n",
      "train loss:0.006028689496629908\n",
      "train loss:0.0004989569867919739\n",
      "train loss:0.00395587780870077\n",
      "train loss:0.0007799072777993771\n",
      "train loss:0.002094863330603683\n",
      "train loss:0.001818338234726525\n",
      "train loss:0.0009466135574466486\n",
      "train loss:0.004382425738961621\n",
      "train loss:0.0009398719803969062\n",
      "train loss:0.00030330922187909266\n",
      "train loss:0.005378220975913375\n",
      "train loss:0.007889831561242771\n",
      "train loss:0.006609716342877428\n",
      "train loss:0.0007361495498151736\n",
      "train loss:0.0008018682384614077\n",
      "train loss:0.017548619344425153\n",
      "train loss:0.00046891937230464695\n",
      "train loss:0.005159318849569617\n",
      "train loss:0.0009092334155962233\n",
      "train loss:0.02024120733162617\n",
      "train loss:0.00032661130067766525\n",
      "=== epoch:14, train acc:0.993, test acc:0.987 ===\n",
      "train loss:0.003404897675137061\n",
      "train loss:0.0015962992872880213\n",
      "train loss:0.008099186053352895\n",
      "train loss:0.0027834820115049696\n",
      "train loss:0.0030959993491162575\n",
      "train loss:0.002080692632497038\n",
      "train loss:0.002486716962425258\n",
      "train loss:0.0019471568917032267\n",
      "train loss:0.04537499979419508\n",
      "train loss:0.009960009423480855\n",
      "train loss:0.0036948708542626075\n",
      "train loss:0.0014965679876877166\n",
      "train loss:0.005853532653636384\n",
      "train loss:0.0035236801119126974\n",
      "train loss:0.0037229619852077412\n",
      "train loss:0.0010933798567675749\n",
      "train loss:0.0058150794630943215\n",
      "train loss:0.0006836037350344009\n",
      "train loss:0.011891954418295303\n",
      "train loss:0.015170497002973918\n",
      "train loss:0.00023786083989982997\n",
      "train loss:0.0012434069902963654\n",
      "train loss:0.0018939942561638707\n",
      "train loss:0.0019411101446690276\n",
      "train loss:0.00288538269462935\n",
      "train loss:0.007068857400511299\n",
      "train loss:0.0002682125144345345\n",
      "train loss:0.006772110315817683\n",
      "train loss:0.0030573180764501\n",
      "train loss:0.004192086807738012\n",
      "train loss:0.04757215759489699\n",
      "train loss:0.007947857895912805\n",
      "train loss:0.002127458806301034\n",
      "train loss:0.0020607270910806778\n",
      "train loss:0.002017600644532586\n",
      "train loss:0.0012164794976638285\n",
      "train loss:0.0013363602133879004\n",
      "train loss:0.0014554372917653614\n",
      "train loss:0.006100099892221942\n",
      "train loss:0.0034377706285791763\n",
      "train loss:0.0020533689942818924\n",
      "train loss:0.017496924232448367\n",
      "train loss:0.004471866487716028\n",
      "train loss:0.0005816342397923168\n",
      "train loss:0.0010642547356436024\n",
      "train loss:0.0038517880816807655\n",
      "train loss:0.00792460999298627\n",
      "train loss:0.0024751545558469603\n",
      "train loss:0.00039314199682244957\n",
      "train loss:0.005605695135396977\n",
      "train loss:0.03908573454284379\n",
      "train loss:0.0008109277177249474\n",
      "train loss:0.0021505564006501655\n",
      "train loss:0.0009042193387267309\n",
      "train loss:0.002943025554721397\n",
      "train loss:0.00332526486014941\n",
      "train loss:0.0013237876521525879\n",
      "train loss:0.0050975036809505665\n",
      "train loss:0.003824495717317551\n",
      "train loss:0.008146808603716723\n",
      "train loss:0.0012515750033020906\n",
      "train loss:0.0002822846862935326\n",
      "train loss:0.0030465187479352825\n",
      "train loss:0.0005156143228711291\n",
      "train loss:0.0051833283708457014\n",
      "train loss:0.009146999345146423\n",
      "train loss:0.00034896048458603183\n",
      "train loss:0.002953734745004266\n",
      "train loss:0.0027629451474552214\n",
      "train loss:0.0025037707289358585\n",
      "train loss:0.0029668091773567677\n",
      "train loss:0.002051848630017119\n",
      "train loss:0.05635301871603079\n",
      "train loss:0.0003658071959134243\n",
      "train loss:0.004317311316448313\n",
      "train loss:0.0018171714822576824\n",
      "train loss:0.006637377344541498\n",
      "train loss:0.003510412836932462\n",
      "train loss:0.0007071456120098944\n",
      "train loss:0.004464424578615322\n",
      "train loss:0.004826258330531138\n",
      "train loss:0.020955680993907575\n",
      "train loss:0.010024290552290567\n",
      "train loss:0.0018776310015973898\n",
      "train loss:3.725897664868467e-05\n",
      "train loss:0.0015505271407948026\n",
      "train loss:0.0016498096044476574\n",
      "train loss:0.0062244488310658555\n",
      "train loss:0.0021108181637305152\n",
      "train loss:0.0012013763276170657\n",
      "train loss:0.0015932950608270784\n",
      "train loss:0.0015132732956958331\n",
      "train loss:0.006075797156222759\n",
      "train loss:0.0022070690439830497\n",
      "train loss:0.00030583329313194687\n",
      "train loss:0.00042609319518020083\n",
      "train loss:0.007969091220051691\n",
      "train loss:0.004059045675349039\n",
      "train loss:0.002116320540925242\n",
      "train loss:0.00022947880019154595\n",
      "train loss:0.0021218607924311846\n",
      "train loss:0.006727697416228583\n",
      "train loss:0.0022271413011402097\n",
      "train loss:0.000774199962620261\n",
      "train loss:0.0013543274924351207\n",
      "train loss:0.0012297428982300726\n",
      "train loss:0.002207594232732717\n",
      "train loss:0.0003042466185439107\n",
      "train loss:0.0019825209748075847\n",
      "train loss:0.0015094947356808592\n",
      "train loss:0.0024903433692945887\n",
      "train loss:0.001163974186263816\n",
      "train loss:0.005074500524775608\n",
      "train loss:0.0013401145660295428\n",
      "train loss:0.00029414070563406667\n",
      "train loss:0.003038097272670009\n",
      "train loss:0.01817043256285061\n",
      "train loss:0.11794847080329235\n",
      "train loss:0.000139211158881368\n",
      "train loss:0.00593652307152118\n",
      "train loss:0.0004973845484666003\n",
      "train loss:0.00357044666465105\n",
      "train loss:0.008451572558434322\n",
      "train loss:0.002210663031277389\n",
      "train loss:0.000896521635280397\n",
      "train loss:0.0010693871444907282\n",
      "train loss:0.0005043492537767932\n",
      "train loss:0.0004520340719939845\n",
      "train loss:0.0012728468994067212\n",
      "train loss:0.018962297709121\n",
      "train loss:0.0054922815414329565\n",
      "train loss:0.01998107654713922\n",
      "train loss:0.007487952906351584\n",
      "train loss:0.008950368797001599\n",
      "train loss:0.0001992306428483267\n",
      "train loss:0.0012949265377557155\n",
      "train loss:0.0006224974732294636\n",
      "train loss:0.002115375633657725\n",
      "train loss:0.0024359659605128277\n",
      "train loss:0.000800823400142068\n",
      "train loss:0.0004622011625756387\n",
      "train loss:0.0021612637353680825\n",
      "train loss:0.0032108573276540165\n",
      "train loss:0.01604547490197222\n",
      "train loss:0.0015167357811580722\n",
      "train loss:0.0036702325543787346\n",
      "train loss:0.006202063251889874\n",
      "train loss:0.0028681277868704536\n",
      "train loss:0.0011612087916470825\n",
      "train loss:0.004839098649973217\n",
      "train loss:0.0012319146094239535\n",
      "train loss:0.0003093990546661447\n",
      "train loss:0.00037544148235617194\n",
      "train loss:0.0010428535829091706\n",
      "train loss:0.007809126445924292\n",
      "train loss:0.00706621581542471\n",
      "train loss:0.0006664493643291892\n",
      "train loss:0.0005176768346575915\n",
      "train loss:0.0011900600642021748\n",
      "train loss:0.0006236888884995675\n",
      "train loss:0.004415330510980954\n",
      "train loss:0.0014874203642507022\n",
      "train loss:0.003548094284241428\n",
      "train loss:0.014608993212405934\n",
      "train loss:0.0006201601899357686\n",
      "train loss:0.004016246693388813\n",
      "train loss:0.0016295426585390264\n",
      "train loss:0.0007882402190883725\n",
      "train loss:0.0006241160527670888\n",
      "train loss:0.001819358747527775\n",
      "train loss:0.0009235127530653782\n",
      "train loss:0.0022424965598614086\n",
      "train loss:0.00082408861363457\n",
      "train loss:0.0014071682996055685\n",
      "train loss:0.006102024067233274\n",
      "train loss:0.011026485975221408\n",
      "train loss:0.0012124006090786419\n",
      "train loss:0.002078444913712918\n",
      "train loss:0.00047975527241553593\n",
      "train loss:0.0004988047082593209\n",
      "train loss:0.0004494647021893507\n",
      "train loss:0.000990674692791681\n",
      "train loss:0.004013579122181285\n",
      "train loss:0.0028742161601761035\n",
      "train loss:0.0005907438012877119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.001134524015502458\n",
      "train loss:0.002291897144953455\n",
      "train loss:0.0035268074689559312\n",
      "train loss:0.0009072498192765229\n",
      "train loss:0.0004954775021188527\n",
      "train loss:0.0007644142541792853\n",
      "train loss:0.0018185074732808054\n",
      "train loss:0.0008955089606494722\n",
      "train loss:0.0005526673715984004\n",
      "train loss:0.0032790740624054336\n",
      "train loss:0.0036372860442049253\n",
      "train loss:0.0027476310003162973\n",
      "train loss:0.010961434162080709\n",
      "train loss:0.0035583662235217283\n",
      "train loss:0.002532217044065124\n",
      "train loss:0.012787864671566103\n",
      "train loss:0.000944118374489003\n",
      "train loss:0.0014014043116722197\n",
      "train loss:0.0025751503258301363\n",
      "train loss:0.0011287359614816721\n",
      "train loss:0.0009643929566215085\n",
      "train loss:0.0018741285548853305\n",
      "train loss:0.0011163600408824388\n",
      "train loss:0.0008406079582879168\n",
      "train loss:0.0010352211412979304\n",
      "train loss:0.002326328584512817\n",
      "train loss:0.005358873924319207\n",
      "train loss:0.004394139925355588\n",
      "train loss:0.00035447253761746616\n",
      "train loss:0.0008267737017929725\n",
      "train loss:0.0002659930927569725\n",
      "train loss:0.000517831296140405\n",
      "train loss:0.006465008423745477\n",
      "train loss:0.006914023772586319\n",
      "train loss:0.001352604455069754\n",
      "train loss:0.003579383061788383\n",
      "train loss:0.0016644748865216955\n",
      "train loss:0.0006468295511832061\n",
      "train loss:0.0038662713894099076\n",
      "train loss:0.0011096679948169855\n",
      "train loss:0.0012629917882720852\n",
      "train loss:0.002307810561767667\n",
      "train loss:0.0020980251607773705\n",
      "train loss:0.0024985273480287794\n",
      "train loss:0.0037582641218233386\n",
      "train loss:0.002370354503581509\n",
      "train loss:0.0006748797804815189\n",
      "train loss:0.0012351563683289692\n",
      "train loss:0.0025720972772288425\n",
      "train loss:0.0019385856189371375\n",
      "train loss:0.0007310047416995137\n",
      "train loss:0.0014212832857430112\n",
      "train loss:0.00018574904938192232\n",
      "train loss:0.0002952631236781982\n",
      "train loss:0.0038858143198251373\n",
      "train loss:0.001487396309852262\n",
      "train loss:0.00019257574285845805\n",
      "train loss:0.001819489082428749\n",
      "train loss:0.011867300590516563\n",
      "train loss:0.000752840844999788\n",
      "train loss:0.002116093630511945\n",
      "train loss:0.02241739201247285\n",
      "train loss:0.00224759815509338\n",
      "train loss:0.0014449322340719748\n",
      "train loss:0.0009201823233743327\n",
      "train loss:0.0016561635268763039\n",
      "train loss:0.004454474408602968\n",
      "train loss:0.0008040933420041664\n",
      "train loss:0.0021311983782868627\n",
      "train loss:0.008909248711261775\n",
      "train loss:6.932559600840993e-05\n",
      "train loss:0.0010005644377942755\n",
      "train loss:0.001096766414849604\n",
      "train loss:0.00631323056709705\n",
      "train loss:0.0009572150337647806\n",
      "train loss:0.0019569531837421187\n",
      "train loss:0.00025662215694057184\n",
      "train loss:0.0009373969724806825\n",
      "train loss:0.0009322503417302018\n",
      "train loss:0.0020053248663138546\n",
      "train loss:0.0011989583000201521\n",
      "train loss:0.012204815205485012\n",
      "train loss:0.0037721035364631722\n",
      "train loss:0.0018080931795423818\n",
      "train loss:0.001986766242696188\n",
      "train loss:0.0018733812199284723\n",
      "train loss:0.004270398177814103\n",
      "train loss:0.0022785133784515047\n",
      "train loss:0.00047260743544015556\n",
      "train loss:0.0025204084304472135\n",
      "train loss:0.006047466694009748\n",
      "train loss:0.003979840209543372\n",
      "train loss:0.0049108542096389\n",
      "train loss:0.0028871580000161424\n",
      "train loss:0.0038927092280423483\n",
      "train loss:0.004045939765045144\n",
      "train loss:0.0023228733102682673\n",
      "train loss:0.0019407423996672104\n",
      "train loss:0.0038441430665197263\n",
      "train loss:5.362709561861114e-05\n",
      "train loss:0.0011639465671652949\n",
      "train loss:0.0010397233362686791\n",
      "train loss:0.0015721791402478979\n",
      "train loss:0.0013360291442928154\n",
      "train loss:0.0006729484845363457\n",
      "train loss:0.005574657076884548\n",
      "train loss:0.005756772048642924\n",
      "train loss:0.0029240914677476425\n",
      "train loss:0.00042237296926187493\n",
      "train loss:0.0023894387640282064\n",
      "train loss:0.003951009368491851\n",
      "train loss:0.0019055677860607134\n",
      "train loss:0.00305870633307206\n",
      "train loss:0.003516651229462857\n",
      "train loss:0.003391932024160109\n",
      "train loss:0.003916006660300082\n",
      "train loss:0.00031632607942850513\n",
      "train loss:0.0007246843216877312\n",
      "train loss:0.03144528586802672\n",
      "train loss:0.00034731887117572563\n",
      "train loss:0.0060771819835772544\n",
      "train loss:0.001357489619762485\n",
      "train loss:0.00040130865217910864\n",
      "train loss:0.010833304328229916\n",
      "train loss:0.0015621190483486875\n",
      "train loss:0.0018028819453510514\n",
      "train loss:0.0019036727917860475\n",
      "train loss:0.00026410541682766553\n",
      "train loss:0.0028379918879134565\n",
      "train loss:0.0004580374093308844\n",
      "train loss:0.005580678116203163\n",
      "train loss:0.0032630894823693973\n",
      "train loss:0.0025041785836802484\n",
      "train loss:0.009205781292171254\n",
      "train loss:0.001282057102547183\n",
      "train loss:0.021771962645545755\n",
      "train loss:0.0016024718823968475\n",
      "train loss:0.005098977932033379\n",
      "train loss:0.0012079234547599674\n",
      "train loss:0.00414384647515981\n",
      "train loss:0.009124752748066348\n",
      "train loss:0.00408785001718272\n",
      "train loss:0.0004350056802287565\n",
      "train loss:0.002000968599049391\n",
      "train loss:0.0003948037025716978\n",
      "train loss:0.008805523035383412\n",
      "train loss:0.002595676399249008\n",
      "train loss:0.0027016883408001917\n",
      "train loss:0.0036395356909360737\n",
      "train loss:0.0037652099711868426\n",
      "train loss:0.0011988081232864906\n",
      "train loss:0.00403895416470498\n",
      "train loss:0.003496289324667019\n",
      "train loss:0.0006721425897987084\n",
      "train loss:0.0009005572012468102\n",
      "train loss:0.005979618689282136\n",
      "train loss:0.0006019976917861222\n",
      "train loss:0.004306890373296932\n",
      "train loss:0.008637281892971256\n",
      "train loss:0.004937166678643879\n",
      "train loss:0.004321833441890524\n",
      "train loss:0.0005930969243652771\n",
      "train loss:0.002157172319840481\n",
      "train loss:0.0005131420197459271\n",
      "train loss:0.00331612145975359\n",
      "train loss:0.0006805671739462443\n",
      "train loss:0.0004301120175663941\n",
      "train loss:0.009351147580536684\n",
      "train loss:0.00026654409375246815\n",
      "train loss:0.0038587930075976535\n",
      "train loss:0.006148383868262335\n",
      "train loss:0.004998157981682382\n",
      "train loss:0.0032332580084066887\n",
      "train loss:0.0017446130113055389\n",
      "train loss:0.0013739412380205727\n",
      "train loss:0.0005242220074237363\n",
      "train loss:0.0006611655166630686\n",
      "train loss:0.003232818148520915\n",
      "train loss:0.0007264155001958032\n",
      "train loss:0.0049415773665581674\n",
      "train loss:0.006648007766267922\n",
      "train loss:0.00047064329009821403\n",
      "train loss:0.006891883762517867\n",
      "train loss:0.002231424012048486\n",
      "train loss:0.00033210790430830776\n",
      "train loss:0.002297640532938806\n",
      "train loss:0.002553911362134885\n",
      "train loss:0.0005158005221788353\n",
      "train loss:0.001487897723321691\n",
      "train loss:0.0038406147332078794\n",
      "train loss:0.0014275380677154276\n",
      "train loss:0.0028590313727563455\n",
      "train loss:0.0018062677986456044\n",
      "train loss:0.009583801097950394\n",
      "train loss:0.005168451900024994\n",
      "train loss:0.0034897251762516157\n",
      "train loss:0.0020813254848175613\n",
      "train loss:0.0004962741514907709\n",
      "train loss:0.001517030622321319\n",
      "train loss:0.0017537721337581751\n",
      "train loss:0.005253286948895256\n",
      "train loss:0.002716415742244256\n",
      "train loss:0.0005026992077884758\n",
      "train loss:0.002258659540660882\n",
      "train loss:0.0006188232953537736\n",
      "train loss:0.004268652592571267\n",
      "train loss:0.0009174459732190241\n",
      "train loss:0.002192502889220695\n",
      "train loss:0.005071098943787509\n",
      "train loss:0.0031555508077458737\n",
      "train loss:0.006062665222394623\n",
      "train loss:0.00207650273176479\n",
      "train loss:0.003057716061161673\n",
      "train loss:0.00273610273234828\n",
      "train loss:0.0006629547558006908\n",
      "train loss:0.0020422795268633036\n",
      "train loss:0.0009119826008530972\n",
      "train loss:0.0054048696902914105\n",
      "train loss:0.0014380086156541843\n",
      "train loss:0.00029229993791716016\n",
      "train loss:0.0001337967224558646\n",
      "train loss:0.0023954656774233824\n",
      "train loss:0.00023298974095773542\n",
      "train loss:0.00864414480907542\n",
      "train loss:0.00114400261579263\n",
      "train loss:0.023925847431193848\n",
      "train loss:0.0009483737679121881\n",
      "train loss:0.002063891111316758\n",
      "train loss:6.7298353496605e-05\n",
      "train loss:0.0014441742791359165\n",
      "train loss:0.012322232742392329\n",
      "train loss:0.005249755787988389\n",
      "train loss:0.0006725061336625963\n",
      "train loss:0.002572237468048455\n",
      "train loss:0.0043272762433933494\n",
      "train loss:0.0020504448386234435\n",
      "train loss:0.0006609791225897142\n",
      "train loss:0.007133674849911744\n",
      "train loss:0.003062065192944977\n",
      "train loss:0.0005880157185613775\n",
      "train loss:0.0029174913694427064\n",
      "train loss:0.017303451233324146\n",
      "train loss:0.0012394285269590876\n",
      "train loss:0.006665281169539191\n",
      "train loss:0.00037990748756725796\n",
      "train loss:0.0014173540268050838\n",
      "train loss:0.002701373186485893\n",
      "train loss:0.0006669067282755951\n",
      "train loss:0.0005298465759549009\n",
      "train loss:0.010913090368174722\n",
      "train loss:0.0015225250607531404\n",
      "train loss:0.002344602003977754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004722965964750528\n",
      "train loss:0.0007928921001345226\n",
      "train loss:0.005662977528473819\n",
      "train loss:0.0043769128221145285\n",
      "train loss:0.013701339634043054\n",
      "train loss:0.002247130952547245\n",
      "train loss:0.004283623580673336\n",
      "train loss:0.0044974312609531355\n",
      "train loss:0.0005191371266352071\n",
      "train loss:0.0037362263365210485\n",
      "train loss:0.0009054886598809867\n",
      "train loss:0.0008401618679772396\n",
      "train loss:9.758058008402919e-05\n",
      "train loss:0.0007489899504622446\n",
      "train loss:0.0004999130735498353\n",
      "train loss:0.0025140344812294587\n",
      "train loss:0.0005371906795032702\n",
      "train loss:0.0445698263886529\n",
      "train loss:0.0017953531423361515\n",
      "train loss:0.0027783680542557898\n",
      "train loss:0.002177212743380365\n",
      "train loss:0.0008521259749652827\n",
      "train loss:0.00033878234441552207\n",
      "train loss:0.0017398517916764095\n",
      "train loss:0.0005485436777631519\n",
      "train loss:0.009466420918183985\n",
      "train loss:0.004071296931776857\n",
      "train loss:0.0027120314212858306\n",
      "train loss:0.005310703609964171\n",
      "train loss:0.0005822941728681312\n",
      "train loss:5.6660856989153635e-05\n",
      "train loss:0.004443287310758947\n",
      "train loss:0.003442699829446654\n",
      "train loss:0.0022789789609307057\n",
      "train loss:0.0001342450801926233\n",
      "train loss:0.0006983202347640942\n",
      "train loss:0.009169140167058568\n",
      "train loss:0.0002683988795738076\n",
      "train loss:0.0006839598605172243\n",
      "train loss:0.0019681596330956342\n",
      "train loss:0.00381969736043661\n",
      "train loss:0.0020810317023036103\n",
      "train loss:0.0005308945247482641\n",
      "train loss:0.0028113124797984183\n",
      "train loss:0.0003454866411089578\n",
      "train loss:0.003692473024799052\n",
      "train loss:0.0008287639181431025\n",
      "train loss:0.004187974805999032\n",
      "train loss:0.0004342301377776505\n",
      "train loss:0.0002951061227655536\n",
      "train loss:0.002088295231185001\n",
      "train loss:0.0018689876905764848\n",
      "train loss:0.002312726055087579\n",
      "train loss:0.0015199502398898818\n",
      "train loss:0.0024729886466201677\n",
      "train loss:0.0016243632942647252\n",
      "train loss:0.006109045692735516\n",
      "train loss:0.00027874650851693263\n",
      "train loss:0.0016418920745830943\n",
      "train loss:0.0016391183911773695\n",
      "train loss:0.0018732467672485753\n",
      "train loss:0.00023037256214838268\n",
      "train loss:0.0004422089677912439\n",
      "train loss:0.047749450541601915\n",
      "train loss:0.0065627308315758205\n",
      "train loss:0.000402997689564022\n",
      "train loss:0.0032778889032145497\n",
      "train loss:0.0001571275431812967\n",
      "train loss:0.003821288675150009\n",
      "train loss:0.0024584327859067698\n",
      "train loss:0.00010852829720079639\n",
      "train loss:0.0011492900516927454\n",
      "train loss:0.00044139872654412463\n",
      "train loss:0.0003568099131332925\n",
      "train loss:0.0005697576820177022\n",
      "train loss:0.0033119883581171415\n",
      "train loss:0.0021395454400049015\n",
      "train loss:0.003442961348998881\n",
      "train loss:0.0007335510160918297\n",
      "train loss:0.0031169193024201385\n",
      "train loss:0.0014425520515367926\n",
      "train loss:0.0037775022810524767\n",
      "train loss:0.0013940287803788007\n",
      "train loss:0.002084468334200059\n",
      "train loss:0.002145008355396073\n",
      "train loss:0.005763516536978362\n",
      "train loss:0.0032215223725845584\n",
      "train loss:0.0004177177231414542\n",
      "train loss:0.009202095741483689\n",
      "train loss:0.0029006369373578028\n",
      "train loss:0.017470536301519693\n",
      "train loss:0.0005045196982436422\n",
      "train loss:0.0005682750859695505\n",
      "train loss:0.0005369714208042873\n",
      "train loss:0.0033506624346418303\n",
      "train loss:0.007926572247103879\n",
      "train loss:0.002644285915581951\n",
      "train loss:0.0014971059650644607\n",
      "train loss:0.016382273075053445\n",
      "train loss:0.024743291663967378\n",
      "train loss:0.0005810623855757612\n",
      "train loss:0.005147152830716857\n",
      "train loss:0.00042736839290190705\n",
      "train loss:0.0014984552311407577\n",
      "train loss:0.001863753249391343\n",
      "train loss:0.004450985881401166\n",
      "train loss:0.009139036103125373\n",
      "train loss:0.0112370720139631\n",
      "train loss:0.0007313922831110635\n",
      "train loss:0.000772183490102209\n",
      "train loss:0.008187745120673743\n",
      "train loss:0.004306816043022748\n",
      "train loss:0.0008924907551292159\n",
      "train loss:0.0006077368829051595\n",
      "train loss:0.0012480366003673907\n",
      "train loss:0.0022353380647802314\n",
      "train loss:0.002824048405624855\n",
      "train loss:0.00020920110144536015\n",
      "train loss:0.00860222725043595\n",
      "train loss:0.0015123956121799117\n",
      "train loss:0.0029748703371997587\n",
      "train loss:0.006353441447425041\n",
      "train loss:0.003950872433190953\n",
      "train loss:0.009721309425721013\n",
      "train loss:0.0011046969794534743\n",
      "train loss:0.0007946094578021204\n",
      "train loss:0.004360142412593618\n",
      "train loss:0.0005261250652086242\n",
      "train loss:0.056234666928435574\n",
      "train loss:0.00040194160929891504\n",
      "train loss:0.0002511395187402005\n",
      "train loss:0.007890143620581791\n",
      "train loss:0.0036809052853547302\n",
      "train loss:0.0034366670439755663\n",
      "train loss:0.0011208389454969389\n",
      "train loss:0.0025255462250290818\n",
      "train loss:0.0013955155347058022\n",
      "train loss:0.012388752041793197\n",
      "train loss:0.000584922531645784\n",
      "train loss:0.002132748020376638\n",
      "train loss:0.00066414075245398\n",
      "train loss:0.0008222761362686091\n",
      "train loss:0.0002778149981956007\n",
      "train loss:0.006060844034570866\n",
      "train loss:0.035083915275859134\n",
      "train loss:0.006379556741462968\n",
      "train loss:0.0020937036401660284\n",
      "train loss:0.04554270740421953\n",
      "train loss:0.000902730342652717\n",
      "train loss:0.0009356075039662191\n",
      "train loss:0.0010323558766244995\n",
      "train loss:0.0045945584082371805\n",
      "train loss:0.00018048246823061822\n",
      "train loss:0.0026136208636241905\n",
      "train loss:0.0032560234358294205\n",
      "train loss:0.0006513928466342162\n",
      "train loss:0.05496267790033673\n",
      "train loss:0.0002518510344102657\n",
      "train loss:0.0032776660309110426\n",
      "train loss:0.0025014375188469927\n",
      "train loss:0.0015416311191183993\n",
      "train loss:0.0004439992307494164\n",
      "train loss:0.0015822737538592993\n",
      "=== epoch:15, train acc:0.997, test acc:0.991 ===\n",
      "train loss:0.0014716518270602706\n",
      "train loss:0.0035220140684009337\n",
      "train loss:0.0008882844807728447\n",
      "train loss:0.00348036266240015\n",
      "train loss:0.008165038126069753\n",
      "train loss:0.0044931278780811846\n",
      "train loss:0.009456833078661792\n",
      "train loss:0.00029939046400495194\n",
      "train loss:0.004071244075511782\n",
      "train loss:0.006873266982743273\n",
      "train loss:0.003049311151713864\n",
      "train loss:0.009845345509003648\n",
      "train loss:0.003725227486937617\n",
      "train loss:0.004299344431592794\n",
      "train loss:0.0011644983000130699\n",
      "train loss:0.007706600685304921\n",
      "train loss:0.00048214982700983086\n",
      "train loss:0.004105217944904613\n",
      "train loss:0.0006977860842674536\n",
      "train loss:0.0023078101448816813\n",
      "train loss:0.0006586306326104457\n",
      "train loss:0.0008877988787757338\n",
      "train loss:0.0004913203703988094\n",
      "train loss:0.005434931462609981\n",
      "train loss:0.005580394010156166\n",
      "train loss:0.003942798535874004\n",
      "train loss:0.0021882256026373157\n",
      "train loss:0.004827954657052253\n",
      "train loss:0.006630610607057817\n",
      "train loss:0.0009312564202202194\n",
      "train loss:0.0013679106773827816\n",
      "train loss:0.0023330092843798144\n",
      "train loss:0.0021295500541102337\n",
      "train loss:0.0010609528666330906\n",
      "train loss:0.0003051283666043612\n",
      "train loss:0.005011567024355967\n",
      "train loss:0.0017467827143789144\n",
      "train loss:0.0005169067686056553\n",
      "train loss:0.006785764028104307\n",
      "train loss:0.0006610002668872315\n",
      "train loss:2.4123544014089296e-05\n",
      "train loss:0.0030667547875558045\n",
      "train loss:0.0006893893656773116\n",
      "train loss:0.0007867325672781083\n",
      "train loss:0.004184199757599827\n",
      "train loss:0.0002725078777890803\n",
      "train loss:0.0012529571152654394\n",
      "train loss:0.002605042042040986\n",
      "train loss:0.005365750121710093\n",
      "train loss:9.978975149355315e-05\n",
      "train loss:0.0006503780044847561\n",
      "train loss:0.0019436055127416184\n",
      "train loss:0.0031945880048692486\n",
      "train loss:0.0038401207262626622\n",
      "train loss:0.018207402290616022\n",
      "train loss:0.0017977806015983004\n",
      "train loss:0.0014173639481877194\n",
      "train loss:0.004538831271537919\n",
      "train loss:0.0007540796231406803\n",
      "train loss:0.0007874006818840794\n",
      "train loss:0.0036099126651464473\n",
      "train loss:0.00019486993211642267\n",
      "train loss:0.0004322654310638378\n",
      "train loss:0.004269392145326971\n",
      "train loss:0.0011426575779101122\n",
      "train loss:0.001642903042059736\n",
      "train loss:0.0003331760743401378\n",
      "train loss:0.013017439600650018\n",
      "train loss:0.0028855076039497065\n",
      "train loss:0.0023553595988443144\n",
      "train loss:0.0020208523111668315\n",
      "train loss:0.00027071694468612935\n",
      "train loss:0.0003711095245490939\n",
      "train loss:0.005660911841491188\n",
      "train loss:0.001740049358138342\n",
      "train loss:0.0027462410225305716\n",
      "train loss:0.0023407747665814857\n",
      "train loss:0.0009408583254533851\n",
      "train loss:0.0003386267058749945\n",
      "train loss:0.0027779865129978145\n",
      "train loss:0.002111001134050437\n",
      "train loss:0.0022521354684479074\n",
      "train loss:0.0013719565378323864\n",
      "train loss:0.005028335443306239\n",
      "train loss:0.0027163683801753736\n",
      "train loss:0.0014867100414537625\n",
      "train loss:0.0021075764190865323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0011756964400626599\n",
      "train loss:0.001987884213072047\n",
      "train loss:0.0006203973650473741\n",
      "train loss:0.0039061893351842415\n",
      "train loss:0.0028423717642286177\n",
      "train loss:0.007836718500968906\n",
      "train loss:0.0021171698849087334\n",
      "train loss:0.0004486649436333536\n",
      "train loss:6.245240721664363e-05\n",
      "train loss:0.001562849045421872\n",
      "train loss:0.004750336961425151\n",
      "train loss:0.0003417913978246693\n",
      "train loss:0.0010687541235574849\n",
      "train loss:0.00022743640987244466\n",
      "train loss:0.002026973614908029\n",
      "train loss:0.001431734774809645\n",
      "train loss:0.00215223639126425\n",
      "train loss:0.00047412107728035387\n",
      "train loss:0.00011309127654291665\n",
      "train loss:0.004345787636981623\n",
      "train loss:2.5793369608468874e-05\n",
      "train loss:0.0012438801000604748\n",
      "train loss:0.0017885128321700858\n",
      "train loss:0.0021481424268418614\n",
      "train loss:0.00771094096538449\n",
      "train loss:0.00188697544856496\n",
      "train loss:0.0012132625580339943\n",
      "train loss:0.0025401285969712307\n",
      "train loss:0.003569993318123203\n",
      "train loss:0.0006452894940356029\n",
      "train loss:0.0013818281825412866\n",
      "train loss:0.0011837526344757262\n",
      "train loss:0.00020959051876131494\n",
      "train loss:0.003304557137130419\n",
      "train loss:0.002624607542513582\n",
      "train loss:0.000599980483049816\n",
      "train loss:0.0009693579829761436\n",
      "train loss:0.0004023729640857086\n",
      "train loss:0.0032177472775718357\n",
      "train loss:8.673885775762587e-05\n",
      "train loss:0.00034612987782477097\n",
      "train loss:0.006872637367906795\n",
      "train loss:0.0020191306843992383\n",
      "train loss:0.0018205777940051608\n",
      "train loss:0.00022994784071812921\n",
      "train loss:0.0022949362900418395\n",
      "train loss:0.0007161283810845315\n",
      "train loss:0.002316893056770731\n",
      "train loss:0.003989981477770694\n",
      "train loss:9.66368480461086e-05\n",
      "train loss:0.00023124226071799832\n",
      "train loss:0.0067010346638371535\n",
      "train loss:0.0012969677749027065\n",
      "train loss:0.001386779783850301\n",
      "train loss:0.0053675232880722856\n",
      "train loss:0.001280037926636883\n",
      "train loss:0.0009955339590741396\n",
      "train loss:0.0007239546038019553\n",
      "train loss:0.0017208304326628932\n",
      "train loss:0.00011166245430889561\n",
      "train loss:0.0005316912179082113\n",
      "train loss:0.003003293979005049\n",
      "train loss:0.0013275027196978032\n",
      "train loss:0.004629037301792127\n",
      "train loss:0.0013303130557309024\n",
      "train loss:0.004260241261339987\n",
      "train loss:0.0033483977527231407\n",
      "train loss:0.0102809954479169\n",
      "train loss:0.00038904842778929695\n",
      "train loss:0.002301595197936307\n",
      "train loss:0.0010138166334394702\n",
      "train loss:0.0004622007799879922\n",
      "train loss:9.145888577898685e-05\n",
      "train loss:0.002621274764666882\n",
      "train loss:0.006979368194501645\n",
      "train loss:0.0013987762443316394\n",
      "train loss:0.0027120996897491817\n",
      "train loss:0.00023784233112283934\n",
      "train loss:0.0028504081794162245\n",
      "train loss:0.0011344070084476866\n",
      "train loss:0.0020922623879624487\n",
      "train loss:0.001685607336766467\n",
      "train loss:0.0016011255848948315\n",
      "train loss:0.001124674139099046\n",
      "train loss:0.003553805180619698\n",
      "train loss:0.0025639377860329398\n",
      "train loss:0.0001750623238150836\n",
      "train loss:0.00021059467387949768\n",
      "train loss:0.00037917233199121365\n",
      "train loss:0.0003378365716282921\n",
      "train loss:0.0027852210432236174\n",
      "train loss:0.00045628630149189636\n",
      "train loss:0.0034969744189605368\n",
      "train loss:0.001556055368873128\n",
      "train loss:0.0004240931992305996\n",
      "train loss:0.0033483039000055744\n",
      "train loss:0.00186351191694279\n",
      "train loss:0.0006821934660197426\n",
      "train loss:0.002410504981966811\n",
      "train loss:0.0014011308090266796\n",
      "train loss:0.002998886058623486\n",
      "train loss:0.003170370189450582\n",
      "train loss:0.030855508605296164\n",
      "train loss:0.023609389957151925\n",
      "train loss:0.0021325569558395614\n",
      "train loss:0.0017075355140548814\n",
      "train loss:3.877879353521032e-05\n",
      "train loss:0.0014403070402675834\n",
      "train loss:0.018749581143548046\n",
      "train loss:0.016481843253868127\n",
      "train loss:0.001862248066367582\n",
      "train loss:0.003308225787059218\n",
      "train loss:0.0017193838915620582\n",
      "train loss:0.0008958716241881203\n",
      "train loss:0.00014098910772921737\n",
      "train loss:0.002112069015911823\n",
      "train loss:0.001634217929330611\n",
      "train loss:0.00033320368850073495\n",
      "train loss:0.00034202592573053593\n",
      "train loss:0.0022491025494687797\n",
      "train loss:0.005092168998889357\n",
      "train loss:0.012005942833296234\n",
      "train loss:0.002742599040098447\n",
      "train loss:0.0005104667795294233\n",
      "train loss:0.004663333680101261\n",
      "train loss:0.004424831936284523\n",
      "train loss:0.0061466531357757094\n",
      "train loss:0.0008035043313917458\n",
      "train loss:0.0007815757093383066\n",
      "train loss:0.002851279133170077\n",
      "train loss:0.016798028541150294\n",
      "train loss:0.005522768731897569\n",
      "train loss:0.0018350854345231893\n",
      "train loss:0.0009124601063537747\n",
      "train loss:0.0004928799153414151\n",
      "train loss:0.0035151601243240517\n",
      "train loss:0.0084727761718845\n",
      "train loss:0.0016250304445895075\n",
      "train loss:0.0015599003242295348\n",
      "train loss:0.0025009775124232585\n",
      "train loss:0.0005307803377762687\n",
      "train loss:0.02550309706085864\n",
      "train loss:0.014256464776125844\n",
      "train loss:0.002250874477110846\n",
      "train loss:0.005389480610701335\n",
      "train loss:0.0026765925467563123\n",
      "train loss:0.0013393346980089293\n",
      "train loss:0.04013864324020386\n",
      "train loss:0.000674434650480414\n",
      "train loss:0.003907700645675019\n",
      "train loss:0.003157405005986513\n",
      "train loss:0.0018937034694733181\n",
      "train loss:0.0017762960687437949\n",
      "train loss:0.000992330264382333\n",
      "train loss:0.0010116339666502237\n",
      "train loss:0.0014510526874134957\n",
      "train loss:8.48984535792992e-05\n",
      "train loss:0.0003156094572165389\n",
      "train loss:0.005442850008843505\n",
      "train loss:0.02691733295492214\n",
      "train loss:0.0024545291845618454\n",
      "train loss:0.0017702601814756564\n",
      "train loss:0.00047732854658705937\n",
      "train loss:0.0020259768382748754\n",
      "train loss:0.00019578881518662094\n",
      "train loss:0.0010752820158006881\n",
      "train loss:0.0020256618953574143\n",
      "train loss:0.0003961052075067688\n",
      "train loss:0.0005836907505644937\n",
      "train loss:0.0007963008702706514\n",
      "train loss:0.005979300634870775\n",
      "train loss:0.0005436679005149395\n",
      "train loss:0.003221591421189074\n",
      "train loss:0.0004988930041741924\n",
      "train loss:0.0008755121546420773\n",
      "train loss:0.00039742038937115587\n",
      "train loss:0.0008777680520559503\n",
      "train loss:0.0003872480204845934\n",
      "train loss:0.0019192255467190603\n",
      "train loss:0.006242321164165902\n",
      "train loss:0.020852151328050305\n",
      "train loss:0.002020791376199007\n",
      "train loss:0.00015288385792247314\n",
      "train loss:0.005568400717628923\n",
      "train loss:0.0003972222131982251\n",
      "train loss:0.0054534073467332874\n",
      "train loss:0.0011823973436819524\n",
      "train loss:0.002015574755220324\n",
      "train loss:0.0022245451745459143\n",
      "train loss:0.0038129982708181814\n",
      "train loss:0.0011210785291930416\n",
      "train loss:0.002182437074864297\n",
      "train loss:0.0008587030604807319\n",
      "train loss:0.0028373400766636427\n",
      "train loss:0.008653237662240375\n",
      "train loss:0.0020537501290862005\n",
      "train loss:0.004304278498506678\n",
      "train loss:0.004185309237092955\n",
      "train loss:0.001290262252951686\n",
      "train loss:0.0005288595217709772\n",
      "train loss:0.001027079137424722\n",
      "train loss:0.00042282170940000633\n",
      "train loss:0.0010759211558839484\n",
      "train loss:0.00024205698909247797\n",
      "train loss:0.0009034225688478835\n",
      "train loss:0.05624645434755526\n",
      "train loss:0.002315775158587408\n",
      "train loss:0.012671265256365506\n",
      "train loss:0.004181299515179202\n",
      "train loss:0.0008490288440991706\n",
      "train loss:0.00027512781136665145\n",
      "train loss:0.0033971518500989745\n",
      "train loss:0.005868868471371758\n",
      "train loss:0.0009993671951181052\n",
      "train loss:0.00020707962484422612\n",
      "train loss:0.000669833774109819\n",
      "train loss:0.0014792959561446353\n",
      "train loss:0.0001362080489195089\n",
      "train loss:0.0020261496409149584\n",
      "train loss:0.0005522660204001153\n",
      "train loss:0.017807713807545388\n",
      "train loss:0.002241632535539684\n",
      "train loss:0.000602099667486729\n",
      "train loss:0.0008264909951080646\n",
      "train loss:0.010150064528432931\n",
      "train loss:0.0014892985152724773\n",
      "train loss:0.00540389250423834\n",
      "train loss:0.004124527969793433\n",
      "train loss:0.00028805144342444777\n",
      "train loss:0.0026388650511951777\n",
      "train loss:0.00327886490068966\n",
      "train loss:0.0008782269428311731\n",
      "train loss:0.0010187185778472122\n",
      "train loss:0.004858507290226217\n",
      "train loss:0.03177390819237349\n",
      "train loss:0.005066103394649395\n",
      "train loss:0.0016125671222661506\n",
      "train loss:0.0004664037509914396\n",
      "train loss:5.3327458094899456e-05\n",
      "train loss:0.0020326004709484884\n",
      "train loss:0.006018956150816341\n",
      "train loss:0.0031030980055295056\n",
      "train loss:0.0003671548183419747\n",
      "train loss:0.000611675710319311\n",
      "train loss:0.0003771005922564951\n",
      "train loss:0.0003928760376559527\n",
      "train loss:0.005147561713041901\n",
      "train loss:0.00487123013687036\n",
      "train loss:0.002726189135407392\n",
      "train loss:0.0002914212228986802\n",
      "train loss:0.003187548783073727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004930777082057153\n",
      "train loss:9.668493442812728e-05\n",
      "train loss:0.0005651262687453841\n",
      "train loss:0.00197043526060341\n",
      "train loss:0.011303316523347968\n",
      "train loss:0.00131846993339836\n",
      "train loss:0.07774353874830209\n",
      "train loss:0.0006380581192018852\n",
      "train loss:0.006514136094188987\n",
      "train loss:0.0040188596983263\n",
      "train loss:0.0011675746707615097\n",
      "train loss:0.003017784806382672\n",
      "train loss:0.0007264308797290382\n",
      "train loss:0.0016622330646285071\n",
      "train loss:0.0034955050433099866\n",
      "train loss:0.0015503661705483123\n",
      "train loss:0.0016613883748595054\n",
      "train loss:0.0030262426804053204\n",
      "train loss:0.0013154375113867463\n",
      "train loss:0.004259729110238541\n",
      "train loss:0.0027288785384346364\n",
      "train loss:0.0066814542047651795\n",
      "train loss:0.005072118753796075\n",
      "train loss:0.0002809776290326576\n",
      "train loss:0.00032277923014751073\n",
      "train loss:0.0005220151974931028\n",
      "train loss:0.002759136519283821\n",
      "train loss:0.0015562597294214479\n",
      "train loss:0.004534277512767953\n",
      "train loss:0.0006067630027829266\n",
      "train loss:0.0006532497095216507\n",
      "train loss:0.0015249965307375566\n",
      "train loss:0.0008939629278617428\n",
      "train loss:0.0021078795492474843\n",
      "train loss:0.0002150327966399277\n",
      "train loss:0.0015684241824618914\n",
      "train loss:0.006794315406538567\n",
      "train loss:0.00022965031497653717\n",
      "train loss:0.00029244492979500574\n",
      "train loss:0.004867109274226929\n",
      "train loss:0.0015140212609188798\n",
      "train loss:0.00023164077263373078\n",
      "train loss:0.002178284983354225\n",
      "train loss:0.00043278546606715247\n",
      "train loss:0.00787092712707192\n",
      "train loss:0.00535629360623269\n",
      "train loss:0.0028358067540314703\n",
      "train loss:0.0018034855403098033\n",
      "train loss:0.007601606185478974\n",
      "train loss:0.00244834492998787\n",
      "train loss:0.04379195829126825\n",
      "train loss:0.005273874130108333\n",
      "train loss:0.0013057258739228843\n",
      "train loss:0.003941312695496162\n",
      "train loss:0.0005252780000571839\n",
      "train loss:0.002032741473459242\n",
      "train loss:0.00136818680255466\n",
      "train loss:0.0029253955955471284\n",
      "train loss:0.0002138650693370454\n",
      "train loss:0.00105721251002608\n",
      "train loss:0.0035538818500328736\n",
      "train loss:0.017781156187736503\n",
      "train loss:0.002246636553344708\n",
      "train loss:0.013708415939388796\n",
      "train loss:0.014221287929821984\n",
      "train loss:0.0015491812444425352\n",
      "train loss:0.0005576500820423116\n",
      "train loss:0.0005411700178759348\n",
      "train loss:0.0004991567539204644\n",
      "train loss:0.00028227885367147537\n",
      "train loss:0.004177813274864769\n",
      "train loss:0.003436594180947006\n",
      "train loss:0.0017112632980811043\n",
      "train loss:0.0006869385275423835\n",
      "train loss:0.003377443701481401\n",
      "train loss:0.001423090271671551\n",
      "train loss:0.0020942632105432632\n",
      "train loss:0.011556173334632658\n",
      "train loss:0.001059261321499552\n",
      "train loss:0.00045519234824806167\n",
      "train loss:0.0019286844808957173\n",
      "train loss:0.0007198380855523284\n",
      "train loss:0.015364456773114956\n",
      "train loss:0.015636184940919482\n",
      "train loss:0.006702565826548313\n",
      "train loss:0.0008577716559811863\n",
      "train loss:0.00027690249057960324\n",
      "train loss:0.002161820371143162\n",
      "train loss:0.0004899064168325313\n",
      "train loss:0.001827641767000423\n",
      "train loss:0.0043695416775439986\n",
      "train loss:0.0013024679109475325\n",
      "train loss:0.0004842582946373067\n",
      "train loss:0.00034446394009982143\n",
      "train loss:0.0009302229421925787\n",
      "train loss:0.0016781801186790913\n",
      "train loss:0.003419459803225799\n",
      "train loss:0.008963059934623055\n",
      "train loss:0.005665044776863658\n",
      "train loss:0.00219472692342899\n",
      "train loss:0.00772342258260099\n",
      "train loss:0.0017988846770700274\n",
      "train loss:0.0002540644377695033\n",
      "train loss:0.00442303135259366\n",
      "train loss:0.00819747170321472\n",
      "train loss:0.005510607121624184\n",
      "train loss:0.003022756124139191\n",
      "train loss:0.010594900767459638\n",
      "train loss:0.0013455766702612623\n",
      "train loss:0.006955680098459266\n",
      "train loss:0.0040622786957026395\n",
      "train loss:0.0019708425550632918\n",
      "train loss:0.0017681010620595027\n",
      "train loss:0.008941016292061456\n",
      "train loss:0.001244593858511152\n",
      "train loss:0.002187384855215676\n",
      "train loss:0.016494670806725863\n",
      "train loss:0.0006738847313543741\n",
      "train loss:0.02593986074708745\n",
      "train loss:0.010569696544640328\n",
      "train loss:0.0049860934758067885\n",
      "train loss:0.00112120534261212\n",
      "train loss:0.0025917885934569917\n",
      "train loss:0.0014542847254991015\n",
      "train loss:0.0020868612913973023\n",
      "train loss:0.011032892619951183\n",
      "train loss:0.008253465883333054\n",
      "train loss:0.010000821209157235\n",
      "train loss:0.003207747603970348\n",
      "train loss:0.002679427414476051\n",
      "train loss:0.010347386770520908\n",
      "train loss:0.034607465617414145\n",
      "train loss:0.0010429544537413449\n",
      "train loss:0.00412040883023114\n",
      "train loss:0.008806259100170286\n",
      "train loss:0.0033873890713937366\n",
      "train loss:0.024981263309975944\n",
      "train loss:0.005725922241467554\n",
      "train loss:0.0012870886414704558\n",
      "train loss:0.0028591797337898157\n",
      "train loss:0.0030231825485751355\n",
      "train loss:0.0007169127748870119\n",
      "train loss:0.005464509000284299\n",
      "train loss:0.0013306605387314971\n",
      "train loss:0.0022171998438526184\n",
      "train loss:0.014412959078690986\n",
      "train loss:0.003861812462867165\n",
      "train loss:0.004846290521314938\n",
      "train loss:0.007019248022167722\n",
      "train loss:0.0003332375280839056\n",
      "train loss:0.0017438372742515818\n",
      "train loss:0.0020446805718285516\n",
      "train loss:0.004118691325986398\n",
      "train loss:0.002247950534282632\n",
      "train loss:0.007228077516159935\n",
      "train loss:0.0015648757036983458\n",
      "train loss:0.0015146249435766374\n",
      "train loss:0.003642000661647957\n",
      "train loss:0.0009906846108254934\n",
      "train loss:0.0020025653452017053\n",
      "train loss:0.0014278945982231328\n",
      "train loss:0.0020303819138771297\n",
      "train loss:0.005927389508290669\n",
      "train loss:0.010058299079101425\n",
      "train loss:0.006724598673391245\n",
      "train loss:0.003832175352454723\n",
      "train loss:0.00029929239173441476\n",
      "train loss:0.0020490900334121484\n",
      "train loss:0.0018190529552906593\n",
      "train loss:0.0006965819804783891\n",
      "train loss:0.00029898963854710055\n",
      "train loss:0.003892476467336786\n",
      "train loss:0.0005332783357348997\n",
      "train loss:0.00010635716178781994\n",
      "train loss:0.0012794735683342203\n",
      "train loss:0.0008260805974823242\n",
      "train loss:9.600570193999704e-05\n",
      "train loss:0.004024394053545941\n",
      "train loss:0.003022120360190922\n",
      "train loss:0.00026456025394555556\n",
      "train loss:0.0013350109499578131\n",
      "train loss:0.0005853713733033578\n",
      "train loss:0.0013507766188037365\n",
      "train loss:0.0030459813542070753\n",
      "train loss:0.0002853816540797502\n",
      "train loss:0.0032925766305897924\n",
      "train loss:0.0004821966990570127\n",
      "train loss:0.001200812657007296\n",
      "train loss:0.003966569463505167\n",
      "train loss:0.001299705019427765\n",
      "train loss:0.0026218545495729183\n",
      "train loss:0.0025806588729517283\n",
      "train loss:0.00017434087617775385\n",
      "train loss:0.00018159298729245269\n",
      "train loss:0.002249093388922192\n",
      "train loss:0.014838751955444662\n",
      "train loss:0.000710197387559728\n",
      "train loss:0.0002413769691084233\n",
      "train loss:0.00032962685941086573\n",
      "train loss:0.010386714331276829\n",
      "train loss:0.00012311553375863525\n",
      "train loss:0.018752664648587124\n",
      "train loss:0.00399518829835942\n",
      "train loss:0.005184012198100889\n",
      "train loss:0.00451334886701615\n",
      "train loss:0.0033857904655217857\n",
      "train loss:0.006506338265252371\n",
      "train loss:0.0046599004179762185\n",
      "train loss:0.009853514682167558\n",
      "train loss:0.006830496625445374\n",
      "train loss:0.0035239668254754596\n",
      "train loss:0.0008669322048798434\n",
      "train loss:0.0014102537640023236\n",
      "train loss:0.0012747671517415906\n",
      "train loss:0.00037709805519529227\n",
      "train loss:0.0009836589139621237\n",
      "train loss:0.021147376298485766\n",
      "train loss:0.0016902045580365226\n",
      "train loss:0.0007147326288758087\n",
      "train loss:0.00034236064904076205\n",
      "train loss:0.0046369826460554925\n",
      "train loss:0.00015981427785628742\n",
      "train loss:0.009834737518584854\n",
      "train loss:0.0001613792091885469\n",
      "train loss:0.0003819249361969037\n",
      "train loss:0.002300488299920648\n",
      "train loss:0.001399654312005469\n",
      "train loss:0.0032489263274135516\n",
      "train loss:0.0015121355835251862\n",
      "train loss:0.004884112607814018\n",
      "train loss:0.001321979826436566\n",
      "train loss:0.0006923225457620399\n",
      "train loss:0.0027703449065247998\n",
      "train loss:0.002733567488190239\n",
      "train loss:0.003759156376748634\n",
      "train loss:0.002224697228090381\n",
      "train loss:0.00026749467270190905\n",
      "train loss:0.005118934518378494\n",
      "train loss:0.0015262014087742135\n",
      "train loss:0.0002235782640912902\n",
      "train loss:0.006775491940046795\n",
      "train loss:7.532776056776028e-05\n",
      "train loss:0.0016820375354933217\n",
      "train loss:0.000645206093733106\n",
      "train loss:0.002701672121671\n",
      "train loss:0.0014868546744413187\n",
      "train loss:0.015573340299531358\n",
      "train loss:0.0017879377549553969\n",
      "train loss:0.0014307494117757594\n",
      "train loss:0.0006025072863566441\n",
      "train loss:0.0031139355546662274\n",
      "train loss:0.008855427226507505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0022867364211350562\n",
      "train loss:0.000932442481882471\n",
      "train loss:0.00794182621509622\n",
      "train loss:0.0003838497204815921\n",
      "train loss:0.003603618141354984\n",
      "train loss:0.0010924040404279424\n",
      "train loss:0.0012229889265529073\n",
      "train loss:0.014415033252391473\n",
      "train loss:0.0011282035950626232\n",
      "train loss:0.0017655026762659475\n",
      "=== epoch:16, train acc:0.995, test acc:0.99 ===\n",
      "train loss:0.00038604946135162944\n",
      "train loss:0.001500492210800301\n",
      "train loss:0.0007497370424024568\n",
      "train loss:0.005008664726099535\n",
      "train loss:0.005245908576946214\n",
      "train loss:0.0005746352968873231\n",
      "train loss:0.0082989422618027\n",
      "train loss:0.0025642373802706162\n",
      "train loss:0.0005634616956405611\n",
      "train loss:0.0027772705280821107\n",
      "train loss:0.0005502420789256995\n",
      "train loss:0.004072982073830538\n",
      "train loss:0.0016455868663003959\n",
      "train loss:0.001408955030979169\n",
      "train loss:0.0020991043378235947\n",
      "train loss:0.00014005644791301514\n",
      "train loss:0.001334682988795761\n",
      "train loss:0.004278340014039983\n",
      "train loss:0.005008295863876292\n",
      "train loss:0.015550383604403717\n",
      "train loss:0.003406233666294881\n",
      "train loss:0.001102158290294601\n",
      "train loss:0.0006898199604675391\n",
      "train loss:0.0012780995196275216\n",
      "train loss:0.0015750759653931246\n",
      "train loss:0.0051227086334658545\n",
      "train loss:0.0030950212369282378\n",
      "train loss:0.0005339293036087021\n",
      "train loss:0.0010170078689994448\n",
      "train loss:0.00036584518614013245\n",
      "train loss:0.002027136435356937\n",
      "train loss:0.0006133582616069451\n",
      "train loss:0.0018658656832597994\n",
      "train loss:0.001967553305231487\n",
      "train loss:0.0006131062501980904\n",
      "train loss:0.0002720170698028247\n",
      "train loss:0.0018821637352773707\n",
      "train loss:0.009000107545923168\n",
      "train loss:0.0014993407386053761\n",
      "train loss:0.00666415083767446\n",
      "train loss:0.0004659324257800529\n",
      "train loss:0.0025638305803848457\n",
      "train loss:0.00030712136344396035\n",
      "train loss:0.041261560377188006\n",
      "train loss:0.0013634086247772612\n",
      "train loss:0.0015887804254194793\n",
      "train loss:0.007494121398840397\n",
      "train loss:0.0036180417187647363\n",
      "train loss:0.0005350010268699714\n",
      "train loss:0.032627743599745525\n",
      "train loss:0.000522361016947072\n",
      "train loss:0.0026490964907944737\n",
      "train loss:0.0007996154881649621\n",
      "train loss:0.0010815827617811273\n",
      "train loss:0.00029681416846819253\n",
      "train loss:0.0008153927722570854\n",
      "train loss:0.00022983510268035235\n",
      "train loss:0.0006739013870806457\n",
      "train loss:0.0005079193035164422\n",
      "train loss:0.0025094810841110745\n",
      "train loss:0.0007551165474479471\n",
      "train loss:0.002648535690177694\n",
      "train loss:0.0017236154677857244\n",
      "train loss:0.005198238028460724\n",
      "train loss:0.0026516070976404117\n",
      "train loss:0.0014987907667635126\n",
      "train loss:0.0004045512518588378\n",
      "train loss:0.0007089918036018408\n",
      "train loss:0.001258362507128275\n",
      "train loss:0.0002877836225448953\n",
      "train loss:0.0008327056886466406\n",
      "train loss:0.000537704290369561\n",
      "train loss:0.0044152073150637745\n",
      "train loss:0.001318885938263496\n",
      "train loss:0.0033920102841778254\n",
      "train loss:0.0007080891740406713\n",
      "train loss:0.0030042815145712343\n",
      "train loss:0.011963714609816519\n",
      "train loss:0.0019735738943405558\n",
      "train loss:0.003487606439908501\n",
      "train loss:0.00043855847181574557\n",
      "train loss:0.0009561764575300765\n",
      "train loss:0.001965584430066196\n",
      "train loss:0.00041437666732857493\n",
      "train loss:0.0006351255209844221\n",
      "train loss:0.0017010875556448645\n",
      "train loss:0.0015132396655891905\n",
      "train loss:0.0011126946034692596\n",
      "train loss:0.0014061021412734435\n",
      "train loss:0.0015487681856304525\n",
      "train loss:0.0003657977890003086\n",
      "train loss:0.00996164003389735\n",
      "train loss:0.0026340837802906504\n",
      "train loss:0.003151160030927923\n",
      "train loss:0.0014949697435797788\n",
      "train loss:0.0013318352442574088\n",
      "train loss:0.0031948219294477298\n",
      "train loss:0.0015182027689529722\n",
      "train loss:0.0017840385840459435\n",
      "train loss:0.08731247196261792\n",
      "train loss:0.00032934251545229846\n",
      "train loss:0.0008831996622100395\n",
      "train loss:0.0004736637861533922\n",
      "train loss:0.0023191301039166452\n",
      "train loss:0.0044450386614403505\n",
      "train loss:0.0004977772206211103\n",
      "train loss:0.0010255449274648447\n",
      "train loss:0.0011520169483343202\n",
      "train loss:7.092715651906466e-05\n",
      "train loss:0.0028053064714428154\n",
      "train loss:0.0015424441425470853\n",
      "train loss:0.0020942268094367718\n",
      "train loss:0.0002518924635333468\n",
      "train loss:0.0011787051864724923\n",
      "train loss:0.0009742051630851695\n",
      "train loss:0.0007132198847734692\n",
      "train loss:0.0009498817599856048\n",
      "train loss:0.0014281520306208687\n",
      "train loss:0.007839152814477364\n",
      "train loss:0.0019336951571384201\n",
      "train loss:0.0004453972039952295\n",
      "train loss:0.002044296464453495\n",
      "train loss:9.004718134237207e-05\n",
      "train loss:0.0003090395702833013\n",
      "train loss:0.00039861940590284694\n",
      "train loss:0.00013706709740805056\n",
      "train loss:0.0050709046162436145\n",
      "train loss:0.0011796166076652318\n",
      "train loss:0.0013561832948506883\n",
      "train loss:0.004988214723978491\n",
      "train loss:0.004818068567108305\n",
      "train loss:0.0005546245698660196\n",
      "train loss:0.00032072704764530115\n",
      "train loss:0.002422982919272435\n",
      "train loss:0.0012981631861540017\n",
      "train loss:0.000593264218834544\n",
      "train loss:0.0005279659905082901\n",
      "train loss:0.0003678451801474243\n",
      "train loss:0.00023644687385449998\n",
      "train loss:0.0006916223203656318\n",
      "train loss:0.0007655956885768245\n",
      "train loss:0.0010920295966226087\n",
      "train loss:0.0020341955335379867\n",
      "train loss:0.0013185658347695723\n",
      "train loss:0.008239312790226293\n",
      "train loss:0.0009272332942375319\n",
      "train loss:0.0001828349797402459\n",
      "train loss:0.0018103276540128504\n",
      "train loss:0.00033383949230218204\n",
      "train loss:0.005596701122128155\n",
      "train loss:0.0020183501624712386\n",
      "train loss:0.012983814354296942\n",
      "train loss:0.0005697253656121757\n",
      "train loss:0.00724134359427946\n",
      "train loss:0.002157609552714905\n",
      "train loss:0.0006721623210888044\n",
      "train loss:0.0008487909068194152\n",
      "train loss:0.00025516045300240825\n",
      "train loss:0.000580751273306256\n",
      "train loss:0.002080573247003081\n",
      "train loss:0.0010772457996921104\n",
      "train loss:0.0010102824475679108\n",
      "train loss:0.004559498093665121\n",
      "train loss:0.0022928359369644245\n",
      "train loss:0.0116441065526957\n",
      "train loss:0.0011896054984278696\n",
      "train loss:0.0005912058861619473\n",
      "train loss:0.0035689748412305283\n",
      "train loss:0.0005027901251763098\n",
      "train loss:0.00044076499304183806\n",
      "train loss:0.0008275314324050894\n",
      "train loss:0.00041615620865420653\n",
      "train loss:0.0013114866757350898\n",
      "train loss:0.0019796187747492034\n",
      "train loss:0.00017836119779620523\n",
      "train loss:0.00017786204371393602\n",
      "train loss:0.0013276730524594876\n",
      "train loss:0.0007865893026321583\n",
      "train loss:0.008701026490772415\n",
      "train loss:0.014152307610999403\n",
      "train loss:0.0022246711904177203\n",
      "train loss:0.001970532118676944\n",
      "train loss:0.004256880362250148\n",
      "train loss:0.00022613715313852186\n",
      "train loss:0.00032329081208826534\n",
      "train loss:0.0023657381453083466\n",
      "train loss:0.003576549400009425\n",
      "train loss:0.0011747238147846453\n",
      "train loss:0.00042644634815980776\n",
      "train loss:0.0005853622488711999\n",
      "train loss:0.003358744420219432\n",
      "train loss:0.0007456916514757358\n",
      "train loss:0.00023337085526818984\n",
      "train loss:0.0017494664808539668\n",
      "train loss:0.0006788677767608417\n",
      "train loss:0.0012258758229571002\n",
      "train loss:0.0016340316980201924\n",
      "train loss:0.019768081738817854\n",
      "train loss:0.00027239031551765195\n",
      "train loss:0.0007123306421803803\n",
      "train loss:0.0009223724498999149\n",
      "train loss:0.0002342080457978933\n",
      "train loss:0.0008907723852990907\n",
      "train loss:0.0027677836266272716\n",
      "train loss:0.001521446576284943\n",
      "train loss:0.000402386774453741\n",
      "train loss:0.00015831940325439008\n",
      "train loss:0.00048424860992692754\n",
      "train loss:0.0007441939899048696\n",
      "train loss:0.0017320102015927516\n",
      "train loss:0.0008111102532614127\n",
      "train loss:0.00044333742594459137\n",
      "train loss:0.001084901784005473\n",
      "train loss:0.0005152553812483479\n",
      "train loss:8.2013213127114e-05\n",
      "train loss:0.00047719049430655874\n",
      "train loss:0.0015089590765097552\n",
      "train loss:0.002692780051027502\n",
      "train loss:0.0016186720425936032\n",
      "train loss:0.00031560040261068603\n",
      "train loss:0.00018980685468545936\n",
      "train loss:0.00027940193330385816\n",
      "train loss:0.03299014052484229\n",
      "train loss:0.0004125462302598546\n",
      "train loss:0.0013034296081472308\n",
      "train loss:0.000466948997017215\n",
      "train loss:9.979259633420735e-05\n",
      "train loss:0.00028961045746452735\n",
      "train loss:0.0008245347667998946\n",
      "train loss:0.001419138046945982\n",
      "train loss:0.0014178160966461673\n",
      "train loss:0.0016881852826857247\n",
      "train loss:0.00024662270025741336\n",
      "train loss:0.0011668742762111042\n",
      "train loss:0.0006291955832025292\n",
      "train loss:0.0013147515583189003\n",
      "train loss:0.0026542123443774102\n",
      "train loss:0.0008839770244492749\n",
      "train loss:0.007482988711388818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00011668172379951353\n",
      "train loss:0.0009354540264065363\n",
      "train loss:0.00027565748349579186\n",
      "train loss:0.00013228400324628628\n",
      "train loss:0.00012146796342626193\n",
      "train loss:0.0024451283756299776\n",
      "train loss:0.00046364114522111095\n",
      "train loss:0.0005554555342363974\n",
      "train loss:0.0004851260614987523\n",
      "train loss:0.0007858827047862355\n",
      "train loss:0.003159883509165256\n",
      "train loss:0.0005141819290341931\n",
      "train loss:0.0001345181712747792\n",
      "train loss:0.009983486606311933\n",
      "train loss:0.000957038240569141\n",
      "train loss:8.709633605514182e-05\n",
      "train loss:0.0020719590775254548\n",
      "train loss:0.0028602119773257916\n",
      "train loss:0.00040986502031847\n",
      "train loss:0.0029906920565415606\n",
      "train loss:0.002051421266997059\n",
      "train loss:0.0031257500079900817\n",
      "train loss:0.0005278547078115699\n",
      "train loss:0.008005276743114688\n",
      "train loss:0.0006545007207822942\n",
      "train loss:0.0009409677734657409\n",
      "train loss:0.0024905009184609554\n",
      "train loss:0.007049239184814865\n",
      "train loss:0.0037116858781581935\n",
      "train loss:0.0006371920983801867\n",
      "train loss:0.00030687016262540375\n",
      "train loss:0.003181248072736172\n",
      "train loss:0.0022327882490957994\n",
      "train loss:0.0004247411617383314\n",
      "train loss:0.0012962559728558474\n",
      "train loss:0.0021095374545528674\n",
      "train loss:0.001929613746933625\n",
      "train loss:0.001224283973349194\n",
      "train loss:0.002375486651215822\n",
      "train loss:0.0008627516710339036\n",
      "train loss:0.00029344321844396935\n",
      "train loss:0.0014626225105825192\n",
      "train loss:0.0006028817380984372\n",
      "train loss:6.736440720075653e-05\n",
      "train loss:0.004791879404485927\n",
      "train loss:0.0006076178437187077\n",
      "train loss:0.0006921429894004343\n",
      "train loss:0.0011835500654633043\n",
      "train loss:0.0065186146584328645\n",
      "train loss:0.00038063279518062284\n",
      "train loss:0.001196079608092871\n",
      "train loss:0.005870029213398018\n",
      "train loss:0.009072487547202216\n",
      "train loss:0.0012140357433084762\n",
      "train loss:3.9356018058897945e-05\n",
      "train loss:0.005426157243475044\n",
      "train loss:0.000793981637989142\n",
      "train loss:0.009547540106641295\n",
      "train loss:0.008255953806151066\n",
      "train loss:0.00017696977274428226\n",
      "train loss:0.0004304096326627071\n",
      "train loss:0.0010460647792315235\n",
      "train loss:0.009333866678238361\n",
      "train loss:0.0005664599849004322\n",
      "train loss:0.0019992276433116684\n",
      "train loss:0.0002778688455297865\n",
      "train loss:0.00015426031640579512\n",
      "train loss:0.0017400562660841413\n",
      "train loss:0.004979923139544985\n",
      "train loss:0.001191451082019682\n",
      "train loss:0.005268188224441692\n",
      "train loss:0.005597295307530326\n",
      "train loss:0.0001810811695404356\n",
      "train loss:0.0007448018971050617\n",
      "train loss:0.004018805649506994\n",
      "train loss:0.0025065400618717853\n",
      "train loss:0.00047896453177690784\n",
      "train loss:0.0022581295817520565\n",
      "train loss:0.0029958982376502813\n",
      "train loss:0.004181221808825323\n",
      "train loss:0.002104939285766308\n",
      "train loss:0.005268927639204587\n",
      "train loss:0.002852335094371817\n",
      "train loss:0.0032905589141224724\n",
      "train loss:0.01048935740214873\n",
      "train loss:0.002028441957775752\n",
      "train loss:0.005790803069482208\n",
      "train loss:0.0008446094124615314\n",
      "train loss:0.00031930989639641374\n",
      "train loss:0.001607561851891595\n",
      "train loss:0.0007865400083389923\n",
      "train loss:0.0012819310410279719\n",
      "train loss:0.0003367130261031833\n",
      "train loss:0.029221452799811885\n",
      "train loss:0.00037093424203489095\n",
      "train loss:0.001408147410672122\n",
      "train loss:0.002094631186665018\n",
      "train loss:0.005271840012265965\n",
      "train loss:0.0004515149471642444\n",
      "train loss:0.011475833987260549\n",
      "train loss:0.0012957731887727204\n",
      "train loss:0.0042012434413223375\n",
      "train loss:0.00453167685600919\n",
      "train loss:0.0035668196711000594\n",
      "train loss:0.0003408475675876468\n",
      "train loss:0.00043282101965007704\n",
      "train loss:0.0004464249074143362\n",
      "train loss:0.011732788630216423\n",
      "train loss:0.0045657007125427885\n",
      "train loss:0.007395943077787083\n",
      "train loss:0.00020204458428311169\n",
      "train loss:0.0007915462587046886\n",
      "train loss:0.0006538113060290873\n",
      "train loss:0.004186858827060725\n",
      "train loss:0.0010164621757530435\n",
      "train loss:0.0014723082162871352\n",
      "train loss:0.0015697326794760344\n",
      "train loss:0.0012896078233509203\n",
      "train loss:0.0005011861095650182\n",
      "train loss:0.0017522483817887199\n",
      "train loss:0.0030436929261122942\n",
      "train loss:0.00010148836358862365\n",
      "train loss:0.027734953247520067\n",
      "train loss:0.0022426762187071165\n",
      "train loss:0.0007105260104941769\n",
      "train loss:0.002108817307328706\n",
      "train loss:0.0011584439374444006\n",
      "train loss:0.008636203805534296\n",
      "train loss:0.0034214058469255603\n",
      "train loss:0.0018204032496108291\n",
      "train loss:0.000622070366528809\n",
      "train loss:0.003752836053626163\n",
      "train loss:0.0015479048389675845\n",
      "train loss:0.006150583370184288\n",
      "train loss:0.0020251329666425427\n",
      "train loss:0.008581499960815907\n",
      "train loss:0.0008838134210832606\n",
      "train loss:0.003314241771891019\n",
      "train loss:0.0008588538916659988\n",
      "train loss:0.028404178547066786\n",
      "train loss:0.00018244244332113024\n",
      "train loss:0.002593170782932263\n",
      "train loss:0.0024858347250528807\n",
      "train loss:0.0004813329687583319\n",
      "train loss:0.00034183109772880824\n",
      "train loss:0.002911076577013872\n",
      "train loss:0.0173054103364141\n",
      "train loss:0.00031538699924315184\n",
      "train loss:0.0005016935957736404\n",
      "train loss:0.0016266544992529924\n",
      "train loss:0.005814832449400133\n",
      "train loss:0.0009367995443087622\n",
      "train loss:0.001898584057547296\n",
      "train loss:0.0011303863274710099\n",
      "train loss:0.0005574613169790855\n",
      "train loss:0.0009909456198872462\n",
      "train loss:0.0010105581582365067\n",
      "train loss:0.0015146290245183353\n",
      "train loss:0.005542851914804243\n",
      "train loss:0.0005114574938832481\n",
      "train loss:0.012279306287962614\n",
      "train loss:0.0006101657710800363\n",
      "train loss:0.005069291268557078\n",
      "train loss:0.002977213236404859\n",
      "train loss:0.01987755329676251\n",
      "train loss:0.00045018696595996776\n",
      "train loss:0.00036517745256507206\n",
      "train loss:0.0037296776992305665\n",
      "train loss:0.011312546292219634\n",
      "train loss:0.0005283217641469131\n",
      "train loss:0.001980357745242089\n",
      "train loss:0.004454077635282664\n",
      "train loss:0.002367809379275078\n",
      "train loss:0.0008348094680704799\n",
      "train loss:0.0004118651019073857\n",
      "train loss:0.0006891730196346835\n",
      "train loss:0.0007401646589942843\n",
      "train loss:0.0015511207832876316\n",
      "train loss:0.000822150365777813\n",
      "train loss:0.0005365554161136511\n",
      "train loss:0.0036709684856647906\n",
      "train loss:0.0018866063803675073\n",
      "train loss:0.00975480156275355\n",
      "train loss:0.0009699418166164925\n",
      "train loss:0.001326376373132216\n",
      "train loss:0.0023683445103942547\n",
      "train loss:0.0003697566689321275\n",
      "train loss:0.00247916329008111\n",
      "train loss:0.003735794608231906\n",
      "train loss:0.0007325877059296025\n",
      "train loss:0.007476729385822541\n",
      "train loss:0.0005690013642591235\n",
      "train loss:0.029950293915384275\n",
      "train loss:0.0007696664605992058\n",
      "train loss:0.0191974090915016\n",
      "train loss:0.009468072720217718\n",
      "train loss:0.00035271433371162356\n",
      "train loss:0.0003886948173176054\n",
      "train loss:0.00054863519938048\n",
      "train loss:0.0003063975407440982\n",
      "train loss:0.0033377648046893243\n",
      "train loss:0.00041040613387577195\n",
      "train loss:0.0002391939146197121\n",
      "train loss:0.00016091511645590452\n",
      "train loss:0.0038174411250435107\n",
      "train loss:6.182928389661349e-05\n",
      "train loss:0.00032607059867881304\n",
      "train loss:0.006812422878360995\n",
      "train loss:0.003980735589607986\n",
      "train loss:5.183845165717261e-05\n",
      "train loss:0.0023065209335697413\n",
      "train loss:0.0026327410219539995\n",
      "train loss:0.00046069330641429354\n",
      "train loss:0.005698870749107775\n",
      "train loss:0.0016434946260836785\n",
      "train loss:0.002690819714009944\n",
      "train loss:0.009672654050816727\n",
      "train loss:0.006831075807054114\n",
      "train loss:0.0007841486103607583\n",
      "train loss:0.0033539974796597434\n",
      "train loss:0.00042762091374344986\n",
      "train loss:0.0017583495508972974\n",
      "train loss:0.0012540233334756231\n",
      "train loss:0.0012151213219820842\n",
      "train loss:0.0009822320988373972\n",
      "train loss:0.0023571430884790088\n",
      "train loss:0.01197963814342298\n",
      "train loss:0.001731874578790629\n",
      "train loss:0.003684377324978998\n",
      "train loss:0.002962762090605902\n",
      "train loss:0.0013978717961091428\n",
      "train loss:0.0053097621359758426\n",
      "train loss:0.00045235335876749196\n",
      "train loss:0.0006886274873438196\n",
      "train loss:0.006972683873793636\n",
      "train loss:0.002937136608381422\n",
      "train loss:0.0005423047453637759\n",
      "train loss:0.004976891932800427\n",
      "train loss:0.005720511056559554\n",
      "train loss:0.0012158918342026544\n",
      "train loss:0.0005401623902480508\n",
      "train loss:0.00015952948345149615\n",
      "train loss:0.0023534452715079147\n",
      "train loss:0.0009731730675762712\n",
      "train loss:0.0003133201874891225\n",
      "train loss:0.0022250919651325366\n",
      "train loss:0.007484568009285102\n",
      "train loss:0.002448052833232234\n",
      "train loss:0.001853048463632906\n",
      "train loss:0.002087204116580211\n",
      "train loss:0.0025501603147266216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004974557462689644\n",
      "train loss:0.00013643388278980096\n",
      "train loss:0.0019684767057790383\n",
      "train loss:0.004211160677441357\n",
      "train loss:0.0017438373336010557\n",
      "train loss:0.0006873893527975334\n",
      "train loss:0.0005425388204638114\n",
      "train loss:0.00011260591996356417\n",
      "train loss:0.0005874505461127126\n",
      "train loss:0.00034030413726087637\n",
      "train loss:0.0024393332502331303\n",
      "train loss:0.00029644113253984747\n",
      "train loss:0.0013239291795760716\n",
      "train loss:0.0033012270453590103\n",
      "train loss:0.002679749337607348\n",
      "train loss:0.048150736261347825\n",
      "train loss:0.0005647714892578163\n",
      "train loss:0.0024189489855241135\n",
      "train loss:0.002902956850883662\n",
      "train loss:0.0005885380133169811\n",
      "train loss:0.0007760790520094715\n",
      "train loss:0.0026576204415215228\n",
      "train loss:0.0020928578967098917\n",
      "train loss:0.004552199988026042\n",
      "train loss:7.972271183183486e-05\n",
      "train loss:0.002076023138988171\n",
      "train loss:0.0005312367622104712\n",
      "train loss:0.0017930768555013679\n",
      "train loss:0.0006662632880669828\n",
      "train loss:0.0028080675192911414\n",
      "train loss:0.004134498590011072\n",
      "train loss:0.0002762251029481101\n",
      "train loss:0.001480980202342355\n",
      "train loss:0.0020803154780895147\n",
      "train loss:0.001499377389011933\n",
      "train loss:0.002761207032177663\n",
      "train loss:0.0010899879773616573\n",
      "train loss:0.000668865664317268\n",
      "train loss:0.0002785960725914143\n",
      "train loss:0.0016340366663497553\n",
      "train loss:0.00016236161688806952\n",
      "train loss:0.005794647196708207\n",
      "train loss:0.003716922830557333\n",
      "train loss:0.00014593104730638615\n",
      "train loss:0.017613952065462582\n",
      "train loss:0.002909522684419382\n",
      "train loss:0.0031512695397078547\n",
      "train loss:0.005371339020918608\n",
      "train loss:0.003801289389177822\n",
      "train loss:0.00037442610797707153\n",
      "train loss:0.006559363897797519\n",
      "train loss:0.0010884429615875308\n",
      "train loss:0.0007596418244708101\n",
      "train loss:0.00015137381214832063\n",
      "train loss:0.0028516325689815466\n",
      "train loss:0.019491716196138126\n",
      "train loss:0.001363250750594021\n",
      "train loss:0.0017732501002690026\n",
      "train loss:0.003154233078092731\n",
      "train loss:0.001556147656391772\n",
      "train loss:0.009179106629156853\n",
      "train loss:0.0017010031057998539\n",
      "train loss:0.004805974165222254\n",
      "train loss:0.026859147217034588\n",
      "train loss:0.0022803519027399877\n",
      "train loss:0.002075212018633135\n",
      "train loss:0.0016897141398412472\n",
      "train loss:0.0003024440325297545\n",
      "train loss:0.0007131400814063374\n",
      "train loss:0.0028734690909827227\n",
      "train loss:0.013041226871947803\n",
      "train loss:0.0008967041996820506\n",
      "train loss:0.0022855357561689742\n",
      "train loss:0.001179170264189678\n",
      "train loss:0.0008694305935840261\n",
      "train loss:0.0019488317366477845\n",
      "train loss:0.0022875362665391442\n",
      "train loss:0.002352950034353086\n",
      "train loss:0.0019838788778691937\n",
      "train loss:0.005902135060155208\n",
      "train loss:0.000557169228075743\n",
      "train loss:0.0010856675149824566\n",
      "train loss:0.012316302886758706\n",
      "train loss:0.00021654238568673221\n",
      "train loss:0.0003599615327744465\n",
      "train loss:0.0013724633250806807\n",
      "train loss:0.0008995896946716606\n",
      "train loss:0.00290652517971385\n",
      "train loss:0.0006948029453022169\n",
      "train loss:0.0034288156953359815\n",
      "train loss:0.0003886483462199915\n",
      "train loss:0.0014870107240470907\n",
      "train loss:0.0002793643227432938\n",
      "train loss:0.0018640855676027835\n",
      "train loss:0.011957984543709457\n",
      "train loss:0.0038346727645127547\n",
      "train loss:0.00867821005013772\n",
      "train loss:0.000293929091474332\n",
      "train loss:0.0028862246244519595\n",
      "train loss:0.002944810444156144\n",
      "train loss:0.00590563198942029\n",
      "train loss:0.00017244945904206621\n",
      "train loss:0.0035467337003901693\n",
      "train loss:0.02314447998358259\n",
      "train loss:0.0005730916206471186\n",
      "train loss:0.0049359067036899565\n",
      "train loss:0.0019996286248974747\n",
      "train loss:0.001962475571110459\n",
      "train loss:0.0007532081524981393\n",
      "train loss:0.0029301980559620806\n",
      "=== epoch:17, train acc:0.995, test acc:0.986 ===\n",
      "train loss:0.0022940212243755973\n",
      "train loss:0.001099729168379487\n",
      "train loss:0.00045469925118299165\n",
      "train loss:0.01589469113812036\n",
      "train loss:0.03710604724475239\n",
      "train loss:0.0009051372806378183\n",
      "train loss:0.00048412602912163363\n",
      "train loss:0.0005131565343699713\n",
      "train loss:0.0006818875058896487\n",
      "train loss:0.0011489290644965632\n",
      "train loss:0.005927720707801332\n",
      "train loss:0.001125278382155106\n",
      "train loss:0.0013009574418537536\n",
      "train loss:0.013938519945135982\n",
      "train loss:0.0007486977209573321\n",
      "train loss:0.002203103095090076\n",
      "train loss:0.0019199518429459104\n",
      "train loss:0.0006183572075241727\n",
      "train loss:0.0006656587544417629\n",
      "train loss:0.0067620780765294194\n",
      "train loss:0.0008502474291653675\n",
      "train loss:0.002982353800651768\n",
      "train loss:0.040994271488517045\n",
      "train loss:0.000538834215626151\n",
      "train loss:0.0001818515832124022\n",
      "train loss:0.0009572190233472153\n",
      "train loss:0.001948577548483717\n",
      "train loss:0.0017773582637710308\n",
      "train loss:0.0019143367661582423\n",
      "train loss:0.0006799788004684426\n",
      "train loss:0.00278594314097172\n",
      "train loss:0.0014624177873461038\n",
      "train loss:0.004751854273539759\n",
      "train loss:0.00045242390289162917\n",
      "train loss:0.003928133425800822\n",
      "train loss:0.00012512354207171246\n",
      "train loss:0.001147865307755024\n",
      "train loss:0.01061955091849662\n",
      "train loss:0.000694866793609614\n",
      "train loss:0.0009226009154927367\n",
      "train loss:0.0020255679283265786\n",
      "train loss:4.900875674281158e-05\n",
      "train loss:0.0021251915084842055\n",
      "train loss:0.0010095237827075203\n",
      "train loss:0.0014337622217359502\n",
      "train loss:0.007744482457182362\n",
      "train loss:0.0006613393073078383\n",
      "train loss:0.00022173225246544594\n",
      "train loss:0.0019401155240843623\n",
      "train loss:0.00013684711449341223\n",
      "train loss:0.0005708765398203918\n",
      "train loss:0.02456451296151461\n",
      "train loss:0.0022160880149653976\n",
      "train loss:6.9100193502955e-05\n",
      "train loss:0.007258916981815477\n",
      "train loss:0.0008485717430383861\n",
      "train loss:0.002873623979981067\n",
      "train loss:0.0005434308772278553\n",
      "train loss:0.0025279088077299126\n",
      "train loss:0.0031732533148158765\n",
      "train loss:8.646607063256025e-05\n",
      "train loss:0.00781637118592392\n",
      "train loss:0.0027964231743641006\n",
      "train loss:0.001404070931155914\n",
      "train loss:0.0010854415479185152\n",
      "train loss:0.0006682515523719065\n",
      "train loss:0.007729265072911064\n",
      "train loss:0.0029262245504571706\n",
      "train loss:0.010619028599374516\n",
      "train loss:0.001470563705369423\n",
      "train loss:0.002346477134624626\n",
      "train loss:0.000563259841830413\n",
      "train loss:0.00029803847508181035\n",
      "train loss:0.0014018724435448666\n",
      "train loss:0.000888060281880908\n",
      "train loss:5.950016089827493e-05\n",
      "train loss:0.003329991633873275\n",
      "train loss:0.003153235426344641\n",
      "train loss:0.0009139535167205227\n",
      "train loss:0.0059406775660199\n",
      "train loss:0.025330246333573333\n",
      "train loss:0.0036313602081574194\n",
      "train loss:0.0018060585677782321\n",
      "train loss:0.007819342976504053\n",
      "train loss:0.004883258252531419\n",
      "train loss:0.0004956725945850563\n",
      "train loss:0.001077500853616291\n",
      "train loss:0.018184011976607878\n",
      "train loss:0.0014830246487113577\n",
      "train loss:0.0017537272520111197\n",
      "train loss:0.002306518317364697\n",
      "train loss:0.0026522548178590528\n",
      "train loss:0.0012537714027339678\n",
      "train loss:0.0009378286719341335\n",
      "train loss:0.019185021560045975\n",
      "train loss:0.006912065421240826\n",
      "train loss:0.001769406874854537\n",
      "train loss:0.004679536433317277\n",
      "train loss:0.0009829379577391132\n",
      "train loss:0.0016908956250015516\n",
      "train loss:0.0004452487623189191\n",
      "train loss:0.007461619453124739\n",
      "train loss:0.0021684091936066234\n",
      "train loss:0.006109131957404496\n",
      "train loss:0.0024323699085687933\n",
      "train loss:0.00043096945572555854\n",
      "train loss:0.00035419766978452553\n",
      "train loss:0.003317777314180467\n",
      "train loss:0.00018488839833429003\n",
      "train loss:0.003019714396284473\n",
      "train loss:0.00042553126877111896\n",
      "train loss:0.007144625365046632\n",
      "train loss:0.0015300962647110542\n",
      "train loss:0.002387950456974503\n",
      "train loss:0.0003427720960057838\n",
      "train loss:0.0019887232172046245\n",
      "train loss:0.0003604878254416224\n",
      "train loss:0.0004951213726464233\n",
      "train loss:0.002201302934757066\n",
      "train loss:0.0005289940229272029\n",
      "train loss:0.007043131507093322\n",
      "train loss:0.0022210203307975957\n",
      "train loss:0.0017181875397405393\n",
      "train loss:0.0005470800851663823\n",
      "train loss:0.003126076144565704\n",
      "train loss:0.0012295224658919648\n",
      "train loss:0.00021847651914688163\n",
      "train loss:0.0011115202715823167\n",
      "train loss:0.0004493612175986015\n",
      "train loss:0.0014839347452392834\n",
      "train loss:0.0003524129079969579\n",
      "train loss:0.0008728939319289808\n",
      "train loss:0.0021113707772560182\n",
      "train loss:0.0017302552698406372\n",
      "train loss:0.008931074640404879\n",
      "train loss:0.0028806195246694186\n",
      "train loss:0.009149019275416727\n",
      "train loss:0.0009821870992745272\n",
      "train loss:0.0008779204297942998\n",
      "train loss:0.0022739162170064687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:5.398628525524577e-05\n",
      "train loss:0.0003659854104095681\n",
      "train loss:0.00036764722710263447\n",
      "train loss:0.0047593595816312175\n",
      "train loss:0.0018457133484061122\n",
      "train loss:0.000285209539572968\n",
      "train loss:0.0011697230731234048\n",
      "train loss:0.001427089363093925\n",
      "train loss:0.007769310705482455\n",
      "train loss:0.0014541198962930656\n",
      "train loss:0.00012225189459620083\n",
      "train loss:0.0008277293832473375\n",
      "train loss:0.001737729164330471\n",
      "train loss:0.0002802418827190619\n",
      "train loss:0.0016028828888993948\n",
      "train loss:0.006300190438126947\n",
      "train loss:0.00014266006987599276\n",
      "train loss:0.05971141518632114\n",
      "train loss:0.0006276550146667769\n",
      "train loss:0.00025206835258258296\n",
      "train loss:0.00053023803736618\n",
      "train loss:0.0002773682258251917\n",
      "train loss:0.0008012547511963532\n",
      "train loss:0.00032873758323813477\n",
      "train loss:0.0021091778096262673\n",
      "train loss:0.0017057055113206218\n",
      "train loss:0.0016447289675861868\n",
      "train loss:0.00145878238232047\n",
      "train loss:0.00030808243565276543\n",
      "train loss:0.0012788129676234567\n",
      "train loss:0.0015329879198960961\n",
      "train loss:0.0020789608184687038\n",
      "train loss:0.000985519420927518\n",
      "train loss:0.0006063465653886758\n",
      "train loss:0.00041534428107017755\n",
      "train loss:0.00022470030446194788\n",
      "train loss:5.482869263290416e-05\n",
      "train loss:0.001079471217149218\n",
      "train loss:0.010124515925591195\n",
      "train loss:0.0045250026496248385\n",
      "train loss:0.0024944440039714483\n",
      "train loss:7.501354386633843e-05\n",
      "train loss:0.0020900152299879486\n",
      "train loss:0.001133859542860611\n",
      "train loss:0.004734152537478667\n",
      "train loss:0.002594829301499758\n",
      "train loss:0.00018024878244080438\n",
      "train loss:0.0008414318782254009\n",
      "train loss:0.0001756509401506791\n",
      "train loss:0.001157892918740385\n",
      "train loss:0.0002776271103549078\n",
      "train loss:0.00031747946939770475\n",
      "train loss:0.0018027886755001795\n",
      "train loss:0.00353818925514468\n",
      "train loss:0.00017136156529859827\n",
      "train loss:0.006715539353988843\n",
      "train loss:0.015379453471971023\n",
      "train loss:0.0006935656595696451\n",
      "train loss:0.002122576839294712\n",
      "train loss:0.0014098980174402065\n",
      "train loss:0.00022464954602231124\n",
      "train loss:0.0019694698802862694\n",
      "train loss:0.00027675767373653567\n",
      "train loss:0.002281232738134797\n",
      "train loss:0.0043782417700838116\n",
      "train loss:0.0011196101381084976\n",
      "train loss:0.000399186455786092\n",
      "train loss:0.002164399057239112\n",
      "train loss:0.0020461734326927255\n",
      "train loss:0.004979482497168993\n",
      "train loss:0.00013499997264963449\n",
      "train loss:0.001470855041050077\n",
      "train loss:0.0068777478892534825\n",
      "train loss:0.00033809430501190554\n",
      "train loss:0.0010866471736490247\n",
      "train loss:0.003298073184503822\n",
      "train loss:0.0015366174989601402\n",
      "train loss:0.00019523357628302814\n",
      "train loss:0.0007218203050856552\n",
      "train loss:0.001323984774136929\n",
      "train loss:0.005012118350670325\n",
      "train loss:0.0003246776697559621\n",
      "train loss:0.002494336283443349\n",
      "train loss:0.0003472013424348294\n",
      "train loss:0.0006329384932238657\n",
      "train loss:0.0013273414701855362\n",
      "train loss:0.000494255765903272\n",
      "train loss:0.0003646854153574069\n",
      "train loss:0.00042039835300972307\n",
      "train loss:0.00337215886705471\n",
      "train loss:0.0005897855532272473\n",
      "train loss:0.0032902860463539245\n",
      "train loss:0.0012521216382339099\n",
      "train loss:0.0002890125995824959\n",
      "train loss:0.00146386601552394\n",
      "train loss:6.746965488322119e-05\n",
      "train loss:0.0056285896914695325\n",
      "train loss:0.0004783716838265004\n",
      "train loss:0.0018030640193417908\n",
      "train loss:0.000154071237555672\n",
      "train loss:0.0005444174780506997\n",
      "train loss:0.0006985161788705561\n",
      "train loss:0.0002681402607671914\n",
      "train loss:0.000748329244785135\n",
      "train loss:0.001694371171046121\n",
      "train loss:0.0011806529051837811\n",
      "train loss:0.004557157559435656\n",
      "train loss:0.0005346323597235677\n",
      "train loss:0.00037087085206618874\n",
      "train loss:0.0007472941779901141\n",
      "train loss:0.00035017611590169065\n",
      "train loss:0.000860830158994268\n",
      "train loss:8.174455951663307e-05\n",
      "train loss:0.012225568552600185\n",
      "train loss:0.0005273428488743043\n",
      "train loss:0.00035509304981388106\n",
      "train loss:0.0009321432776994978\n",
      "train loss:0.0027713605836828577\n",
      "train loss:0.00018340892195267092\n",
      "train loss:0.00015670872314410913\n",
      "train loss:0.0006498492496866088\n",
      "train loss:0.0007982617639285429\n",
      "train loss:0.001436776179204205\n",
      "train loss:0.00010607954912673552\n",
      "train loss:0.002983385330648737\n",
      "train loss:0.0006477824324402012\n",
      "train loss:0.0025384175471774607\n",
      "train loss:0.0032452585059375904\n",
      "train loss:0.0009670745218806869\n",
      "train loss:0.001073113308465297\n",
      "train loss:0.0020272570322504525\n",
      "train loss:0.0026697284686108967\n",
      "train loss:0.007805922425689746\n",
      "train loss:0.00018047394969109774\n",
      "train loss:0.0002565950392401002\n",
      "train loss:0.0005853366383689988\n",
      "train loss:0.001753268440874979\n",
      "train loss:0.0008652679177732107\n",
      "train loss:0.001440315985031694\n",
      "train loss:0.00248229342875267\n",
      "train loss:0.00012154286218795387\n",
      "train loss:0.0005558769848407971\n",
      "train loss:0.0032042364569408494\n",
      "train loss:0.01059394326674004\n",
      "train loss:0.002090844506694582\n",
      "train loss:0.003489383603619326\n",
      "train loss:0.0014592233819254157\n",
      "train loss:0.00010360574007498173\n",
      "train loss:0.0020659225890103747\n",
      "train loss:0.000611339072159391\n",
      "train loss:0.00380889495627603\n",
      "train loss:0.0036698293385531407\n",
      "train loss:0.0014469768287130658\n",
      "train loss:0.001510656993841302\n",
      "train loss:0.004045519639429413\n",
      "train loss:0.00023121791496843287\n",
      "train loss:0.0021874754745962208\n",
      "train loss:0.00016103346161200116\n",
      "train loss:0.00041231663053424984\n",
      "train loss:0.0008602155756920834\n",
      "train loss:0.002463038591877207\n",
      "train loss:0.007765224590590493\n",
      "train loss:0.001377464570394681\n",
      "train loss:4.048845792227089e-05\n",
      "train loss:0.002502047228404098\n",
      "train loss:0.0009191907673732262\n",
      "train loss:0.0002703765288889764\n",
      "train loss:0.0010347792415845434\n",
      "train loss:0.0002333527827848501\n",
      "train loss:0.0012422211904832574\n",
      "train loss:0.007820664578464502\n",
      "train loss:0.0002867010800031496\n",
      "train loss:0.00014680111342605672\n",
      "train loss:0.00023343406920753331\n",
      "train loss:0.0024065751184733186\n",
      "train loss:0.0006549292143175876\n",
      "train loss:4.9979380561464046e-05\n",
      "train loss:0.00475701514595137\n",
      "train loss:8.263362420654178e-05\n",
      "train loss:0.001925893321933123\n",
      "train loss:0.0004183837566560916\n",
      "train loss:0.0006968423515056066\n",
      "train loss:0.0009300921769268937\n",
      "train loss:0.0035497496087855064\n",
      "train loss:0.0008441895007668422\n",
      "train loss:0.0030991751768995263\n",
      "train loss:0.008268226195256117\n",
      "train loss:0.0002902891781773038\n",
      "train loss:0.0012812501428611609\n",
      "train loss:0.00015607901237607312\n",
      "train loss:0.0006264995119530376\n",
      "train loss:0.0007454205831704366\n",
      "train loss:0.04683800758333565\n",
      "train loss:7.494977009216594e-05\n",
      "train loss:7.858696754905304e-05\n",
      "train loss:0.00022467004147704776\n",
      "train loss:0.0009170240762754819\n",
      "train loss:0.0003898581053793304\n",
      "train loss:0.00038969284044981935\n",
      "train loss:0.0007603105661172643\n",
      "train loss:0.0006200205448640768\n",
      "train loss:0.0014323458260612986\n",
      "train loss:0.00029552439222654413\n",
      "train loss:0.0017426912039238756\n",
      "train loss:0.005053319720923174\n",
      "train loss:0.00018464397640444882\n",
      "train loss:0.00022825348894328184\n",
      "train loss:7.957658133992149e-05\n",
      "train loss:0.006584005223692993\n",
      "train loss:0.0004838772963537831\n",
      "train loss:0.00016830600882925017\n",
      "train loss:6.901291826399953e-05\n",
      "train loss:5.885819314286423e-05\n",
      "train loss:0.0013820035056751688\n",
      "train loss:0.00412164908121276\n",
      "train loss:0.00014361473349447395\n",
      "train loss:0.0014658421113466818\n",
      "train loss:0.004777463763895293\n",
      "train loss:0.00034600102935283296\n",
      "train loss:0.00021058605493708013\n",
      "train loss:0.011767812706893975\n",
      "train loss:0.00011119562799260118\n",
      "train loss:0.00028897954342804185\n",
      "train loss:0.0010992019475614336\n",
      "train loss:0.00038258030501530315\n",
      "train loss:0.0015760287798847552\n",
      "train loss:0.0001735573457978319\n",
      "train loss:0.0010114961001299052\n",
      "train loss:0.00020037205249556577\n",
      "train loss:0.003399265117100372\n",
      "train loss:0.00033719278980692493\n",
      "train loss:0.00020941977934830968\n",
      "train loss:0.005523221508802416\n",
      "train loss:0.0016047780333168895\n",
      "train loss:0.0004045930524746994\n",
      "train loss:0.0008861572107364609\n",
      "train loss:0.0013805158027020601\n",
      "train loss:0.0036023565612164667\n",
      "train loss:0.0023546756263169723\n",
      "train loss:0.005905103700349978\n",
      "train loss:0.0010932853624462003\n",
      "train loss:0.00019266892182266337\n",
      "train loss:0.00025989545988558307\n",
      "train loss:0.00013053366571922568\n",
      "train loss:0.0009942289418389746\n",
      "train loss:0.0002562645794291127\n",
      "train loss:0.001114221002883884\n",
      "train loss:0.0006513572456941721\n",
      "train loss:0.0003267950863307867\n",
      "train loss:0.0032865539771983377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0030552883647917413\n",
      "train loss:0.00104323291826882\n",
      "train loss:0.0005452806026261154\n",
      "train loss:0.00013851216440182153\n",
      "train loss:0.001069262758425188\n",
      "train loss:0.00014926997633673026\n",
      "train loss:0.01182242591665611\n",
      "train loss:0.0008000143128428238\n",
      "train loss:8.192458329216898e-05\n",
      "train loss:0.0013472121072908168\n",
      "train loss:0.0007197932269311701\n",
      "train loss:0.001261169666438465\n",
      "train loss:0.00010372977111717304\n",
      "train loss:0.0011889010980782398\n",
      "train loss:0.0018424334278067762\n",
      "train loss:0.003823198143509288\n",
      "train loss:0.00046694383696493734\n",
      "train loss:0.00014449402525287594\n",
      "train loss:0.004650558687100108\n",
      "train loss:0.0056690032977975615\n",
      "train loss:0.004604382315442388\n",
      "train loss:0.0011119094305357803\n",
      "train loss:0.0009679443757477464\n",
      "train loss:0.0030462769657635586\n",
      "train loss:0.0010492029194785857\n",
      "train loss:0.002867644536792421\n",
      "train loss:0.002087881230791409\n",
      "train loss:0.0016093476300479065\n",
      "train loss:0.0011204731713023695\n",
      "train loss:0.033486362631318205\n",
      "train loss:0.003371504793348789\n",
      "train loss:0.002484878280557325\n",
      "train loss:0.0012847913087418133\n",
      "train loss:0.003114757685274962\n",
      "train loss:0.008643927620360972\n",
      "train loss:0.0017174742227874784\n",
      "train loss:0.00026142016523876836\n",
      "train loss:0.00049159653303328\n",
      "train loss:0.0036334390186225645\n",
      "train loss:0.00018995419766757888\n",
      "train loss:0.006748028070032186\n",
      "train loss:0.00014291330880897133\n",
      "train loss:0.0019877558426664005\n",
      "train loss:0.0002517656488131664\n",
      "train loss:0.0007004373699610448\n",
      "train loss:0.001920424772106785\n",
      "train loss:0.00021143425884081798\n",
      "train loss:0.0014355790229258645\n",
      "train loss:0.0017289461313134708\n",
      "train loss:0.003242194320418107\n",
      "train loss:0.0010900017307866772\n",
      "train loss:0.0011024746121755563\n",
      "train loss:0.03287666280354735\n",
      "train loss:0.002117361210272244\n",
      "train loss:0.0116722557844943\n",
      "train loss:0.0009648558625850445\n",
      "train loss:0.010595802775077157\n",
      "train loss:0.0004347051629063195\n",
      "train loss:0.0005214308687584735\n",
      "train loss:0.0018237152222218367\n",
      "train loss:0.0012850238493171979\n",
      "train loss:0.0008000000440812808\n",
      "train loss:0.0023078456859189876\n",
      "train loss:0.006547993711787731\n",
      "train loss:0.0014290248389909963\n",
      "train loss:0.0006559985920037097\n",
      "train loss:0.001095126358787798\n",
      "train loss:0.0008475882964166984\n",
      "train loss:0.0004550382265187366\n",
      "train loss:0.0001601309565254785\n",
      "train loss:0.0014517489352473304\n",
      "train loss:5.211301918115656e-05\n",
      "train loss:0.0022934344664137015\n",
      "train loss:0.00018848376279494782\n",
      "train loss:9.430628141618243e-05\n",
      "train loss:0.004075680306492902\n",
      "train loss:0.0024018057223359453\n",
      "train loss:0.0004936102942299738\n",
      "train loss:0.004206069978914713\n",
      "train loss:0.0015986155598171569\n",
      "train loss:0.0010273366498591832\n",
      "train loss:0.0007884700448899702\n",
      "train loss:0.0007154518550144459\n",
      "train loss:0.0012900543349846682\n",
      "train loss:0.0019262891649843847\n",
      "train loss:0.007701969953469501\n",
      "train loss:0.0010012961669772452\n",
      "train loss:0.003123898260320318\n",
      "train loss:0.0068350801284977145\n",
      "train loss:0.0012847453821436508\n",
      "train loss:0.0025941759941682744\n",
      "train loss:0.0010926875551390304\n",
      "train loss:0.002495272127175318\n",
      "train loss:0.00014794687593593672\n",
      "train loss:0.004518452041577374\n",
      "train loss:0.000714804505069831\n",
      "train loss:0.003508251882861777\n",
      "train loss:0.000603903547509488\n",
      "train loss:0.0026110652076853013\n",
      "train loss:0.0005820182340738459\n",
      "train loss:0.001220187421855492\n",
      "train loss:0.01971236637252595\n",
      "train loss:0.0005013862878606177\n",
      "train loss:0.00035756932914277127\n",
      "train loss:0.000678551928988538\n",
      "train loss:0.002468861010171965\n",
      "train loss:0.00022026219024062435\n",
      "train loss:0.0042417173889252695\n",
      "train loss:0.024803832717149445\n",
      "train loss:0.004426794772913426\n",
      "train loss:0.00664949826378065\n",
      "train loss:0.00045635326323342605\n",
      "train loss:0.00695978336896863\n",
      "train loss:0.000719053727734485\n",
      "train loss:0.003822957743051624\n",
      "train loss:0.0031619342217176593\n",
      "train loss:0.003428885869795356\n",
      "train loss:0.0012981693806098692\n",
      "train loss:0.000863376956353219\n",
      "train loss:0.001056809866131604\n",
      "train loss:0.004587814820269107\n",
      "train loss:0.0010463138117662296\n",
      "train loss:0.0028640389698668905\n",
      "train loss:0.00019291879882658286\n",
      "train loss:0.0011373182649127476\n",
      "train loss:0.01902188103553218\n",
      "train loss:0.006850392057066928\n",
      "train loss:0.0007513062952705058\n",
      "train loss:5.223812812600428e-05\n",
      "train loss:0.00035789574170806265\n",
      "train loss:0.0037629778790817304\n",
      "train loss:0.001268095845731314\n",
      "train loss:0.0003297924429896102\n",
      "train loss:0.0009474757553971806\n",
      "train loss:0.005035605946330513\n",
      "train loss:0.0007803285998068737\n",
      "train loss:0.005161930307725849\n",
      "train loss:0.003724179829967851\n",
      "train loss:0.03848584643235317\n",
      "train loss:0.0012735258194340269\n",
      "train loss:0.0036964535899397517\n",
      "train loss:0.00627550057475959\n",
      "train loss:0.001107849356561025\n",
      "train loss:0.0049155895758226115\n",
      "train loss:0.0021899553186547774\n",
      "train loss:0.00010976832256384277\n",
      "train loss:0.0009263858317235148\n",
      "train loss:0.0011419036094339453\n",
      "train loss:0.0032911243276845803\n",
      "train loss:0.015995107714907805\n",
      "train loss:0.0007386264694815598\n",
      "train loss:0.0012739244372812516\n",
      "train loss:0.004389128532609521\n",
      "train loss:0.0001009153835279334\n",
      "train loss:0.0048171321011054894\n",
      "train loss:0.002698682209455421\n",
      "train loss:0.001447045956989541\n",
      "train loss:0.0011668526480684656\n",
      "train loss:0.003120784592445103\n",
      "train loss:0.0009113378015334237\n",
      "train loss:0.02640887844834492\n",
      "train loss:0.0007838105536345584\n",
      "train loss:0.00022697312689492837\n",
      "train loss:0.0008358478078075354\n",
      "train loss:0.08289584455406725\n",
      "train loss:0.001403598883177899\n",
      "train loss:0.0009916791809093334\n",
      "train loss:0.0023982527588736423\n",
      "train loss:0.0008802049142535959\n",
      "train loss:0.00383442366361422\n",
      "train loss:0.009434282119980954\n",
      "train loss:0.001047292501697971\n",
      "train loss:0.019300882012482475\n",
      "train loss:0.003415013439443433\n",
      "train loss:0.002123851745728868\n",
      "train loss:4.353362249610838e-05\n",
      "train loss:0.004627946557927102\n",
      "train loss:0.00011665663414552971\n",
      "train loss:0.0006663077759172105\n",
      "train loss:0.0021778490489567236\n",
      "train loss:0.0020476934066302414\n",
      "train loss:0.005006695408228745\n",
      "train loss:0.0008283218054433401\n",
      "train loss:0.003367298280748689\n",
      "train loss:0.0010084634863531002\n",
      "train loss:0.002242801596085321\n",
      "train loss:0.005714360659823455\n",
      "train loss:0.0018922652724817507\n",
      "train loss:0.0004945966729281738\n",
      "train loss:0.011550626914564628\n",
      "train loss:0.015262370302724832\n",
      "train loss:0.0049764077359198446\n",
      "train loss:0.01096419847650668\n",
      "train loss:0.0018676022832896408\n",
      "train loss:0.0014679403437327617\n",
      "train loss:0.004007373667257546\n",
      "train loss:0.00216890562726717\n",
      "train loss:0.0018720587041699847\n",
      "train loss:0.003312515631999744\n",
      "train loss:0.0004542973943162714\n",
      "train loss:0.001843901789637631\n",
      "train loss:0.004293154820417691\n",
      "train loss:0.004951894634061321\n",
      "train loss:0.004407848212770261\n",
      "train loss:0.00023511917868984585\n",
      "train loss:0.0003632232776590169\n",
      "train loss:0.005529935640928182\n",
      "train loss:0.0005886840797735035\n",
      "train loss:0.0007282475592163409\n",
      "train loss:0.004766198426950258\n",
      "=== epoch:18, train acc:1.0, test acc:0.986 ===\n",
      "train loss:0.00016911968371888825\n",
      "train loss:0.00035284552722337917\n",
      "train loss:0.0033096732881137286\n",
      "train loss:0.00022560393790207317\n",
      "train loss:0.0003535268612315452\n",
      "train loss:0.00012376368800694182\n",
      "train loss:0.0006003022420164515\n",
      "train loss:0.00034234924445661336\n",
      "train loss:0.00033084366827026187\n",
      "train loss:0.0008240350988556805\n",
      "train loss:0.002142183142119754\n",
      "train loss:0.002241643238976758\n",
      "train loss:0.0007170382807487334\n",
      "train loss:0.000568826063669078\n",
      "train loss:0.005382734439527062\n",
      "train loss:0.00011717943748724539\n",
      "train loss:0.0015965467063068426\n",
      "train loss:0.0012305794489626757\n",
      "train loss:0.026121401831573007\n",
      "train loss:0.0003228459563495687\n",
      "train loss:0.0034105185155831963\n",
      "train loss:0.0017104239689213682\n",
      "train loss:0.0006185537052266838\n",
      "train loss:0.0004372680103784566\n",
      "train loss:0.007886423727306547\n",
      "train loss:0.0009519437155576717\n",
      "train loss:0.0025980264001714323\n",
      "train loss:0.0012161052136777308\n",
      "train loss:0.00019173058243094108\n",
      "train loss:0.0040029431386116145\n",
      "train loss:0.0016016313233746208\n",
      "train loss:0.000336402599146421\n",
      "train loss:0.00019242236174721054\n",
      "train loss:0.000532402406728192\n",
      "train loss:5.746862249556725e-05\n",
      "train loss:0.0004059247497815624\n",
      "train loss:0.000725195109431508\n",
      "train loss:0.00011437533333052327\n",
      "train loss:0.0018999817169788583\n",
      "train loss:0.00015587360244605875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0003470906341191543\n",
      "train loss:0.001788533495505365\n",
      "train loss:0.004462339050465891\n",
      "train loss:0.0010254302513146238\n",
      "train loss:0.09587591193948743\n",
      "train loss:0.0009978520308732456\n",
      "train loss:0.0015423628352473533\n",
      "train loss:0.00011707595052019813\n",
      "train loss:0.00028758436398997994\n",
      "train loss:0.0003213343322669134\n",
      "train loss:0.0035554098943213677\n",
      "train loss:0.0021006760450036415\n",
      "train loss:0.0016421164387566201\n",
      "train loss:0.00205691668141834\n",
      "train loss:0.00045856182062832437\n",
      "train loss:0.001564761192293272\n",
      "train loss:0.0030435658166983793\n",
      "train loss:0.004799509478074005\n",
      "train loss:0.00037941647639989153\n",
      "train loss:0.002974133621108135\n",
      "train loss:0.004636891301249707\n",
      "train loss:0.008033510243738197\n",
      "train loss:0.0009074518072421829\n",
      "train loss:0.037995044959654514\n",
      "train loss:0.0030977524594514873\n",
      "train loss:0.0004975317654481164\n",
      "train loss:0.000954117415697115\n",
      "train loss:0.0009223087550911981\n",
      "train loss:0.026982645571120744\n",
      "train loss:0.0007014895623412457\n",
      "train loss:0.00021800707786556208\n",
      "train loss:0.0006845581147491128\n",
      "train loss:0.0010670956460893668\n",
      "train loss:0.005072366344000121\n",
      "train loss:0.0004496935867879979\n",
      "train loss:0.0049149608396666464\n",
      "train loss:0.0006066543156776906\n",
      "train loss:0.0013133629709486722\n",
      "train loss:0.0011952999166454277\n",
      "train loss:0.0037963306230131178\n",
      "train loss:0.0013846732385343011\n",
      "train loss:9.112352544386732e-05\n",
      "train loss:0.002549462097119759\n",
      "train loss:0.002996779056620691\n",
      "train loss:0.004502176111073449\n",
      "train loss:0.0008554048050411047\n",
      "train loss:0.002528442508553325\n",
      "train loss:0.0010847266779739047\n",
      "train loss:0.006230158240573025\n",
      "train loss:0.0010741609369593254\n",
      "train loss:0.0028566927978512183\n",
      "train loss:0.005271344194389182\n",
      "train loss:0.001641393719946736\n",
      "train loss:0.0005000757312379269\n",
      "train loss:0.011522792248951778\n",
      "train loss:0.0011227679296451172\n",
      "train loss:0.0029876095414935917\n",
      "train loss:0.0016708676479900448\n",
      "train loss:0.0005903400018798657\n",
      "train loss:0.0014807294304423776\n",
      "train loss:0.003864463322863372\n",
      "train loss:0.00311198410457862\n",
      "train loss:0.0041862463379957445\n",
      "train loss:0.003457652945651271\n",
      "train loss:0.005623942177477137\n",
      "train loss:0.007380794779032307\n",
      "train loss:0.005687029261588673\n",
      "train loss:0.0006961119808027707\n",
      "train loss:0.00023508187337234715\n",
      "train loss:0.000645471125307753\n",
      "train loss:0.0004845499108117069\n",
      "train loss:0.00014818344736105345\n",
      "train loss:0.00039117611274101945\n",
      "train loss:0.0028131149907030446\n",
      "train loss:0.0010112405166317789\n",
      "train loss:0.004926725468364235\n",
      "train loss:0.0002130654314057764\n",
      "train loss:0.0005203509174311156\n",
      "train loss:0.005796916832771509\n",
      "train loss:0.002211708673249628\n",
      "train loss:0.002433308037391564\n",
      "train loss:0.019570192584524707\n",
      "train loss:0.0009807803162920313\n",
      "train loss:0.0026323787821886002\n",
      "train loss:0.001854459015683246\n",
      "train loss:0.0014291640412374424\n",
      "train loss:0.0032097282787764718\n",
      "train loss:0.002470897550224178\n",
      "train loss:0.005781374853391896\n",
      "train loss:0.002740180348269331\n",
      "train loss:0.024141389685323107\n",
      "train loss:0.0018786058092680428\n",
      "train loss:0.001980249509680639\n",
      "train loss:0.0001817962407086335\n",
      "train loss:0.0012713756886505027\n",
      "train loss:0.004020467359601152\n",
      "train loss:0.00017527913586676792\n",
      "train loss:0.00015580740132523075\n",
      "train loss:0.002106658780855317\n",
      "train loss:0.0016582875626782686\n",
      "train loss:0.004435757850125483\n",
      "train loss:0.0009489290890962196\n",
      "train loss:0.001074792244346533\n",
      "train loss:0.0012242069979920716\n",
      "train loss:0.0004496522772511682\n",
      "train loss:0.00373642870583443\n",
      "train loss:0.0012059698037831738\n",
      "train loss:0.001946573036108765\n",
      "train loss:0.003282446053063618\n",
      "train loss:0.004674327829508166\n",
      "train loss:0.0003151607089753809\n",
      "train loss:0.0009296129521596525\n",
      "train loss:0.006283522601578614\n",
      "train loss:0.0012737595542765862\n",
      "train loss:0.002216103617432971\n",
      "train loss:0.00011008366453946572\n",
      "train loss:0.006510075879417121\n",
      "train loss:0.0022795522310976677\n",
      "train loss:0.0028526330559215103\n",
      "train loss:0.0010726717292465762\n",
      "train loss:0.00010106666137568974\n",
      "train loss:7.10069313390333e-05\n",
      "train loss:0.0002781503329394613\n",
      "train loss:0.001735586492676862\n",
      "train loss:0.001863174289956083\n",
      "train loss:0.0019220712170982597\n",
      "train loss:0.0019509424738290316\n",
      "train loss:0.0005555637281557127\n",
      "train loss:0.004711231158616259\n",
      "train loss:0.007810938352438493\n",
      "train loss:0.0010612990843623354\n",
      "train loss:0.0009594997643941567\n",
      "train loss:0.0011665199420530048\n",
      "train loss:0.00037106574974259907\n",
      "train loss:0.00021587091131892544\n",
      "train loss:0.0004919829827830861\n",
      "train loss:0.0005208535879811599\n",
      "train loss:0.0001850098608487632\n",
      "train loss:0.00625148824975161\n",
      "train loss:0.0014861254344048593\n",
      "train loss:0.004800960999429324\n",
      "train loss:0.000856963738713642\n",
      "train loss:0.0006386201976369638\n",
      "train loss:0.0016601803147054338\n",
      "train loss:0.0002765133348406406\n",
      "train loss:0.00037302631477327715\n",
      "train loss:0.0002809625803005658\n",
      "train loss:0.0005338557765609184\n",
      "train loss:0.0029611394716665307\n",
      "train loss:0.014113707346910025\n",
      "train loss:0.0002123968593191882\n",
      "train loss:0.0034547724953637227\n",
      "train loss:0.0002963940053278651\n",
      "train loss:0.002905937487759087\n",
      "train loss:0.0007273266052715545\n",
      "train loss:0.0008044229277751934\n",
      "train loss:0.0004983457376909772\n",
      "train loss:0.0018631072936441224\n",
      "train loss:0.0009725842900741283\n",
      "train loss:0.0014577373254325862\n",
      "train loss:3.26195320008674e-05\n",
      "train loss:0.0037046611667619672\n",
      "train loss:0.0003489031359139717\n",
      "train loss:0.0023954291190955604\n",
      "train loss:0.00024087715087111542\n",
      "train loss:0.00027072490113478617\n",
      "train loss:0.001324712878490315\n",
      "train loss:0.0009496117210590851\n",
      "train loss:3.4804815178965685e-05\n",
      "train loss:0.00357240486770956\n",
      "train loss:0.0003033926274264346\n",
      "train loss:0.0031823046358073178\n",
      "train loss:0.0001955547190705649\n",
      "train loss:0.0012110896164811615\n",
      "train loss:0.00019081474807221925\n",
      "train loss:0.0007260612808396825\n",
      "train loss:0.006374866749607622\n",
      "train loss:0.0002390561168101033\n",
      "train loss:0.0035422198934856484\n",
      "train loss:0.003082896602583633\n",
      "train loss:0.0011511856561988746\n",
      "train loss:0.00034973697240820714\n",
      "train loss:0.000264423378057336\n",
      "train loss:6.06828317608183e-05\n",
      "train loss:0.0019542917078652676\n",
      "train loss:0.001397478505324213\n",
      "train loss:0.003278551542909824\n",
      "train loss:0.003779797914242778\n",
      "train loss:0.0007540114888971791\n",
      "train loss:9.158115814726227e-05\n",
      "train loss:0.0012019494533637453\n",
      "train loss:0.0026988922400319974\n",
      "train loss:0.004566356803925541\n",
      "train loss:0.0003639830262771364\n",
      "train loss:7.269990248061172e-05\n",
      "train loss:0.0006389985818543552\n",
      "train loss:0.0004991416918364226\n",
      "train loss:0.00013551425637758967\n",
      "train loss:0.0016152631583738557\n",
      "train loss:0.002647782238709358\n",
      "train loss:0.00023546429982178657\n",
      "train loss:0.0006828279236143212\n",
      "train loss:8.824999280264827e-05\n",
      "train loss:0.001090299363498823\n",
      "train loss:0.002488204169336661\n",
      "train loss:0.0011109161119549932\n",
      "train loss:0.0009088541534807684\n",
      "train loss:0.0007898832032583785\n",
      "train loss:0.0026867103476897036\n",
      "train loss:0.0008111150232915617\n",
      "train loss:8.924386489980743e-05\n",
      "train loss:0.00014103055246085085\n",
      "train loss:7.19604216412845e-05\n",
      "train loss:0.00020308321137573994\n",
      "train loss:0.00014596730286378504\n",
      "train loss:0.0009157086974048636\n",
      "train loss:0.00024712131463943516\n",
      "train loss:2.4543850583956607e-05\n",
      "train loss:0.00016533385024665188\n",
      "train loss:0.0024106102089204873\n",
      "train loss:0.00041535544242304005\n",
      "train loss:0.0006723103721255866\n",
      "train loss:0.004393252671300021\n",
      "train loss:0.0006391543689999283\n",
      "train loss:0.00032724884420451275\n",
      "train loss:4.022562429128004e-05\n",
      "train loss:0.001442915635740633\n",
      "train loss:0.000516074686751062\n",
      "train loss:0.002605384610660086\n",
      "train loss:0.0008389966906345844\n",
      "train loss:0.00012303888782075882\n",
      "train loss:0.0011637577256137042\n",
      "train loss:0.00017304165238554817\n",
      "train loss:0.007378424213361167\n",
      "train loss:0.0005662890312667222\n",
      "train loss:0.00043149955579528584\n",
      "train loss:0.0007004746743985657\n",
      "train loss:3.9402437135250455e-05\n",
      "train loss:0.0005786758753149327\n",
      "train loss:0.007361912301155362\n",
      "train loss:0.0007117197986398434\n",
      "train loss:0.0012841757256997618\n",
      "train loss:0.0023980365239430097\n",
      "train loss:0.0008262168388373291\n",
      "train loss:0.0022717132672778213\n",
      "train loss:0.001164843244603008\n",
      "train loss:0.00046116685834076527\n",
      "train loss:0.004041773133861775\n",
      "train loss:0.0004438360704772063\n",
      "train loss:0.0011025226964150377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0024674739581634127\n",
      "train loss:0.001264518778848861\n",
      "train loss:0.011214290182432427\n",
      "train loss:0.00035027564945388666\n",
      "train loss:0.0026212899570981617\n",
      "train loss:0.0015960085694135514\n",
      "train loss:0.0016170874993353037\n",
      "train loss:0.0008246568063167438\n",
      "train loss:0.003001316483335758\n",
      "train loss:0.0005044684534863417\n",
      "train loss:0.0016007040914298221\n",
      "train loss:0.0002449969484192991\n",
      "train loss:0.002395846328613774\n",
      "train loss:0.000319105479585891\n",
      "train loss:0.007300780391826086\n",
      "train loss:0.0006305205758695969\n",
      "train loss:0.0002824749545785748\n",
      "train loss:0.002723030307454837\n",
      "train loss:0.0004072786913914347\n",
      "train loss:0.0004958762129876068\n",
      "train loss:0.0003382427728031688\n",
      "train loss:0.0006085993121443257\n",
      "train loss:0.0007175336832645989\n",
      "train loss:0.0013187737678315248\n",
      "train loss:0.011985351558635353\n",
      "train loss:0.0009013245874326744\n",
      "train loss:0.0005327133085076166\n",
      "train loss:0.0006119644028123713\n",
      "train loss:0.0004024860620959935\n",
      "train loss:0.001953438780015633\n",
      "train loss:0.00017131786423701687\n",
      "train loss:0.001842939358744758\n",
      "train loss:0.0028784116465564256\n",
      "train loss:0.0009088497924891731\n",
      "train loss:0.0018444398405854082\n",
      "train loss:2.6895634805377378e-05\n",
      "train loss:0.0013382814012475822\n",
      "train loss:0.0014233797177463992\n",
      "train loss:0.014529549201523379\n",
      "train loss:0.00024899342439066\n",
      "train loss:0.004187514671470516\n",
      "train loss:0.0002470122241048619\n",
      "train loss:0.0031185218753445694\n",
      "train loss:0.001805647490822558\n",
      "train loss:7.928718508248814e-05\n",
      "train loss:7.464793338594267e-05\n",
      "train loss:0.00020804540629271311\n",
      "train loss:0.0031597247731264193\n",
      "train loss:0.001362540565285972\n",
      "train loss:0.0008779368055921863\n",
      "train loss:0.0007593808540970659\n",
      "train loss:0.0002035305628690637\n",
      "train loss:0.00047001887832348593\n",
      "train loss:0.00038757233730703504\n",
      "train loss:0.002104026687975097\n",
      "train loss:0.0008277901378517183\n",
      "train loss:7.108273019960671e-05\n",
      "train loss:0.00035694369530844523\n",
      "train loss:0.0014450696282293305\n",
      "train loss:0.0008287722601826483\n",
      "train loss:0.0001623290407489918\n",
      "train loss:0.0005240220270397579\n",
      "train loss:0.0007674624502467446\n",
      "train loss:4.646399306164312e-05\n",
      "train loss:0.0010631986409923718\n",
      "train loss:0.0012134688693987976\n",
      "train loss:0.0006229362765346185\n",
      "train loss:0.00199555865380749\n",
      "train loss:0.0007982501383414204\n",
      "train loss:0.0002418057949387436\n",
      "train loss:0.0014914470348120006\n",
      "train loss:0.0005912539790042924\n",
      "train loss:0.0008750784924525156\n",
      "train loss:0.0004425839011189269\n",
      "train loss:0.0005660574815503981\n",
      "train loss:0.0015299249525188216\n",
      "train loss:0.0002706380210659188\n",
      "train loss:3.1607922883030614e-05\n",
      "train loss:0.00021173179053121403\n",
      "train loss:0.000141950398303426\n",
      "train loss:0.002105434479137693\n",
      "train loss:0.0006698510629602471\n",
      "train loss:0.0004029185770321975\n",
      "train loss:0.003106045198686478\n",
      "train loss:0.001118104879817637\n",
      "train loss:0.0006073352185415507\n",
      "train loss:9.30798224759551e-05\n",
      "train loss:7.021187364128835e-05\n",
      "train loss:0.00011375319442688795\n",
      "train loss:0.0015005029855258594\n",
      "train loss:9.274998424082728e-05\n",
      "train loss:0.0003825515256407408\n",
      "train loss:0.0003294894262177964\n",
      "train loss:0.0012082878093661329\n",
      "train loss:0.00019992268921327667\n",
      "train loss:0.0003637391759187449\n",
      "train loss:0.0004888271282132471\n",
      "train loss:0.000321216460369735\n",
      "train loss:3.243600869886005e-05\n",
      "train loss:0.005919381472990751\n",
      "train loss:0.004939521695846981\n",
      "train loss:0.00015264487287742045\n",
      "train loss:0.0013508113915127599\n",
      "train loss:0.0012520539347440776\n",
      "train loss:0.00016502059110653426\n",
      "train loss:0.025577311910512015\n",
      "train loss:0.002470282621469531\n",
      "train loss:0.0038609441219055523\n",
      "train loss:0.0030139041127408895\n",
      "train loss:0.00030625311504938927\n",
      "train loss:0.0006919201603737468\n",
      "train loss:0.0016575251845748862\n",
      "train loss:0.0005641433959292291\n",
      "train loss:5.5557012633398054e-05\n",
      "train loss:0.00021929581175236313\n",
      "train loss:0.0005488557898526364\n",
      "train loss:0.0022761821802646425\n",
      "train loss:0.0007998986473977339\n",
      "train loss:0.00015209070724052823\n",
      "train loss:0.0003816688173453671\n",
      "train loss:0.030062370658748828\n",
      "train loss:0.0016471275232020927\n",
      "train loss:0.0017076723863648042\n",
      "train loss:0.00017567913981731323\n",
      "train loss:0.0003579812796441573\n",
      "train loss:0.00017543662026143873\n",
      "train loss:0.0004301671633134006\n",
      "train loss:0.0005817199313273992\n",
      "train loss:0.0036842275609820243\n",
      "train loss:0.00015990709489910614\n",
      "train loss:0.003844852266731609\n",
      "train loss:0.0008363524590691145\n",
      "train loss:0.0003042138952793008\n",
      "train loss:0.00023552415692620158\n",
      "train loss:0.001821886127988301\n",
      "train loss:6.686864462640445e-05\n",
      "train loss:3.1320714519706245e-05\n",
      "train loss:0.0021900539792522626\n",
      "train loss:0.00026757455310158664\n",
      "train loss:0.0001696663685368793\n",
      "train loss:0.003274728523282948\n",
      "train loss:0.0004747468107919538\n",
      "train loss:0.0006747426261987266\n",
      "train loss:0.005284455411749235\n",
      "train loss:0.0013099827535914368\n",
      "train loss:0.002201953903459208\n",
      "train loss:0.0015358181140047813\n",
      "train loss:0.0024735365057654396\n",
      "train loss:3.645347832349957e-05\n",
      "train loss:0.003678012044981022\n",
      "train loss:0.0013881657406140625\n",
      "train loss:0.00010643560133448995\n",
      "train loss:8.949103876678072e-05\n",
      "train loss:0.0011448127690565067\n",
      "train loss:1.4074355082638263e-05\n",
      "train loss:0.007427307581851671\n",
      "train loss:0.0011162797906902216\n",
      "train loss:0.00021644939131817569\n",
      "train loss:0.0042583939885307235\n",
      "train loss:0.0006904590377180341\n",
      "train loss:0.00035338145028353035\n",
      "train loss:0.0013335615438927414\n",
      "train loss:0.000799744800934142\n",
      "train loss:0.0005090590421000199\n",
      "train loss:0.005692116630526325\n",
      "train loss:0.0008917078249697096\n",
      "train loss:0.0008771279618773202\n",
      "train loss:0.0014848829739776536\n",
      "train loss:0.003563660120697512\n",
      "train loss:0.00027838049587858136\n",
      "train loss:0.0005968431506453725\n",
      "train loss:0.002720657935550574\n",
      "train loss:0.0021441073788836308\n",
      "train loss:0.0006217944548796496\n",
      "train loss:0.000256512297211259\n",
      "train loss:5.21990321469534e-05\n",
      "train loss:0.004124026752540902\n",
      "train loss:0.0009623143044290998\n",
      "train loss:0.0016768276053183559\n",
      "train loss:0.007489234770742184\n",
      "train loss:0.0025397608502292068\n",
      "train loss:6.067629365578082e-05\n",
      "train loss:0.00019116324248824433\n",
      "train loss:0.0015273088949629894\n",
      "train loss:4.910286268860034e-05\n",
      "train loss:0.0009954698583069827\n",
      "train loss:0.0006695928298473059\n",
      "train loss:0.014564534470355274\n",
      "train loss:0.00042889013817692744\n",
      "train loss:0.012213333864777663\n",
      "train loss:0.0055586857600985915\n",
      "train loss:0.0021362432832591873\n",
      "train loss:0.0010995997546021632\n",
      "train loss:0.0007252609256500659\n",
      "train loss:0.001877533770767424\n",
      "train loss:0.0012689035075111646\n",
      "train loss:0.00039816670846903136\n",
      "train loss:0.0015458873182385893\n",
      "train loss:0.000312094291037707\n",
      "train loss:0.00013413492108601494\n",
      "train loss:0.0027752409709460367\n",
      "train loss:0.005157801044789994\n",
      "train loss:0.000623959869630727\n",
      "train loss:0.0001708256402631921\n",
      "train loss:0.002604967780606327\n",
      "train loss:0.006439931416092016\n",
      "train loss:4.944244112258147e-05\n",
      "train loss:9.491402118748523e-05\n",
      "train loss:0.0009143679882995031\n",
      "train loss:0.04110110235980665\n",
      "train loss:0.0012692454695767616\n",
      "train loss:0.0012538950224859529\n",
      "train loss:0.0010107303710916054\n",
      "train loss:6.447387105131684e-05\n",
      "train loss:0.009066866073127944\n",
      "train loss:0.00042235005842959487\n",
      "train loss:0.003260425087753148\n",
      "train loss:6.690376977502944e-05\n",
      "train loss:0.0008016807677353796\n",
      "train loss:0.00017119869052594234\n",
      "train loss:0.00015672965830385794\n",
      "train loss:0.0004007928676494293\n",
      "train loss:0.00034468381710919593\n",
      "train loss:0.000879675767108766\n",
      "train loss:0.0010341784710941784\n",
      "train loss:0.000811929677418484\n",
      "train loss:0.00047647253612328604\n",
      "train loss:0.0004240846254266387\n",
      "train loss:0.0015145736066263077\n",
      "train loss:0.00013992207604434864\n",
      "train loss:0.0027372286027961845\n",
      "train loss:0.000273977772460235\n",
      "train loss:7.583390217326039e-05\n",
      "train loss:0.00048113821725482084\n",
      "train loss:0.0011043085231460692\n",
      "train loss:0.0005150846237948341\n",
      "train loss:0.0014925600408691039\n",
      "train loss:0.0002689476266424459\n",
      "train loss:0.00015921354534079426\n",
      "train loss:0.0006029631245983496\n",
      "train loss:0.0005006344247685025\n",
      "train loss:7.712075416234369e-05\n",
      "train loss:0.00031720489997345857\n",
      "train loss:0.0004232382775725091\n",
      "train loss:0.0011857942539698304\n",
      "train loss:0.0004147962535768642\n",
      "train loss:0.0035684764353989423\n",
      "train loss:0.0024470550006956936\n",
      "train loss:5.755168744208528e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0013434248176931612\n",
      "train loss:6.006262855429938e-05\n",
      "train loss:8.760932580441617e-05\n",
      "train loss:0.00044588579672834105\n",
      "train loss:0.0002664354953069652\n",
      "train loss:0.0010010967575882666\n",
      "train loss:0.0003023863315140663\n",
      "train loss:0.0014473922607125015\n",
      "train loss:0.00503606044225659\n",
      "train loss:0.000267660922254348\n",
      "train loss:0.0017181571628526796\n",
      "train loss:0.0005212249290575427\n",
      "train loss:0.0005042194830602564\n",
      "train loss:0.0001568730724821845\n",
      "train loss:1.293612469536681e-05\n",
      "train loss:2.3165916043870342e-05\n",
      "train loss:0.0002732207280526619\n",
      "train loss:0.0027586630267992856\n",
      "train loss:0.0003311245508428567\n",
      "train loss:0.0010870720862144027\n",
      "train loss:0.0006216746305327963\n",
      "train loss:0.00182913851337629\n",
      "train loss:0.0003654498333943492\n",
      "train loss:2.6575785176177425e-05\n",
      "train loss:6.273723089140865e-05\n",
      "train loss:0.0010658123941485055\n",
      "train loss:0.0014819428020740296\n",
      "train loss:0.00020402172730201544\n",
      "train loss:0.0012225570039964499\n",
      "train loss:0.0005067436770184338\n",
      "train loss:1.5476409576142535e-05\n",
      "train loss:0.00017175776678868805\n",
      "train loss:0.0007093356920845836\n",
      "train loss:5.37561528761384e-05\n",
      "train loss:0.0001666739417110085\n",
      "train loss:0.0009092020233979177\n",
      "train loss:0.00028702673038971156\n",
      "train loss:0.00015121800971597312\n",
      "train loss:0.000357767878160051\n",
      "train loss:5.1932484614809914e-05\n",
      "train loss:0.0006644127771637752\n",
      "train loss:0.00012122475366687507\n",
      "train loss:0.00022767486935868118\n",
      "train loss:0.0001279006431118394\n",
      "train loss:6.004860430040434e-05\n",
      "train loss:0.0004918358479244504\n",
      "train loss:0.000284878435869846\n",
      "train loss:0.00023706108300281396\n",
      "train loss:0.00012032779585592833\n",
      "train loss:0.0017992840990223246\n",
      "train loss:7.69975269268657e-05\n",
      "train loss:2.6001024156157713e-05\n",
      "train loss:2.4399995228168534e-05\n",
      "train loss:0.000717498006855458\n",
      "train loss:0.00042407591788821107\n",
      "train loss:0.0004164796288061263\n",
      "train loss:0.00039510244522416395\n",
      "train loss:0.0005497056267461247\n",
      "train loss:7.331586162006727e-05\n",
      "train loss:0.00014840272884038828\n",
      "train loss:0.0005422855704186405\n",
      "=== epoch:19, train acc:0.998, test acc:0.985 ===\n",
      "train loss:0.0010246332994611545\n",
      "train loss:8.369167026219412e-05\n",
      "train loss:0.00018027572611503293\n",
      "train loss:0.002451073522403212\n",
      "train loss:0.000693898707862387\n",
      "train loss:0.00010375989214897219\n",
      "train loss:0.0015866726589831462\n",
      "train loss:0.0005367688076403941\n",
      "train loss:0.0002278741339346254\n",
      "train loss:0.0022616306055390683\n",
      "train loss:0.00020932062596307297\n",
      "train loss:0.0004178913684562882\n",
      "train loss:0.0001022061051377099\n",
      "train loss:0.00019842161085569513\n",
      "train loss:0.00013583639478540594\n",
      "train loss:0.0004043756921037571\n",
      "train loss:0.0005313776857415791\n",
      "train loss:0.0016630069588029655\n",
      "train loss:0.001517249728014829\n",
      "train loss:0.00037919025227087477\n",
      "train loss:0.0002742517236545819\n",
      "train loss:4.09173846576003e-05\n",
      "train loss:0.0029767378541210258\n",
      "train loss:0.0015705857392860256\n",
      "train loss:0.0016190577136791845\n",
      "train loss:0.0013487105125451178\n",
      "train loss:7.17028545226173e-06\n",
      "train loss:0.0018006136847353714\n",
      "train loss:0.0005825855329067557\n",
      "train loss:0.0013423184777280126\n",
      "train loss:0.00012107592448753845\n",
      "train loss:0.0014791080848252033\n",
      "train loss:0.0009240417793233479\n",
      "train loss:0.0006520139948014568\n",
      "train loss:0.00012875228659541655\n",
      "train loss:8.540800831597853e-05\n",
      "train loss:0.017534521913268587\n",
      "train loss:0.0021776770128777443\n",
      "train loss:0.0002730790045492535\n",
      "train loss:0.0004411557385771573\n",
      "train loss:6.535003043474773e-05\n",
      "train loss:0.00016987302934740896\n",
      "train loss:0.0001931436602200575\n",
      "train loss:0.0001656130356774898\n",
      "train loss:0.0007698905592326807\n",
      "train loss:0.00013190147518210216\n",
      "train loss:0.0017668603300891985\n",
      "train loss:0.0021647101168532205\n",
      "train loss:0.0002370094353416051\n",
      "train loss:0.0002885874299680932\n",
      "train loss:0.0016928599323090274\n",
      "train loss:0.0003731098350567726\n",
      "train loss:0.0002451752743502726\n",
      "train loss:0.001644077151497479\n",
      "train loss:0.00024500107398016597\n",
      "train loss:0.0007101444383707128\n",
      "train loss:0.0002875591959416934\n",
      "train loss:0.00019504366481823868\n",
      "train loss:7.155535493720214e-05\n",
      "train loss:0.0001354417373013458\n",
      "train loss:0.00012892792493259333\n",
      "train loss:0.031168474013666566\n",
      "train loss:0.00047648814916303653\n",
      "train loss:0.000834154526889274\n",
      "train loss:5.1677647055903277e-05\n",
      "train loss:0.0004591611306182066\n",
      "train loss:0.0009251508524826274\n",
      "train loss:0.0007002400031849209\n",
      "train loss:0.0011856925790829779\n",
      "train loss:0.00031880330185467097\n",
      "train loss:0.0010386003858786023\n",
      "train loss:3.283421148836351e-05\n",
      "train loss:0.0010583437230134859\n",
      "train loss:0.0005264339767051513\n",
      "train loss:0.0036544220190321075\n",
      "train loss:5.72849814733938e-05\n",
      "train loss:4.4591192999567764e-05\n",
      "train loss:0.000566565245833825\n",
      "train loss:0.000472730763300182\n",
      "train loss:0.0005637075068640757\n",
      "train loss:0.0009834155351436929\n",
      "train loss:6.17832990278194e-05\n",
      "train loss:0.00048077666628797426\n",
      "train loss:0.0002051570484640519\n",
      "train loss:0.0001731651810128829\n",
      "train loss:2.100106539473286e-05\n",
      "train loss:0.0015374788568188042\n",
      "train loss:0.00045192409835216336\n",
      "train loss:4.8125664805590783e-05\n",
      "train loss:0.00016410736704196408\n",
      "train loss:0.00019887711066766706\n",
      "train loss:4.1512081659808274e-05\n",
      "train loss:0.0013220410599486788\n",
      "train loss:5.872150973024362e-05\n",
      "train loss:0.0031478806396336516\n",
      "train loss:0.00034548241820394265\n",
      "train loss:0.0008706886790693807\n",
      "train loss:0.0007504617132402431\n",
      "train loss:0.0005451435030036267\n",
      "train loss:0.0011255317533346485\n",
      "train loss:0.00046361652555763753\n",
      "train loss:4.8945712304394436e-05\n",
      "train loss:0.0005627571441122324\n",
      "train loss:0.0012282867982080148\n",
      "train loss:0.0002609987916463559\n",
      "train loss:0.0010692206821581185\n",
      "train loss:0.001212976521930101\n",
      "train loss:0.00025500898661448795\n",
      "train loss:1.5988099785454286e-05\n",
      "train loss:0.00030746782476478594\n",
      "train loss:0.000318993840656827\n",
      "train loss:0.0024922693708553465\n",
      "train loss:8.79798497565074e-05\n",
      "train loss:0.0014322242708840463\n",
      "train loss:2.7698375530604055e-05\n",
      "train loss:0.0003158368411963456\n",
      "train loss:6.821947886488152e-05\n",
      "train loss:0.0002452843318881071\n",
      "train loss:0.00034627658748772065\n",
      "train loss:9.702615917391594e-05\n",
      "train loss:0.00016058738580617836\n",
      "train loss:0.00020026135939690972\n",
      "train loss:2.4040476334838056e-05\n",
      "train loss:4.674170011272899e-05\n",
      "train loss:0.00011130970896412019\n",
      "train loss:0.0017113342926763592\n",
      "train loss:0.00028417225361009176\n",
      "train loss:0.00013763233295483165\n",
      "train loss:0.0003959896676638105\n",
      "train loss:0.0012240467023124175\n",
      "train loss:0.0003524476292171873\n",
      "train loss:6.228035847419132e-05\n",
      "train loss:9.841128495800427e-05\n",
      "train loss:0.00030829763940578637\n",
      "train loss:0.00039192019471088915\n",
      "train loss:4.8526642457806955e-05\n",
      "train loss:0.0009923737366857104\n",
      "train loss:7.722543290596363e-05\n",
      "train loss:0.00019598648101195438\n",
      "train loss:2.365851036687559e-05\n",
      "train loss:0.002764295644555815\n",
      "train loss:0.0002804055972461023\n",
      "train loss:0.00012113508347342815\n",
      "train loss:0.0007589334669870978\n",
      "train loss:0.0008031451325567474\n",
      "train loss:8.912606507370627e-05\n",
      "train loss:0.0004610880720737943\n",
      "train loss:1.9978046596092826e-05\n",
      "train loss:0.03067206891132861\n",
      "train loss:0.00032872469758657354\n",
      "train loss:2.072138663531727e-05\n",
      "train loss:0.00019396696492026585\n",
      "train loss:0.00018347455885273472\n",
      "train loss:7.23272382158684e-05\n",
      "train loss:0.0001307757701748279\n",
      "train loss:0.0013401888721129808\n",
      "train loss:0.0025461429370634402\n",
      "train loss:0.000361230189072795\n",
      "train loss:0.00023369350856197187\n",
      "train loss:3.701551853712651e-05\n",
      "train loss:7.267633689530501e-05\n",
      "train loss:0.0007485502351818493\n",
      "train loss:7.007658587091325e-05\n",
      "train loss:0.001001051719150179\n",
      "train loss:0.0009161540735785846\n",
      "train loss:0.0023100323824571172\n",
      "train loss:0.0006966456629487809\n",
      "train loss:0.0002815276701495135\n",
      "train loss:0.0008045348244555598\n",
      "train loss:0.0010522227476259056\n",
      "train loss:0.0002597500566051887\n",
      "train loss:0.0005716621223923142\n",
      "train loss:0.0013891368463015696\n",
      "train loss:0.0005390186690823254\n",
      "train loss:0.0008024178310524859\n",
      "train loss:0.00011860858593812953\n",
      "train loss:0.00020361626380595744\n",
      "train loss:0.0009408933275383135\n",
      "train loss:6.402701981791535e-05\n",
      "train loss:0.00025976993976410266\n",
      "train loss:4.055740125409909e-05\n",
      "train loss:0.00029946373608739777\n",
      "train loss:0.00045388429734276835\n",
      "train loss:9.468864403538985e-05\n",
      "train loss:9.910344672500645e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0003730730296076567\n",
      "train loss:0.0002600376421002299\n",
      "train loss:7.988761871535303e-05\n",
      "train loss:0.0010707998436730857\n",
      "train loss:0.0026768935267909464\n",
      "train loss:0.0007484289091156771\n",
      "train loss:0.00011332347649902493\n",
      "train loss:0.00030851120632675866\n",
      "train loss:0.0002883647363082538\n",
      "train loss:0.003758838628614128\n",
      "train loss:0.00324345024872703\n",
      "train loss:0.0007527718884544032\n",
      "train loss:0.0006384140539292521\n",
      "train loss:0.0008598325502981449\n",
      "train loss:0.0010226431495818594\n",
      "train loss:3.5691919507885544e-05\n",
      "train loss:0.003964786898319672\n",
      "train loss:0.0003757140781021209\n",
      "train loss:3.370347811425858e-05\n",
      "train loss:0.00023540082448835105\n",
      "train loss:0.000422721061836772\n",
      "train loss:0.0004329243014942514\n",
      "train loss:0.016618322706186992\n",
      "train loss:0.00017628254665490346\n",
      "train loss:0.0005182111847152209\n",
      "train loss:0.00020186801220922654\n",
      "train loss:0.00012831143889448302\n",
      "train loss:0.0010102466177495288\n",
      "train loss:0.0016850148759792443\n",
      "train loss:0.0002856284329798314\n",
      "train loss:0.00035397805541020335\n",
      "train loss:0.00038718132623900045\n",
      "train loss:0.001225861837933106\n",
      "train loss:0.0055490926584322335\n",
      "train loss:0.0011517507996190006\n",
      "train loss:0.0008449542647017902\n",
      "train loss:0.002134215164394093\n",
      "train loss:0.00010692200794710024\n",
      "train loss:0.00178869533678215\n",
      "train loss:0.0004027932109836997\n",
      "train loss:0.00010142594980545805\n",
      "train loss:0.0004340799807189036\n",
      "train loss:0.0015223573928461057\n",
      "train loss:0.002411147049171558\n",
      "train loss:0.000286414163319673\n",
      "train loss:0.00036342017366793234\n",
      "train loss:0.0024383982580487244\n",
      "train loss:0.0019417777983857661\n",
      "train loss:0.00023367664477459845\n",
      "train loss:0.0010323667405950873\n",
      "train loss:0.0002133995149076152\n",
      "train loss:0.0013776405234327996\n",
      "train loss:0.000282233759325674\n",
      "train loss:0.00038979115013793774\n",
      "train loss:0.0011107847232056682\n",
      "train loss:0.00011068301301698778\n",
      "train loss:0.0015213398233112044\n",
      "train loss:0.0014917323449451269\n",
      "train loss:3.205950180650559e-05\n",
      "train loss:0.0027253245524528954\n",
      "train loss:0.00013046707556954446\n",
      "train loss:0.00046675327380930464\n",
      "train loss:0.00017324581414677342\n",
      "train loss:4.457837285903957e-05\n",
      "train loss:0.0032848013611479466\n",
      "train loss:0.0010464764134431293\n",
      "train loss:0.0001031116678051109\n",
      "train loss:0.001241255554249226\n",
      "train loss:0.006312533732581203\n",
      "train loss:0.0002858111014870586\n",
      "train loss:0.0010562330697191878\n",
      "train loss:0.0005174448753255995\n",
      "train loss:0.0005944884759504991\n",
      "train loss:5.573937757182148e-05\n",
      "train loss:0.0008371708014143848\n",
      "train loss:5.2251067946249164e-05\n",
      "train loss:0.0006515021018625669\n",
      "train loss:0.0007755591782584842\n",
      "train loss:0.004794953500685214\n",
      "train loss:0.00020370851864450452\n",
      "train loss:0.004008360859839563\n",
      "train loss:0.0007102395099245733\n",
      "train loss:0.0007567120628507612\n",
      "train loss:0.00020624989172271488\n",
      "train loss:0.0007676763898936783\n",
      "train loss:0.0005485128837572985\n",
      "train loss:0.00014072639516382165\n",
      "train loss:5.982560319269998e-05\n",
      "train loss:0.0012189251214977908\n",
      "train loss:0.0012945153319627739\n",
      "train loss:0.00023256270383485158\n",
      "train loss:0.0028136316873086315\n",
      "train loss:0.0114239586143924\n",
      "train loss:0.0021028281352706035\n",
      "train loss:1.5092796611336963e-05\n",
      "train loss:5.909722766281194e-05\n",
      "train loss:0.00014758007218477096\n",
      "train loss:0.0002377059353405922\n",
      "train loss:0.00023815804618744445\n",
      "train loss:0.00018056700419001817\n",
      "train loss:2.640143407564936e-06\n",
      "train loss:0.0005832761084517885\n",
      "train loss:0.0012916124637258016\n",
      "train loss:0.0003232266459690207\n",
      "train loss:0.0009457086948340103\n",
      "train loss:0.0002773044792398142\n",
      "train loss:0.00010557942366506779\n",
      "train loss:0.0015095028853220856\n",
      "train loss:4.5557312368430084e-05\n",
      "train loss:0.00034222038132324784\n",
      "train loss:0.00547519877171851\n",
      "train loss:0.0009021712014614597\n",
      "train loss:0.00017536417640009598\n",
      "train loss:0.000852457647137885\n",
      "train loss:0.00040123488598167804\n",
      "train loss:0.001683041454084987\n",
      "train loss:0.0016770872433285358\n",
      "train loss:0.002689977164197568\n",
      "train loss:0.0010411125246705304\n",
      "train loss:0.008702576629378754\n",
      "train loss:0.0007413675307564223\n",
      "train loss:0.0008118485689297441\n",
      "train loss:0.005273426520015178\n",
      "train loss:0.000892433626983461\n",
      "train loss:0.00030491638395843435\n",
      "train loss:0.0012425844954204086\n",
      "train loss:0.00030750030396265674\n",
      "train loss:0.0009845975253613185\n",
      "train loss:0.00017877608373591912\n",
      "train loss:0.0007812557139609691\n",
      "train loss:0.0007961115034299412\n",
      "train loss:0.0003943773370278157\n",
      "train loss:0.0007484378630530702\n",
      "train loss:0.00010772478345247744\n",
      "train loss:0.0012063265719280002\n",
      "train loss:0.002482717964301999\n",
      "train loss:0.00022509499280820973\n",
      "train loss:0.008918133485944498\n",
      "train loss:8.326590612415231e-05\n",
      "train loss:0.0017324270782341402\n",
      "train loss:0.00033615409089799466\n",
      "train loss:0.0005066839830573124\n",
      "train loss:0.00015932975284511895\n",
      "train loss:0.0007721005045325193\n",
      "train loss:0.0009974945943510625\n",
      "train loss:0.004261544600480865\n",
      "train loss:0.0024957413897571477\n",
      "train loss:0.001288157081674088\n",
      "train loss:0.0009157616124512237\n",
      "train loss:0.001068466132151027\n",
      "train loss:0.0003400223653138148\n",
      "train loss:0.002892152044676541\n",
      "train loss:0.0028741542322680575\n",
      "train loss:0.0002211171925571545\n",
      "train loss:0.0002564636045657481\n",
      "train loss:6.48344605341281e-05\n",
      "train loss:0.00039737675883802037\n",
      "train loss:0.0008118079812000163\n",
      "train loss:0.007341987558822299\n",
      "train loss:0.0005216046776074907\n",
      "train loss:0.0033114088973691634\n",
      "train loss:0.0044848793792256585\n",
      "train loss:0.00036910004561745586\n",
      "train loss:4.286812092432447e-05\n",
      "train loss:0.0013394073957601197\n",
      "train loss:0.000518873565799377\n",
      "train loss:0.0006269411672743679\n",
      "train loss:0.0013378714674645614\n",
      "train loss:0.0006443161704533147\n",
      "train loss:0.00011018522360332539\n",
      "train loss:0.001713844737344614\n",
      "train loss:0.0002667538728684403\n",
      "train loss:0.0019958362733257158\n",
      "train loss:0.0035092862863333714\n",
      "train loss:0.0019949901997510476\n",
      "train loss:0.009153153547889955\n",
      "train loss:0.0011959813267434774\n",
      "train loss:0.00018522355636875108\n",
      "train loss:0.00047235045418523024\n",
      "train loss:0.00044340941895561626\n",
      "train loss:0.0006111745297875778\n",
      "train loss:0.001184522372266888\n",
      "train loss:0.0015880040395197248\n",
      "train loss:1.654170001715111e-05\n",
      "train loss:0.0014055537329532434\n",
      "train loss:0.02611654069169076\n",
      "train loss:0.00590803714558361\n",
      "train loss:0.0005915298412070743\n",
      "train loss:0.0005063770107764324\n",
      "train loss:0.0016077744586577162\n",
      "train loss:0.0013891721987423539\n",
      "train loss:0.002365139849053383\n",
      "train loss:0.0047540233785667045\n",
      "train loss:0.0007464647886107443\n",
      "train loss:0.0007319945397583958\n",
      "train loss:0.020597410195080074\n",
      "train loss:0.0006182960530559157\n",
      "train loss:0.0033186809794818724\n",
      "train loss:0.0005860116475457296\n",
      "train loss:0.0006814837713287202\n",
      "train loss:4.041199996140782e-05\n",
      "train loss:3.642689180160411e-05\n",
      "train loss:0.0018049781909830513\n",
      "train loss:2.4442189731844054e-05\n",
      "train loss:0.0033718418303238682\n",
      "train loss:0.0018271797009056126\n",
      "train loss:0.003047291568492777\n",
      "train loss:0.027362902583574707\n",
      "train loss:0.0003681977985290952\n",
      "train loss:0.02007306374135469\n",
      "train loss:0.003236991732983351\n",
      "train loss:0.00118268442793789\n",
      "train loss:0.0002754419501511144\n",
      "train loss:0.001285931559731281\n",
      "train loss:0.013884002305607284\n",
      "train loss:0.0013768581169595565\n",
      "train loss:0.0006739268168078136\n",
      "train loss:0.00033284730902198876\n",
      "train loss:0.00022931538526472334\n",
      "train loss:0.0005966903471179924\n",
      "train loss:0.0028900987446274593\n",
      "train loss:0.003150989400410301\n",
      "train loss:0.0007045986033997787\n",
      "train loss:0.020590457457720767\n",
      "train loss:0.0002482034335422126\n",
      "train loss:2.0504478763907112e-05\n",
      "train loss:0.0013987802630307045\n",
      "train loss:0.0006052158477413554\n",
      "train loss:0.0005854999569235714\n",
      "train loss:0.02335731343060221\n",
      "train loss:7.164735940269525e-05\n",
      "train loss:0.0013760907795840704\n",
      "train loss:0.0033883697541197614\n",
      "train loss:0.000887819177569372\n",
      "train loss:0.0038685971184734226\n",
      "train loss:0.0003853889275186582\n",
      "train loss:0.001536666936092674\n",
      "train loss:0.0007766076540676747\n",
      "train loss:0.00027660353669205944\n",
      "train loss:0.000517899094477162\n",
      "train loss:0.000845261830410221\n",
      "train loss:0.0007268256733815663\n",
      "train loss:0.001555644040368971\n",
      "train loss:8.154383636646357e-05\n",
      "train loss:0.02115772369425344\n",
      "train loss:0.00013793501544613328\n",
      "train loss:0.004685610688442586\n",
      "train loss:0.0015354950022313152\n",
      "train loss:0.0010293133912834085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0007797545748280037\n",
      "train loss:0.0012502714985267505\n",
      "train loss:0.0033431622917637336\n",
      "train loss:0.001119013945551124\n",
      "train loss:0.0038360630822426058\n",
      "train loss:0.0022863878830968317\n",
      "train loss:0.0002905970997084266\n",
      "train loss:0.00034866938224343836\n",
      "train loss:0.0014846743032608787\n",
      "train loss:0.011037996062938817\n",
      "train loss:0.0012614621942001023\n",
      "train loss:0.0011743921340915823\n",
      "train loss:0.0002778748640821019\n",
      "train loss:0.0012706972374559122\n",
      "train loss:0.0013482594810178513\n",
      "train loss:0.00035898678287973445\n",
      "train loss:0.0001169782040742719\n",
      "train loss:0.011383159308822064\n",
      "train loss:0.0016277274845695475\n",
      "train loss:9.372971590373485e-05\n",
      "train loss:0.0011272836252448674\n",
      "train loss:0.0010886306735411171\n",
      "train loss:0.003199398800324166\n",
      "train loss:0.00017658275005047038\n",
      "train loss:0.0004281279762447608\n",
      "train loss:0.002262690801432347\n",
      "train loss:6.273122639756971e-05\n",
      "train loss:0.0002170107841588621\n",
      "train loss:0.003567014518008958\n",
      "train loss:0.0011209294594776264\n",
      "train loss:0.0012880751819494907\n",
      "train loss:0.0013330965798213578\n",
      "train loss:0.0004286800606531379\n",
      "train loss:0.0013257984488281613\n",
      "train loss:0.0009489367662352155\n",
      "train loss:0.0006822224381264882\n",
      "train loss:0.0021002431056211957\n",
      "train loss:0.04672167182472504\n",
      "train loss:6.737546698605804e-05\n",
      "train loss:0.0016883417411311236\n",
      "train loss:0.0002868847244863501\n",
      "train loss:0.00017803473171228544\n",
      "train loss:0.000851358207614322\n",
      "train loss:0.0015310568661589866\n",
      "train loss:0.00302263308246472\n",
      "train loss:0.0002498875852709754\n",
      "train loss:0.0001938712170298804\n",
      "train loss:0.000466123886087603\n",
      "train loss:2.2278683856107283e-05\n",
      "train loss:0.0001264269182703766\n",
      "train loss:0.001211181627564053\n",
      "train loss:0.00033906724360900626\n",
      "train loss:0.0003416518534880196\n",
      "train loss:0.00047687348215128087\n",
      "train loss:0.0011339678227724013\n",
      "train loss:6.857373329060309e-06\n",
      "train loss:0.00943502482764585\n",
      "train loss:0.0013112864974550533\n",
      "train loss:0.0003523842263456168\n",
      "train loss:0.0004762118386838284\n",
      "train loss:0.0011973796837495474\n",
      "train loss:0.004985280657161902\n",
      "train loss:0.0020943206659547477\n",
      "train loss:0.0005356360529235206\n",
      "train loss:0.00436802621789013\n",
      "train loss:0.0028569819484611666\n",
      "train loss:0.00027983397658455086\n",
      "train loss:5.740867479655563e-05\n",
      "train loss:0.003415990660082345\n",
      "train loss:5.108457251412634e-05\n",
      "train loss:0.0001934901961574559\n",
      "train loss:9.406488604849515e-06\n",
      "train loss:0.0017332698494149437\n",
      "train loss:0.0006236733636713926\n",
      "train loss:0.00010077543347576097\n",
      "train loss:0.0016494775534715359\n",
      "train loss:0.0007975919670032215\n",
      "train loss:0.002666296863962519\n",
      "train loss:0.0022074191673133346\n",
      "train loss:0.00060586374706911\n",
      "train loss:0.0011308415911321793\n",
      "train loss:0.007730456326964797\n",
      "train loss:2.829756107157991e-05\n",
      "train loss:0.00010216120312156319\n",
      "train loss:0.00011081871675635142\n",
      "train loss:0.0002927704942236323\n",
      "train loss:5.001171261931058e-05\n",
      "train loss:0.010304711839327947\n",
      "train loss:0.00072551546328689\n",
      "train loss:0.0012673163661286822\n",
      "train loss:0.0007109124644451601\n",
      "train loss:0.0006904659331978263\n",
      "train loss:0.000250618836363623\n",
      "train loss:0.0015233131970062888\n",
      "train loss:3.0335176274304486e-05\n",
      "train loss:0.00022493433793444249\n",
      "train loss:0.0002256087050358191\n",
      "train loss:0.001550666021847049\n",
      "train loss:0.016945915855875616\n",
      "train loss:0.0011211569588551414\n",
      "train loss:0.00356742697059573\n",
      "train loss:0.0017783185311755724\n",
      "train loss:0.0009823370823163586\n",
      "train loss:0.0002968603418978085\n",
      "train loss:0.00015713148806156604\n",
      "train loss:0.001926333179204687\n",
      "train loss:0.0001623964680899534\n",
      "train loss:0.000532302224521137\n",
      "train loss:0.00016405555565844601\n",
      "train loss:0.002417785135955543\n",
      "train loss:0.00039262019834355566\n",
      "train loss:0.002457923468038175\n",
      "train loss:0.00025846871669638944\n",
      "train loss:6.755817420485641e-05\n",
      "train loss:0.0017675178360654817\n",
      "train loss:0.0011287034249793043\n",
      "train loss:0.00041993746872733413\n",
      "train loss:0.0010976972110150623\n",
      "train loss:0.0028888576272542276\n",
      "train loss:0.0010687505597101606\n",
      "train loss:0.0008431687642684126\n",
      "train loss:0.0006350304092295414\n",
      "train loss:0.00034670537656579937\n",
      "train loss:0.0030107541938434713\n",
      "train loss:0.00021026970953076093\n",
      "train loss:0.00012343221610841172\n",
      "train loss:0.00018461970164523452\n",
      "train loss:0.0036999362669373516\n",
      "train loss:0.0017600657044265864\n",
      "train loss:0.0002071908145480626\n",
      "train loss:0.003447467424762496\n",
      "train loss:0.00047970091027834094\n",
      "train loss:0.00024665186033253885\n",
      "train loss:0.0018706784093364395\n",
      "train loss:0.00039583712288022695\n",
      "train loss:0.007268513263885589\n",
      "train loss:0.003867817766830886\n",
      "train loss:0.0002658493714554549\n",
      "train loss:7.273964500762723e-05\n",
      "train loss:0.0015716980842649948\n",
      "train loss:0.0004292974437191789\n",
      "train loss:0.0002113428247662479\n",
      "train loss:0.013730137039296824\n",
      "train loss:0.0008146792863184918\n",
      "train loss:0.0016136274448589867\n",
      "train loss:0.001734162921102995\n",
      "train loss:0.0004618345835706257\n",
      "train loss:0.0012123953378334093\n",
      "train loss:0.00045384969855275984\n",
      "train loss:0.0022378793302221082\n",
      "train loss:0.000980081673197446\n",
      "train loss:0.0020599995205946024\n",
      "train loss:0.0008416626199491956\n",
      "train loss:0.000103204649972541\n",
      "train loss:0.0010763298859868711\n",
      "train loss:0.00015518343923010924\n",
      "train loss:0.0003657326539400207\n",
      "train loss:0.0018163995117328273\n",
      "train loss:3.755160076236621e-05\n",
      "train loss:0.0009687986329167313\n",
      "train loss:0.00011030855392168588\n",
      "train loss:0.00034056120072071427\n",
      "train loss:0.0009236124062589488\n",
      "train loss:9.478518958333931e-05\n",
      "train loss:0.0032951545723637885\n",
      "train loss:0.0006517609365011257\n",
      "=== epoch:20, train acc:1.0, test acc:0.989 ===\n",
      "train loss:0.0013724273344237678\n",
      "train loss:0.0006049909304813897\n",
      "train loss:0.00036393735491331027\n",
      "train loss:0.00011127807025271466\n",
      "train loss:0.0018601892539519477\n",
      "train loss:0.0011295385367172273\n",
      "train loss:0.0021626785910095047\n",
      "train loss:3.943642859460473e-05\n",
      "train loss:0.0003372187133682521\n",
      "train loss:0.0006419345510848858\n",
      "train loss:0.00030269202479137687\n",
      "train loss:6.136514818466101e-05\n",
      "train loss:0.0006200709277236164\n",
      "train loss:0.001153677507634829\n",
      "train loss:9.173400596008168e-05\n",
      "train loss:0.0007061246804546392\n",
      "train loss:0.0009297545232534801\n",
      "train loss:0.001881181225529176\n",
      "train loss:0.0004747079850209512\n",
      "train loss:0.0007337880092288287\n",
      "train loss:3.2103440011278404e-05\n",
      "train loss:0.00019507138739215625\n",
      "train loss:0.0020624144212818005\n",
      "train loss:0.00013414281043319645\n",
      "train loss:0.00020935859307012872\n",
      "train loss:3.1913858743853206e-05\n",
      "train loss:0.0025130397021398865\n",
      "train loss:0.0008982270037417706\n",
      "train loss:0.006636520791891683\n",
      "train loss:0.00047994044165870065\n",
      "train loss:6.667083501807774e-05\n",
      "train loss:3.445346579214926e-05\n",
      "train loss:0.002207470781940734\n",
      "train loss:8.65676710117411e-05\n",
      "train loss:0.0008553456331063593\n",
      "train loss:0.003225464146732028\n",
      "train loss:0.001150581182751704\n",
      "train loss:0.0003103836594106049\n",
      "train loss:0.0022962583463948167\n",
      "train loss:9.08238144616813e-05\n",
      "train loss:0.000330293999668741\n",
      "train loss:0.014590369889836974\n",
      "train loss:0.0017836256757556717\n",
      "train loss:0.008144935566270654\n",
      "train loss:0.00012868254086598047\n",
      "train loss:0.0007862506264266902\n",
      "train loss:0.00021494929315294807\n",
      "train loss:0.002894080906779997\n",
      "train loss:0.000374148518799522\n",
      "train loss:2.8677158461340102e-05\n",
      "train loss:0.004331805947125014\n",
      "train loss:0.0002466295942792877\n",
      "train loss:0.0002814979515835071\n",
      "train loss:0.001955264198214715\n",
      "train loss:0.004500663988660728\n",
      "train loss:0.0033222305984104807\n",
      "train loss:1.999249667229568e-05\n",
      "train loss:0.006239780430156037\n",
      "train loss:0.0002526693742556324\n",
      "train loss:0.0073335495357272715\n",
      "train loss:0.0005331268121144794\n",
      "train loss:0.0007765512042485996\n",
      "train loss:2.3865421260224274e-05\n",
      "train loss:2.3423571533409218e-05\n",
      "train loss:0.0004752594039620304\n",
      "train loss:0.00037083392216888964\n",
      "train loss:0.0002263099533740114\n",
      "train loss:0.004047785810672774\n",
      "train loss:0.0021371132268077327\n",
      "train loss:0.0027139786181279136\n",
      "train loss:0.002005896348252716\n",
      "train loss:0.00011858099282893725\n",
      "train loss:0.0015902231950614431\n",
      "train loss:2.4634609158327467e-05\n",
      "train loss:0.0018446813770437533\n",
      "train loss:0.0011800318247578512\n",
      "train loss:0.0002698497679289036\n",
      "train loss:0.002860638202122682\n",
      "train loss:0.0007748142402231724\n",
      "train loss:0.0009819555365738744\n",
      "train loss:0.0003126832935138466\n",
      "train loss:0.0003482930854081164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0006619430129896624\n",
      "train loss:1.1607463920121954e-05\n",
      "train loss:0.0002253502330032063\n",
      "train loss:0.00043749978233422284\n",
      "train loss:0.00013374806232842345\n",
      "train loss:0.00044021418860039146\n",
      "train loss:0.002445673385378673\n",
      "train loss:0.0010955826092664848\n",
      "train loss:0.0003516629978913557\n",
      "train loss:9.380819077960431e-05\n",
      "train loss:0.0013985610802306448\n",
      "train loss:0.003828304566068964\n",
      "train loss:0.00012273245100881115\n",
      "train loss:4.1758634319820725e-05\n",
      "train loss:0.00028808681633305097\n",
      "train loss:0.0022312258632343073\n",
      "train loss:0.001894590340350574\n",
      "train loss:0.001731662836380145\n",
      "train loss:6.654201277946962e-05\n",
      "train loss:0.0005366953541080412\n",
      "train loss:0.00027719130027202224\n",
      "train loss:0.001699612620910283\n",
      "train loss:0.0005828914806847809\n",
      "train loss:0.001115713181097375\n",
      "train loss:0.0018234103520367237\n",
      "train loss:0.0029834150448586243\n",
      "train loss:0.00041640053246821366\n",
      "train loss:0.0014363889169886907\n",
      "train loss:0.0007106527669021536\n",
      "train loss:2.4352140449929617e-05\n",
      "train loss:0.0003074117571282666\n",
      "train loss:0.0014893896900200268\n",
      "train loss:0.01030542034743926\n",
      "train loss:0.0003642613471808046\n",
      "train loss:0.0006332009312814431\n",
      "train loss:0.0006885882997364684\n",
      "train loss:0.0002465275988201213\n",
      "train loss:0.00016541223614964106\n",
      "train loss:0.0001509315868714689\n",
      "train loss:4.724084790820461e-05\n",
      "train loss:8.348949814450178e-05\n",
      "train loss:0.0006690158109857641\n",
      "train loss:3.637897832481029e-05\n",
      "train loss:0.00020062745909158456\n",
      "train loss:0.0031060508164066827\n",
      "train loss:0.0043678153862983125\n",
      "train loss:0.0011911429301172804\n",
      "train loss:0.00037999057500346186\n",
      "train loss:0.010889168977826555\n",
      "train loss:0.00016720085235738484\n",
      "train loss:0.0008030989900385603\n",
      "train loss:0.00030251550944676006\n",
      "train loss:0.001363344756385653\n",
      "train loss:0.0009472931975471242\n",
      "train loss:0.0038790936225939943\n",
      "train loss:0.00020191504078436094\n",
      "train loss:0.00014364993390782708\n",
      "train loss:4.585341685729843e-05\n",
      "train loss:0.0008470202642750072\n",
      "train loss:0.008269377468136094\n",
      "train loss:1.2180305733242963e-05\n",
      "train loss:0.0003536946618774317\n",
      "train loss:0.000943471312580385\n",
      "train loss:0.00033874949188801047\n",
      "train loss:0.0009710503673349964\n",
      "train loss:0.0003774692902233797\n",
      "train loss:0.0002593484062758141\n",
      "train loss:0.0008209364737009167\n",
      "train loss:0.0007107309911380391\n",
      "train loss:0.0019947338218508064\n",
      "train loss:6.395139337756648e-05\n",
      "train loss:8.920701053719753e-05\n",
      "train loss:0.0028568417831676446\n",
      "train loss:0.0015075179255396385\n",
      "train loss:0.010310772710136543\n",
      "train loss:0.000388080527404895\n",
      "train loss:5.4252688561048966e-05\n",
      "train loss:9.353805744057055e-05\n",
      "train loss:0.003361169887544997\n",
      "train loss:0.007304358938469616\n",
      "train loss:0.006635546355419683\n",
      "train loss:0.0005509496276374419\n",
      "train loss:0.006023327243185538\n",
      "train loss:0.004274783588777128\n",
      "train loss:0.00015517502972228783\n",
      "train loss:0.00016840371302293274\n",
      "train loss:0.0009827465536671718\n",
      "train loss:0.0013878056790840247\n",
      "train loss:5.49005051107728e-05\n",
      "train loss:0.0011490845255279405\n",
      "train loss:0.0005186174249926615\n",
      "train loss:0.0010276559199939063\n",
      "train loss:0.00325507675797246\n",
      "train loss:0.018964886131033795\n",
      "train loss:0.000920033574662191\n",
      "train loss:0.0077745055462986\n",
      "train loss:0.00019649994141661745\n",
      "train loss:0.0009692487028268438\n",
      "train loss:0.0009804625792137465\n",
      "train loss:0.0002683203206328876\n",
      "train loss:0.00101159951368054\n",
      "train loss:0.00023294860262621167\n",
      "train loss:0.00047221737862183276\n",
      "train loss:0.0007113994282383866\n",
      "train loss:0.0001908829021083617\n",
      "train loss:0.0002575257418931425\n",
      "train loss:0.0007153261362775631\n",
      "train loss:0.00012815035463341988\n",
      "train loss:0.0017275571451090851\n",
      "train loss:0.0008645893339119526\n",
      "train loss:0.0004800056251378959\n",
      "train loss:0.001959590081446312\n",
      "train loss:0.0003049038905631718\n",
      "train loss:0.011918156819725294\n",
      "train loss:0.003350590147934997\n",
      "train loss:0.0003974562015615543\n",
      "train loss:0.0016450128645961945\n",
      "train loss:0.0005225058707197094\n",
      "train loss:0.00013961543845469068\n",
      "train loss:0.0003771087746505325\n",
      "train loss:0.001880455980476672\n",
      "train loss:0.001604171684572871\n",
      "train loss:0.0029501969139732738\n",
      "train loss:0.0011508180931918785\n",
      "train loss:0.003217778659281974\n",
      "train loss:0.0020257520201920278\n",
      "train loss:6.784139048846608e-05\n",
      "train loss:0.0002318888944977528\n",
      "train loss:0.0006965844596186437\n",
      "train loss:0.0001319439214683117\n",
      "train loss:7.382588681091342e-05\n",
      "train loss:0.0025802470875090854\n",
      "train loss:0.002856689268246347\n",
      "train loss:0.0007357460580166608\n",
      "train loss:0.00021476392600579288\n",
      "train loss:0.0003556434278000472\n",
      "train loss:0.0005194133150835488\n",
      "train loss:0.0027431847365888703\n",
      "train loss:0.00238040159756303\n",
      "train loss:0.00022698194290134317\n",
      "train loss:0.0003324676314801829\n",
      "train loss:0.0016648118088149302\n",
      "train loss:0.002673458423928226\n",
      "train loss:0.00017139350979859447\n",
      "train loss:0.001228365423088676\n",
      "train loss:0.0017125952594876667\n",
      "train loss:0.0004590262114095784\n",
      "train loss:0.0006713284978167007\n",
      "train loss:0.0006586203810881587\n",
      "train loss:0.00021570312012893916\n",
      "train loss:0.0004687426198655848\n",
      "train loss:0.017052339959048025\n",
      "train loss:0.0005805382806677849\n",
      "train loss:3.289948292554635e-05\n",
      "train loss:0.00011970562348573658\n",
      "train loss:0.0007482282997329286\n",
      "train loss:0.00014088643139023411\n",
      "train loss:0.0007280927592234274\n",
      "train loss:7.63847955344999e-05\n",
      "train loss:0.00023844593986314456\n",
      "train loss:0.00027931164408793557\n",
      "train loss:0.005038618564743283\n",
      "train loss:0.004237356851951976\n",
      "train loss:0.003366697597469379\n",
      "train loss:7.330649489741815e-05\n",
      "train loss:0.0009479699939214402\n",
      "train loss:0.00022639034409757406\n",
      "train loss:0.0005160666965003511\n",
      "train loss:0.0006103490120383497\n",
      "train loss:0.004767482692628911\n",
      "train loss:0.0009255174505683984\n",
      "train loss:0.08336482383665399\n",
      "train loss:0.0004252160953583733\n",
      "train loss:0.0011495487919849492\n",
      "train loss:0.002353414030857328\n",
      "train loss:2.99067018778298e-05\n",
      "train loss:0.001183353619290553\n",
      "train loss:0.0005950194390495386\n",
      "train loss:0.0005799686496736093\n",
      "train loss:0.002291433634946613\n",
      "train loss:0.00014561053770447395\n",
      "train loss:0.009085510363617088\n",
      "train loss:0.0008824539427815245\n",
      "train loss:0.0015535732713869098\n",
      "train loss:0.00027669643796730424\n",
      "train loss:0.002525528556157777\n",
      "train loss:0.0007257054056470523\n",
      "train loss:0.0004985703730720005\n",
      "train loss:0.0001777371094836271\n",
      "train loss:0.001832568671520411\n",
      "train loss:0.0009404518813079889\n",
      "train loss:0.001360399299496578\n",
      "train loss:0.00032910610700483497\n",
      "train loss:0.0001039114118923184\n",
      "train loss:3.3905564502277464e-05\n",
      "train loss:6.868212119236802e-05\n",
      "train loss:0.0007964249720103745\n",
      "train loss:0.0036626772981783683\n",
      "train loss:0.00022073118253304036\n",
      "train loss:0.00027998528527382676\n",
      "train loss:0.0007405080668239866\n",
      "train loss:0.0006607624394386092\n",
      "train loss:0.0009426199311937348\n",
      "train loss:0.0013322673402255914\n",
      "train loss:0.00013588031652629355\n",
      "train loss:0.0004461166129019396\n",
      "train loss:0.0017186596224964073\n",
      "train loss:0.0017644438829990015\n",
      "train loss:0.002247009119371067\n",
      "train loss:8.910229864292396e-05\n",
      "train loss:0.012243879846293765\n",
      "train loss:0.00043664179348138523\n",
      "train loss:0.0002734781485364956\n",
      "train loss:0.005163128499044441\n",
      "train loss:0.0005734987690186863\n",
      "train loss:9.080381294517998e-05\n",
      "train loss:0.00025934012651622913\n",
      "train loss:0.00011521216222548133\n",
      "train loss:0.0036696317086897094\n",
      "train loss:0.00022961608584059318\n",
      "train loss:0.0009095596514124094\n",
      "train loss:0.003268594155577193\n",
      "train loss:0.0009509146132393955\n",
      "train loss:0.0018336057694606559\n",
      "train loss:5.9049567909437863e-05\n",
      "train loss:2.3278238285751675e-05\n",
      "train loss:0.003023620167671671\n",
      "train loss:0.0009806078025492012\n",
      "train loss:0.003850097968932971\n",
      "train loss:0.0018173629342355562\n",
      "train loss:0.0010649679268887628\n",
      "train loss:0.0002386792561105084\n",
      "train loss:0.0007245762038027902\n",
      "train loss:0.002381996323292585\n",
      "train loss:0.002642450239442456\n",
      "train loss:0.0003851463271999033\n",
      "train loss:0.0006052246325300301\n",
      "train loss:0.0009937953490528248\n",
      "train loss:0.0007893867238611154\n",
      "train loss:0.0002362605425023509\n",
      "train loss:0.005004565967789082\n",
      "train loss:0.002616935363686892\n",
      "train loss:0.0006543464101703346\n",
      "train loss:0.0006983425194603514\n",
      "train loss:0.0006340150477557098\n",
      "train loss:0.0012035890983770892\n",
      "train loss:0.002233291804465904\n",
      "train loss:0.0012744241432508729\n",
      "train loss:0.002476192000055999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.008734011998577073\n",
      "train loss:0.0009999975661750696\n",
      "train loss:0.00053409178825736\n",
      "train loss:0.00019660879290028007\n",
      "train loss:0.0009239618232368948\n",
      "train loss:0.0020228626135642726\n",
      "train loss:0.0007318112968451329\n",
      "train loss:0.002013205545305607\n",
      "train loss:0.0003025997818492139\n",
      "train loss:0.004281309048009575\n",
      "train loss:0.0014110412519622432\n",
      "train loss:0.00476788449907086\n",
      "train loss:5.929571941224615e-05\n",
      "train loss:0.00022875735124145067\n",
      "train loss:0.003767892145500012\n",
      "train loss:0.0005192483994047308\n",
      "train loss:0.00038991147277217487\n",
      "train loss:0.00027739510225804144\n",
      "train loss:0.0011830303578033853\n",
      "train loss:0.0005327109043335558\n",
      "train loss:0.00014508769434331336\n",
      "train loss:7.767521581841699e-05\n",
      "train loss:0.0003741530547303359\n",
      "train loss:0.001874196279952803\n",
      "train loss:0.0004369121254572473\n",
      "train loss:0.001907426909475554\n",
      "train loss:0.000488507864108249\n",
      "train loss:0.0014303495672937899\n",
      "train loss:0.0015850727253963776\n",
      "train loss:0.0023689211108439516\n",
      "train loss:3.599613299873973e-05\n",
      "train loss:0.0034383426408757783\n",
      "train loss:0.0004141836322066897\n",
      "train loss:0.0005664224427186344\n",
      "train loss:0.0003381770970953528\n",
      "train loss:0.036214503122181586\n",
      "train loss:0.0002935518523179239\n",
      "train loss:0.0007628282062818884\n",
      "train loss:0.0003533826365196772\n",
      "train loss:0.0056794704010517\n",
      "train loss:0.002645847686167047\n",
      "train loss:0.0002063272591658575\n",
      "train loss:0.00344291557952628\n",
      "train loss:0.0013329266976563991\n",
      "train loss:0.03575586948943519\n",
      "train loss:0.0022650563553410817\n",
      "train loss:0.0012668489125908964\n",
      "train loss:0.00016926648610441668\n",
      "train loss:0.00022648767831149477\n",
      "train loss:0.00016327726429458684\n",
      "train loss:0.0038855940985627947\n",
      "train loss:0.0009327066761244411\n",
      "train loss:0.0018365875825156485\n",
      "train loss:0.0006471520125329122\n",
      "train loss:0.004460592331953602\n",
      "train loss:0.0008415972241709723\n",
      "train loss:0.0003202187650834857\n",
      "train loss:0.003958018772063562\n",
      "train loss:0.0003262449274022359\n",
      "train loss:3.5952082655246685e-05\n",
      "train loss:0.0015375893492380374\n",
      "train loss:8.913158329316748e-05\n",
      "train loss:0.004894317777268877\n",
      "train loss:0.0031393960002238956\n",
      "train loss:0.005158201113877773\n",
      "train loss:0.0018708346742980113\n",
      "train loss:0.00035819591955096213\n",
      "train loss:0.0035308498983501065\n",
      "train loss:0.002610607910179214\n",
      "train loss:0.00036193567579670546\n",
      "train loss:0.0001548151753251879\n",
      "train loss:0.0016101225304971636\n",
      "train loss:0.0020219652347408528\n",
      "train loss:0.013711830305167944\n",
      "train loss:8.586247172157875e-05\n",
      "train loss:0.004008619477815114\n",
      "train loss:0.004080117578635134\n",
      "train loss:0.0011372408551071954\n",
      "train loss:0.0007536858580074444\n",
      "train loss:0.00020833133578250688\n",
      "train loss:0.0023838578923323465\n",
      "train loss:0.0013211282217148901\n",
      "train loss:0.007058709902386563\n",
      "train loss:0.0003500760255169559\n",
      "train loss:0.0003640791038614559\n",
      "train loss:2.7816027526518963e-05\n",
      "train loss:0.0006328559764078963\n",
      "train loss:0.000374127665276636\n",
      "train loss:0.001460752231995585\n",
      "train loss:0.0006902451743954931\n",
      "train loss:0.00029908246166014647\n",
      "train loss:0.0038476134435052457\n",
      "train loss:0.0002485936816829362\n",
      "train loss:0.00020255438147667734\n",
      "train loss:0.0007161814507588757\n",
      "train loss:0.0003844555032935624\n",
      "train loss:3.601461376783401e-05\n",
      "train loss:0.002647500853649848\n",
      "train loss:0.0008174364529997071\n",
      "train loss:0.001406836984796424\n",
      "train loss:0.002503327570025255\n",
      "train loss:0.00010456473880774682\n",
      "train loss:0.0003059449326966591\n",
      "train loss:0.0014146189820525388\n",
      "train loss:0.0009442040245199769\n",
      "train loss:0.0017890758056114328\n",
      "train loss:0.00014452257541960428\n",
      "train loss:0.000507181937251739\n",
      "train loss:0.0028100793916640276\n",
      "train loss:0.0001617313567049102\n",
      "train loss:0.0014141136262808662\n",
      "train loss:0.0010647864212440438\n",
      "train loss:0.0001717808950397511\n",
      "train loss:0.005503818125945303\n",
      "train loss:0.0007347356804076979\n",
      "train loss:0.0028113400975580457\n",
      "train loss:0.0009451613423891774\n",
      "train loss:0.0035137334463616406\n",
      "train loss:0.005428848659584975\n",
      "train loss:3.5972957920156046e-05\n",
      "train loss:0.0006164452115824673\n",
      "train loss:0.004484211613153366\n",
      "train loss:0.0007279599632699161\n",
      "train loss:0.00019213390071469156\n",
      "train loss:0.0014716647791500218\n",
      "train loss:0.0001232652240790429\n",
      "train loss:0.0014891770080778099\n",
      "train loss:0.0013152730760285878\n",
      "train loss:0.00015473495534294024\n",
      "train loss:0.0019043089821753148\n",
      "train loss:0.018167396142023905\n",
      "train loss:0.0007408912611417905\n",
      "train loss:0.019497653505672695\n",
      "train loss:2.206353231044933e-05\n",
      "train loss:0.00020138670226220123\n",
      "train loss:0.0008475394004423719\n",
      "train loss:0.0008360553309489844\n",
      "train loss:0.00011948008823712303\n",
      "train loss:0.001699926053968959\n",
      "train loss:0.003083941963471043\n",
      "train loss:0.001136040723527424\n",
      "train loss:0.0047070324168341\n",
      "train loss:0.0001312878029011965\n",
      "train loss:0.00011328535458850177\n",
      "train loss:0.0022122436270937324\n",
      "train loss:0.0011847920893272531\n",
      "train loss:0.0012861242761574758\n",
      "train loss:0.0016804579975893707\n",
      "train loss:0.0065145689329525755\n",
      "train loss:0.008759348948374674\n",
      "train loss:0.01775094469000921\n",
      "train loss:0.004477450893873776\n",
      "train loss:0.0025118069225185664\n",
      "train loss:0.0027991057609643155\n",
      "train loss:0.0016129697754664351\n",
      "train loss:0.0012019588592900373\n",
      "train loss:0.0032448811867350335\n",
      "train loss:0.002280878543534114\n",
      "train loss:0.00040922975184227924\n",
      "train loss:0.001822177329435456\n",
      "train loss:0.002040496385595383\n",
      "train loss:0.0011917101995081365\n",
      "train loss:5.290683624514873e-05\n",
      "train loss:0.00014882294262509748\n",
      "train loss:0.0032489067512145903\n",
      "train loss:0.0021232523701255166\n",
      "train loss:0.0011428379693276917\n",
      "train loss:0.00010960341517052562\n",
      "train loss:0.001000157374595032\n",
      "train loss:0.000171151119014773\n",
      "train loss:0.0541696460253072\n",
      "train loss:0.00010213406666492747\n",
      "train loss:0.002182510568739796\n",
      "train loss:0.0004073162439064343\n",
      "train loss:3.615924521472918e-05\n",
      "train loss:0.003648278867351549\n",
      "train loss:0.0016302737513697796\n",
      "train loss:0.0008338062125260784\n",
      "train loss:9.645386891810532e-05\n",
      "train loss:0.003046411541089527\n",
      "train loss:0.001904362493966088\n",
      "train loss:4.9906068952085584e-05\n",
      "train loss:0.004598830873430874\n",
      "train loss:0.0010061355799878577\n",
      "train loss:0.002231043893871616\n",
      "train loss:0.006997413283502749\n",
      "train loss:0.001376212028136708\n",
      "train loss:0.0009476735446539084\n",
      "train loss:0.000963989876490622\n",
      "train loss:0.001808234317278958\n",
      "train loss:0.0020100467914453317\n",
      "train loss:0.00413015866418415\n",
      "train loss:0.0002260378399151192\n",
      "train loss:0.003371072580848775\n",
      "train loss:0.006414638098190484\n",
      "train loss:0.0010208396200061217\n",
      "train loss:0.0005473365183936025\n",
      "train loss:0.0002237750541489515\n",
      "train loss:0.0016311567493897902\n",
      "train loss:0.01933753048831119\n",
      "train loss:0.0010184322240683157\n",
      "train loss:0.003014394183585871\n",
      "train loss:0.0028056869415747187\n",
      "train loss:0.00576347509964797\n",
      "train loss:0.0006329149481879151\n",
      "train loss:0.0003306738891545871\n",
      "train loss:0.0009055419625900764\n",
      "train loss:0.000809817977581686\n",
      "train loss:0.00484041059959173\n",
      "train loss:0.00044547179199685874\n",
      "train loss:0.000755728597374153\n",
      "train loss:0.0010708050411490824\n",
      "train loss:0.0008621522603863926\n",
      "train loss:0.0013157220549623442\n",
      "train loss:0.00018703883258538187\n",
      "train loss:0.003041371815896492\n",
      "train loss:9.325290952184356e-05\n",
      "train loss:0.0027234694009669103\n",
      "train loss:0.0009474813279691434\n",
      "train loss:0.0003277152360532906\n",
      "train loss:0.0007674871785465156\n",
      "train loss:0.0017612019433579185\n",
      "train loss:0.0004931303457393013\n",
      "train loss:0.0021444378084405974\n",
      "train loss:0.001038304463967347\n",
      "train loss:0.009394180624254504\n",
      "train loss:7.739934101099568e-05\n",
      "train loss:0.0019576132435866734\n",
      "train loss:0.00029515700525322835\n",
      "train loss:0.00026727029085027643\n",
      "train loss:0.00023855454104059894\n",
      "train loss:4.2852786340604205e-05\n",
      "train loss:0.0011590012578633082\n",
      "train loss:0.00046018711813230963\n",
      "train loss:8.724957858005054e-06\n",
      "train loss:0.0008623556505839717\n",
      "train loss:6.314848562496408e-05\n",
      "train loss:0.00010216034829439477\n",
      "train loss:0.003472267328825599\n",
      "train loss:0.0012451367390896636\n",
      "train loss:0.002173127593300793\n",
      "train loss:0.0005345768329420933\n",
      "train loss:0.0022424873521635818\n",
      "train loss:0.002706974045593472\n",
      "train loss:0.0003526114848561245\n",
      "train loss:0.00010276503490389447\n",
      "train loss:0.00013479533315781305\n",
      "train loss:0.001388096137053916\n",
      "train loss:0.00035429623561393823\n",
      "train loss:0.010191552782131559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.000472934645088871\n",
      "train loss:6.32704996565934e-05\n",
      "train loss:0.0002935918445154844\n",
      "train loss:0.001228730772072769\n",
      "train loss:0.00033730724512627243\n",
      "train loss:0.002826795837164557\n",
      "train loss:0.00020492919378056084\n",
      "train loss:0.001179886355540469\n",
      "train loss:0.001105163613857099\n",
      "train loss:0.00025894512452603316\n",
      "train loss:0.0006257687590400345\n",
      "train loss:0.003287266806072273\n",
      "train loss:0.0014902346625823837\n",
      "train loss:0.0008886002801872273\n",
      "train loss:0.0005297025281406948\n",
      "train loss:0.000474948577837796\n",
      "train loss:0.0018664469481503361\n",
      "train loss:0.00032489803617164186\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9872\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dataset.mnist import load_mnist\n",
    "from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# if It takes too long -> cut off some data!\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "# Initialize net!\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000) #eval with test!\n",
    "trainer.train()\n",
    "\n",
    "# save params for later use!\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# draw graphs\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs) \n",
    "# value is saved in trainer Class!\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7c292c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "network = SimpleConvNet()\n",
    "# random value!\n",
    "filter_show(network.params['W1'])\n",
    "\n",
    "# weights after training\n",
    "network.load_params(\"params.pkl\")\n",
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f981e7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:my_proj]",
   "language": "python",
   "name": "conda-env-my_proj-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
